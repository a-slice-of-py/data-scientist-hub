# Model monitoring

- [MLflow](https://towardsdatascience.com/5-tips-for-mlflow-experiment-tracking-c70ae117b03f)
- [Model drift](https://towardsdatascience.com/take-my-drift-away-650d0cd92168)
- [Evidently for model monitoring](https://github.com/evidentlyai/evidently)
- [Weights and Biases](https://wandb.ai/site)
- [Sacred](https://github.com/IDSIA/sacred)
- [Omniboard as a Sacred frontend](https://github.com/vivekratnavel/omniboard)
- [MLflow 101](https://towardsdatascience.com/machine-learning-adventures-with-mlflow-64127713b0a1)
- [deepchecks](https://github.com/deepchecks/deepchecks)
- [MLNotify for training completion notification](https://github.com/aporia-ai/mlnotify)
- [NannyML for post-deployment model performance monitoring](https://github.com/NannyML/nannyml)
