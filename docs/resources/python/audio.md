# Audio recognition

- [Kaldi and speech recognition](https://towardsdatascience.com/how-to-start-with-kaldi-and-speech-recognition-a9b7670ffff6)
- [FastAI for audio classification and frequency transforms](https://towardsdatascience.com/audio-classification-using-fastai-and-on-the-fly-frequency-transforms-4dbe1b540f89)
- [Sound data analysis with `librosa`](https://towardsdatascience.com/what-is-sound-691988d780bb)
- [Whisper: OpenAI model for audio transcriptions](https://github.com/openai/whisper)
- [Pedalboard: a Python library for working with audio: reading, writing, rendering, adding effects, and more](https://github.com/spotify/pedalboard)
- [WhisperX: Automatic Speech Recognition with Word-level Timestamps and Diarization](https://github.com/m-bain/whisperX)
- [Moonshine: Fast and accurate automatic speech recognition (ASR) for edge devices](https://github.com/usefulsensors/moonshine)
- [Amphion: An Open-Source Audio, Music, and Speech Generation Toolkit](https://github.com/open-mmlab/Amphion)
- [dia: a TTS model capable of generating ultra-realistic dialogue in one pass](https://github.com/nari-labs/dia)
- [Python Audio Transcription: Convert Speech to Text Locally](https://www.pavlinbg.com/posts/python-speech-to-text-guide)
