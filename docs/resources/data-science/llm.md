# Large Language Models (LLM)

## Coding assistant

- [ChatGPT Is An Extra-Ordinary Python Programmer](https://davidamos.dev/chatgpt-is-an-extra-ordinary-python-programmer/)
- [Developers with AI assistants need to follow the pair programming model](https://stackoverflow.blog/2024/04/03/developers-with-ai-assistants-need-to-follow-the-pair-programming-model/?utm_campaign=so-blog&utm_content=pair-programming&utm_medium=social&utm_source=linkedin)
- [Hard Truths About Generative AI for Technology Leaders](https://www.montecarlodata.com/5-hard-truths-about-generative-ai-for-technology-leaders/)
- [My colleague Julius](https://ploum.net/2024-12-23-julius-en.html)
- [Can LLMs write better code if you keep asking them to "write better code"?](https://minimaxir.com/2025/01/write-better-code/)
- [Large Chainsaw Model](https://www.scottsmitelli.com/articles/large-chainsaw-model/)
- [TabbyML: self-hosted AI coding assistant](https://github.com/TabbyML/tabby)
- [The 2025 AI Engineer Reading List](https://www.latent.space/p/2025-papers)
- [LLM code generation workflow](https://harper.blog/2025/02/16/my-llm-codegen-workflow-atm/)
- [Aider: AI pair programming in your terminal](https://github.com/Aider-AI/aider)
- [codegen: Python SDK to Interact with Intelligent Code Generation Agents](https://github.com/codegen-sh/codegen)
- [I'd rather read the prompt](https://claytonwramsey.com/blog/prompt/)
- [The Problem with "Vibe Coding"](https://dylanbeattie.net/2025/04/11/the-problem-with-vibe-coding.html)
- [Emerging Patterns in Building GenAI Products](https://martinfowler.com/articles/gen-ai-patterns/)
- [The Hidden Cost of AI Coding](https://terriblesoftware.org/2025/04/23/the-hidden-cost-of-ai-coding/)
- [AI code is legacy code from day one](https://text-incubation.com/AI+code+is+legacy+code+from+day+one)
- [sourcebot: a self-hosted tool that helps you understand your codebase](https://github.com/sourcebot-dev/sourcebot)
- [AI Is A Floor Raiser Not A Ceiling Raiser](https://elroy.bot/blog/2025/07/29/ai-is-a-floor-raiser-not-a-ceiling-raiser.html)
- [Design Partner](https://betweentheprompts.com/design-partner/)
- [In Praise Of Normal Engineers](https://charity.wtf/2025/06/19/in-praise-of-normal-engineers/amp/)
- [Building your own CLI Coding Agent with Pydantic-AI](https://martinfowler.com/articles/build-own-coding-agent.html)
- [Why Your Prompts Don't Belong in Git](https://towardsdatascience.com/why-your-prompts-dont-belong-in-git/)
- [Designing agentic loops](https://simonwillison.net/2025/Sep/30/designing-agentic-loops/)
- [Why Generative AI Coding Tools and Agents Do Not Work For Me](https://blog.miguelgrinberg.com/post/why-generative-ai-coding-tools-and-agents-do-not-work-for-me)
- [Micromanaged Driven Development: Build all your code with AI and keep full control](https://mmdd.dev/)

## Distillation

- [Model2Vec: Distill a Small Fast Model from any Sentence Transformer](https://huggingface.co/blog/Pringled/model2vec)
- [Model2Vec Size Improvements](https://minish.ai/blog/2025-10-05-size-blogpost)

## Evaluation

- [Chatbot Arena: Benchmarking LLMs in the Wild](https://arena.lmsys.org/)
- [DeepEval: Unit Testing for LLMs](https://github.com/confident-ai/deepeval)
- [LLM Evaluation](https://huggingface.co/blog/clefourrier/llm-evaluation)
- [Auditing the Ask Astro LLM Q&A app](https://blog.trailofbits.com/2024/07/05/auditing-the-ask-astro-llm-qa-app/)
- [giskard: Open-Source Evaluation & Testing for LLMs and ML models](https://github.com/Giskard-AI/giskard)
- [AI models collapse when trained on recursively generated data](https://www.nature.com/articles/s41586-024-07566-y?fbclid=IwZXh0bgNhZW0CMTEAAR02IYQRaioU3B0L2VkxL401nN0qbH0feuxA94S89umdBAYLVsC8iDEgj0Y_aem_xMLGS6APHIPIA_2cyXM9Rg)
- [Beyond Traditional Testing: Addressing the Challenges of Non-Deterministic Software](https://dev.to/aws/beyond-traditional-testing-addressing-the-challenges-of-non-deterministic-software-583a)
- [Introduction to Large Language Models](https://github.com/SelfExplainML/PiML-Toolbox/blob/main/docs/Workshop/202410IntroLLM/202410IntroLLM.pdf)

## Explanation

- [What is ChatGPT doing and why does it work](https://writings.stephenwolfram.com/2023/02/what-is-chatgpt-doing-and-why-does-it-work/)
- [Large language models, explained with a minimum of math and jargon](https://www.understandingai.org/p/large-language-models-explained-with?utm_medium=ios)
- [Inside GPT: Understanding the text generation](https://towardsdatascience.com/inside-gpt-i-1e8840ca8093)
- [Understand how BERT constructs state-of-the-art embeddings](https://towardsdatascience.com/bert-3d1bf880386a)
- [From encoding to embeddings](https://towardsdatascience.com/from-encodings-to-embeddings-5b59bceef094)
- [Large Language Models: Sentence-BERT](https://towardsdatascience.com/sbert-deb3d4aef8a4)
- [Large Language Models: RoBERTa, a Robustly Optimized BERT Approach](https://towardsdatascience.com/roberta-1ef07226c8d8)
- [Generative AI exists because of the transformer: this is how it works](https://ig.ft.com/generative-ai/)
- [All you need to know to Develop using Large Language Models](https://towardsdatascience.com/all-you-need-to-know-to-develop-using-large-language-models-5c45708156bc)
- [A non-exhaustive but essential list of key papers that underpins text-to-video Deep Generative model like SORA](https://www.linkedin.com/posts/cristiano-de-nobili_sora-generativeai-machinelearning-activity-7164174393965699072-aHTo)
- [Do large language models understand the world?](https://www.amazon.science/blog/do-large-language-models-understand-the-world)
- [Explaining generative language models to (almost) anyone](https://stackoverflow.blog/2024/06/27/explaining-generative-language-models-to-almost-anyone/)
- [The Rise of the LLM OS: From AIOS to MemGPT and beyond](https://community.aws/content/2eojjD2E7TBgPFJmB2FGAtrSSBh/the-rise-of-the-llm-os-from-aios-to-memgpt-and-beyond)
- [Will We Run Out of Data? Limits of LLM Scaling Based on Human-Generated Data](https://epochai.org/blog/will-we-run-out-of-data-limits-of-llm-scaling-based-on-human-generated-data)
- [Llama 2: Open Foundation and Fine-Tuned Chat Models](https://arxiv.org/abs/2307.09288)
- [How LLMs Work, Explained Without Math](https://blog.miguelgrinberg.com/post/how-llms-work-explained-without-math)
- [Foundations of Large Language Models](https://arxiv.org/abs/2501.09223)
- [Transformers and Large Language Models cheatsheet for Stanford's CME 295](https://github.com/afshinea/stanford-cme-295-transformers-large-language-models)
- [Dummy's Guide to Modern LLM Sampling](https://rentry.co/samplers)
- [A cheat sheet for why using ChatGPT is not bad for the environment](https://simonwillison.net/2025/Apr/29/chatgpt-is-not-bad-for-the-environment/)
- [The Cultural Divide between Mathematics and AI](https://sugaku.net/content/understanding-the-cultural-divide-between-mathematics-and-ai/)
- [36 Alternatives to LLM Context](https://www.cyberchitta.cc/articles/lc-alternatives.html)
- [Boring is good](https://jenson.org/boring/)
- [The security paradox of local LLMs](https://quesma.com/blog/local-llms-security-paradox/)

## Foundation models

- [Lag-Llama: Towards Foundation Models for Probabilistic Time Series Forecasting](https://github.com/time-series-foundation-models/lag-llama)

## Framework

- [LangChain: Building applications with LLMs through composability](https://github.com/hwchase17/langchain)
- [Cheshire-Cat: Production ready AI assistant framework](https://github.com/cheshire-cat-ai/core)
- [OLMo: a State-of-the-Art, Truly Open LLM and Framework](https://allenai.org/olmo)
- [DSPy: the framework for programming - not prompting! - foundation models](https://towardsdatascience.com/intro-to-dspy-goodbye-prompting-hello-programming-4ca1c6ce3eb9)
- [A programming framework for agentic AI](https://github.com/microsoft/autogen)
- [Open Source Frameworks for Building Generative AI Applications](https://github.com/danilop/oss-for-generative-ai)
- [LangChain for EDA: Build a CSV Sanity-Check Agent in Python](https://towardsdatascience.com/langchain-for-eda-build-a-csv-sanity-check-agent-in-python/)
- [Datapizza AI: a framework to build Gen AI agentic solutions](https://github.com/datapizza-labs/datapizza-ai)

## Implementation

- [GPT in 60 Lines of NumPy](https://jaykmody.com/blog/gpt-from-scratch/)
- [privateGPT](https://github.com/imartinez/privateGPT)
- [All You Need to Know to Build Your First LLM App](https://towardsdatascience.com/all-you-need-to-know-to-build-your-first-llm-app-eb982c78ffac)
- [How to Run LLMs Locally](https://wandb.ai/capecape/LLMs/reports/A-Guide-on-Running-LLMs-Locally--Vmlldzo0Njg5NzMx)
- [A Gentle Introduction to LLM APIs](https://wandb.ai/darek/llmapps/reports/A-Gentle-Introduction-to-LLM-APIs--Vmlldzo0NjM0MTMz)
- [How to build a basic LLM GPT model from Scratch in Python](https://ruslanmv.com/blog/How-to-Build-a-basic-LLM-GPT-from-Scratch-in-Python)
- [Writing an LLM from scratch](https://www.gilesthomas.com/2024/12/llm-from-scratch-1)
- [Teach your LLM about me](https://ai.jakegaylor.com/)
- [nanochat by Andrej Karpathy: a full-stack implementation of an LLM like ChatGPT in a single, clean, minimal, hackable, dependency-lite codebase](https://github.com/karpathy/nanochat)

## Libraries

- [StartChat Playground by Hugging Face](https://huggingface.co/spaces/HuggingFaceH4/starchat-playground)
- [DeclarAI: turning Python code into production-ready LLM tasks](https://github.com/vendi-ai/declarai)
- [codellama](https://github.com/facebookresearch/codellama)
- [Attention Sinks in LLMs for endless fluency](https://huggingface.co/blog/tomaarsen/attention-sinks)
- [OpenLLM Leaderboard](https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard)
- [LMQL: a programming language for large language models](https://github.com/eth-sri/lmql)
- [GPT-Engineer](https://github.com/gpt-engineer-org/gpt-engineer)
- [magentic: easily integrate Large Language Models into your Python code](https://github.com/jackmpcollins/magentic)
- [AlphaCodium: From Prompt Engineering to Flow Engineering](https://github.com/Codium-ai/AlphaCodium)
- [Cohere For AI Launches Aya: an LLM Covering More Than 100 Languages](https://txt.cohere.com/aya/)
- [Gemma: una nuova famiglia di modelli aperti](https://blog.google/intl/it-it/una-nuova-famiglia-di-modelli-aperti-denominata-gemma/)
- [Gemma 2 optimized for your local machine](https://github.com/huggingface/local-gemma)
- [Unsloth: Finetune Llama 3.1, Mistral, Phi and Gemma](https://github.com/unslothai/unsloth)
- [Open WebUI: user-friendly WebUI for LLMs](https://github.com/open-webui/open-webui)
- [LangDrive: train LLMs on private data](https://github.com/addy-ai/langdrive)
- [Trace: AutoDiff for AI Systems and LLM Agents](https://github.com/microsoft/trace)
- [LitGPT: 2high-performance LLMs with recipes to pretrain, finetune and deploy at scale](https://github.com/Lightning-AI/litgpt)
- [guidance: a guidance language for controlling large language models](https://github.com/guidance-ai/guidance)
- [litellm: Python SDK, proxy server to call LLM APIs using the OpenAI format](https://github.com/BerriAI/litellm)
- [guardrails: adding guardrails to large language models](https://github.com/guardrails-ai/guardrails)
- [Burr: build applications that make decisions (chatbots, agents, simulations). Monitor, trace, persist, and execute on your own infrastructure](https://github.com/dagworks-inc/burr)
- [el: a language model programming library](https://github.com/MadcowD/ell)
- [JIT Implementation: A Python Library That Implements Your Code at Runtime](https://github.com/JirkaKlimes/jit-implementation)
- [ChainLit: Build Conversational AI in minutes](https://github.com/Chainlit/chainlit)
- [DataChain: AI-data warehouse to enrich, transform and analyze unstructured data](https://github.com/iterative/datachain)
- [Simplemind: Python client for AI providers](https://github.com/kennethreitz/simplemind)
- [Docling: parse documents and export them to the desired format with ease and speed](https://github.com/DS4SD/docling)
- [Posting: the modern API client that lives in your terminal](https://github.com/darrenburns/posting)
- [TabPFN: Foundation Model for Tabular Data](https://github.com/PriorLabs/TabPFN)
- [agx: AI Powered Analytics App](https://github.com/agnosticeng/agx)
- [torchexplorer: interactively inspect module inputs, outputs, parameters, and gradients](https://github.com/spfrommer/torchexplorer)
- [token-explorer: a simple tool to explore different possible paths that an LLM might sample](https://github.com/willkurt/token-explorer)
- [CoRT (Chain-of-Recursive-Thoughts): AI think harder when it argues with itself repeatedly](https://github.com/PhialsBasement/Chain-of-Recursive-Thoughts)
- [agenticSeek: fully Local Manus AI](https://github.com/Fosowl/agenticSeek)
- [blast: browser-LLM Auto-Scaling Technology](https://github.com/stanford-mast/blast)
- [Basic Memory: AI conversations that actually remember](https://github.com/basicmachines-co/basic-memory)
- [elroy: An AI assistant that remembers and sets goals](https://github.com/elroy-bot/elroy)
- [langextract: A Python library for extracting structured information from unstructured text using LLMs with precise source grounding and interactive visualization](https://github.com/google/langextract)
- [LLMs to Alloy](https://github.com/jacopotagliabue/LLMs-to-Alloy)
- [Ollama Web search](https://ollama.com/blog/web-search)

## MCP

- [ask-human MCP](https://github.com/Masony817/ask-human-mcp)
- [fastmcp: The fast, Pythonic way to build MCP servers and clients](https://github.com/jlowin/fastmcp)
- [Google A2A: Agent2Agent Protocol](https://github.com/google-a2a/A2A)
- [MCP As An Accidentally Universal Plugin](https://worksonmymachine.substack.com/p/mcp-an-accidentally-universal-plugin)
- [Python MCP Server: Connect LLMs to Your Data](https://realpython.com/python-mcp/)
- [Claude Skills are awesome, maybe a bigger deal than MCP](https://simonwillison.net/2025/Oct/16/claude-skills/)

## Methods

- [LLM sampling](https://artefact2.github.io/llm-sampling/index.xhtml)
- [Open Source LLMs To Power A LLM Application](https://pub.towardsai.net/top-10-open-source-llms-to-use-in-your-next-llm-application-fbfc51542b78)
- [NLP tasks via LLM](https://towardsdatascience.com/natural-language-processing-for-absolute-beginners-a195549a3164)
- [Methods For Improving Your Large Language Model](https://towardsdatascience.com/3-easy-methods-for-improving-your-large-language-model-68670fde9ffa)

## Prompt engineering

- [Pushing Prompt Engineering to the Limit](https://towardsdatascience.com/what-i-learned-pushing-prompt-engineering-to-the-limit-c40f0740641f)
- [Mastering Prompt Engineering](https://towardsdatascience.com/mastering-prompt-engineering-to-unleash-chatgpts-potential-9578a3fe799c)
- [The Prompt Engineering Playbook For Programmers](https://addyo.substack.com/p/the-prompt-engineering-playbook-for)

## RAG

- [GraphRAG: a modular graph-based Retrieval-Augmented Generation (RAG) system](https://github.com/microsoft/graphrag)
- [llmware: unified framework for building enterprise RAG pipelines with small, specialized models](https://github.com/llmware-ai/llmware)
- [talkd/dialog: RAG LLM Ops App for easy deployment and testing](https://github.com/talkdai/dialog)
- [A RAG from scratch to query the scikit-learn documentation](https://papers.probabl.ai/a-rag-from-scratch-to-query-the-scikit-learn-documentation)
- [Production RAG: what I learned from processing 5M+ documents](https://blog.abdellatif.io/production-rag-processing-5m-documents)

## Regulation

- [How Foundation Model Providers Comply with the Draft EU AI Act](https://crfm.stanford.edu/2023/06/15/eu-ai-act.html)

## Vector databases

- [Vector Databases and How to Use Them to Augment LLM](https://towardsdatascience.com/all-you-need-to-know-about-vector-databases-and-how-to-use-them-to-augment-your-llm-apps-596f39adfedb)

## Visuals

- [A Visual Guide to Mamba and State Space Models](https://maartengrootendorst.substack.com/p/a-visual-guide-to-mamba-and-state)
- [A Visual Guide to Quantization](https://newsletter.maartengrootendorst.com/p/a-visual-guide-to-quantization)
- ["Attention, Please!": A Visual Guide To The Attention Mechanism](https://codecompass00.substack.com/p/visual-guide-attention-mechanism-transformers)
- [Official code repo for the O'Reilly Book "Hands-On Large Language Models"](https://github.com/HandsOnLLM/Hands-On-Large-Language-Models)
- [Understanding Transformers Using A Minimal Example](https://github.com/rti/gptvis)

## World models

- [Yann LeCun's SSL, JEPA, World Models and the Future of AI](https://drive.google.com/file/d/1oeaO03YRpxkTjKamfYrksEm-MCHk4JbS/view)
