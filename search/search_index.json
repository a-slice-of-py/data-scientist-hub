{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"A Data Scientist Blog","text":""},{"location":"about/","title":"About","text":""},{"location":"about/#whatis","title":"Whatis","text":"<p>Data Scientist Hub (DSH) is my personal knowledge center.</p> <p>DSH is definitely a living creature, always under development and I expect - and somehow wish - frequent changes in both contents and shape. It is currently implemented via mkdocs with material theme and deployed on GitHub Pages.</p> <p>It all started with random mails to myself to store somewhere useful links I came across, then became a Trello board and now is a full mkdocs project with a useful search feature to quickly retrieve references together with a brand new blog which I hope to update frequently - insipiration about TIL approach taken from koaning.</p>"},{"location":"about/#whois","title":"Whois","text":"<p>I am a former mathematician<sup>1</sup>, amateur singer, guitarist and music producer and casual hiker - currently employed as Data Scientist.</p> <p>You can find me on GitHub or Linkedin.</p>"},{"location":"about/#changelog","title":"Changelog","text":""},{"location":"about/#v24","title":"v2.4","text":"<p>Release date: Dec 27, 2023</p> <p>Lighter appearance and big refactor:</p> <ul> <li>upgrade <code>mkdocs-material</code> to latest version</li> <li>enable Git metadata</li> <li>move all notes under new Blog plugin</li> <li>move Snippets under Resources section</li> <li>refactor several resources pages</li> <li>remove legacy sections</li> </ul>"},{"location":"about/#v23","title":"v2.3","text":"<p>Release date: Jun 18, 2022</p> <p>Several additions and improvements:</p> <ul> <li>move from setup.py to setup.cfg</li> <li>add Docker and Makefile support</li> <li>add tags plugin</li> <li>add Gource animation</li> <li>update Projects section</li> </ul>"},{"location":"about/#v22","title":"v2.2","text":"<p>Release date: Jan 19, 2022</p> <p>Move PAWS section under Notes.</p>"},{"location":"about/#v21","title":"v2.1","text":"<p>Release date: Jan 5, 2022</p> <p>Update with most up-to-date mkdocs-material features, brand new contents and appearance.</p>"},{"location":"about/#v20","title":"v2.0","text":"<p>Release date: Nov 02, 2020</p> <p>First DSH version as standalone mkdocs project.</p>"},{"location":"about/#v10","title":"v1.0","text":"<p>Release date: Mar 8, 2020</p> <p>Trello board named \"Resources\", with topics as cards and links as checklist items.</p>"},{"location":"about/#v01","title":"v0.1","text":"<p>Release date: Jun 21, 2018</p> <p>Unorganized collection of links stored in random mails to myself.</p> <ol> <li> <p>For reference, here my master thesis and here some Prezi slides used during the final dissertation.\u00a0\u21a9</p> </li> </ol>"},{"location":"tags/","title":"Tags","text":""},{"location":"tags/#aws","title":"AWS","text":"<ul> <li>A comparison between AWS Chalice and AWS SAM</li> <li>AWS CodeBuild local testing</li> <li>A comparison between AWS databases</li> <li>Read DynamoDB table items into a Pandas Dataframe</li> <li>An introduction to Amazon DynamoDB</li> <li>Amazon EC2 instance debug</li> <li>How to display AWS CloudWatch logs in Streamlit</li> <li>AWS S3 presigned URLs</li> <li>Build Lambda layers with AWS SAM</li> <li>Best practices per AWS CDK L3 constructs</li> <li>A visual comparison of AWS Certifications</li> <li>AWS Certification Skill Tree</li> <li>All you need is closure</li> <li>Cross-account full table copy options for Amazon DynamoDB</li> </ul>"},{"location":"tags/#database","title":"Database","text":"<ul> <li>A comparison between AWS databases</li> <li>Read DynamoDB table items into a Pandas Dataframe</li> <li>An introduction to Amazon DynamoDB</li> <li>Cross-account full table copy options for Amazon DynamoDB</li> </ul>"},{"location":"tags/#devops","title":"DevOps","text":"<ul> <li>AWS CodeBuild local testing</li> </ul>"},{"location":"tags/#ita","title":"ITA","text":"<ul> <li>Best practices per AWS CDK L3 constructs</li> <li>Presto/Trino, unix timestamp, window functions e daylight saving time</li> </ul>"},{"location":"tags/#iac","title":"IaC","text":"<ul> <li>Best practices per AWS CDK L3 constructs</li> </ul>"},{"location":"tags/#or","title":"OR","text":"<ul> <li>A brief guide to Python's PuLP</li> <li>A guide to transportation problems</li> </ul>"},{"location":"tags/#open-source","title":"Open Source","text":"<ul> <li>Read DynamoDB table items into a Pandas Dataframe</li> </ul>"},{"location":"tags/#python","title":"Python","text":"<ul> <li>Read DynamoDB table items into a Pandas Dataframe</li> <li>A brief guide to Python's PuLP</li> <li>A visual comparison of AWS Certifications</li> <li>AWS Certification Skill Tree</li> <li>All you need is closure</li> <li>Terminal User Interface</li> </ul>"},{"location":"tags/#sql","title":"SQL","text":"<ul> <li>Presto/Trino, unix timestamp, window functions e daylight saving time</li> </ul>"},{"location":"tags/#streamlit","title":"Streamlit","text":"<ul> <li>How to display AWS CloudWatch logs in Streamlit</li> </ul>"},{"location":"2021/12/21/a-comparison-between-aws-chalice-and-aws-sam/","title":"A comparison between AWS Chalice and AWS SAM","text":"<p>AWS Chalice is a microframework for writing serverless apps in Python.</p> <p>The following table provides a mapping between AWS SAM and AWS Chalice commands:</p> <p>Chalice</p> <p>Main options</p> <p>Notes</p> <p>SAM equivalent</p> <p><code>chalice new-project </code> <p>initialize an \"hello world\" sample project at the dev stage</p> <p><code>sam init --name </code> <p><code>chalice deploy</code></p> <p><code>--no-autogen-policy</code> to avoid auto policy generation, requires a source policy file <code>.chalice/policy-</code><code>.json</code> <code>--stage </code> to set a different deployment stage (dev by default) <p>Chalice automatically builds apps, storing the build results in <code>.chalice/deployments/</code></p> <p><code>sam build &amp;&amp; sam deploy</code></p> <p><code>chalice local</code></p> <p><code>--port=XXXX</code> to redirect local hosting on a specific port</p> <p>locally run the app (by default on port 8000)</p> <p>partially covered by <code>sam local invoke</code></p> <p><code>chalice invoke --name </code> <p>invoke a Lambda function</p> <p>partially covered by <code>sam local invoke</code></p> <p><code>chalice gen-policy</code></p> <p>redirect to stdout the auto-generated AWS policy for the defined app (useful as a starting template for <code>.chalice/policy-</code><code>.json</code>) <p><code>chalice delete</code></p> <p>delete the deployed app</p> <p>The following sample is the Chalice implementation equivalent of SAM project discussed here.</p> <pre><code>chalice-app/\n\u2502\n\u251c\u2500\u2500 .chalice/\n\u2502   \u251c\u2500\u2500 deployed/\n\u2502   \u2502   \u2514\u2500\u2500 &lt;stage_name&gt;.json\n\u2502   \u251c\u2500\u2500 deployments/\n\u2502   \u251c\u2500\u2500 policy-&lt;stage_name&gt;.json\n\u2502   \u2514\u2500\u2500 config.json\n\u2502\n\u251c\u2500\u2500 chalicelib/\n\u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u2514\u2500\u2500 custom_script.py\n\u2502\n\u251c\u2500\u2500 app.py\n\u2502\n\u2514\u2500\u2500 requirements.txt\n</code></pre> <p>where <code>app.py</code> contains (possibly) all the Lambda handlers, each one decorated with <code>@app.lambda_function(name='my_lambda_name')</code>, needed to let Chalice treat them as pure Lambda functions.</p>","tags":["AWS"]},{"location":"2021/12/21/aws-codebuild-local-testing/","title":"AWS CodeBuild local testing","text":"<p>Suppose you have a CodeBuild project triggered by a push on a given branch of a linked CodeCommit repo. If the build is particularly heavy, you might want to ensure its correctness before an actual commit to the related repo - for example, you might be interested in testing the build process specified in <code>buildspec.yml</code> locally.</p> <p>Thankfully, AWS released in 2018 the capability to do so with AWS CodeBuild agent. To use it you must:</p> <ol> <li>clone the repo with CodeBuild Docker image</li> <li>build it (~9 GB, it might take time...)</li> <li>pull of CodeBuild local agent image</li> <li>finally test a buildspec locally!</li> </ol> <p>Warning 1</p> <p>If you are on Windows, pay attention to EOL conversion after cloning (step 1). During build phase (step 2) you might encounter errors like this.</p> <p>Warning 2</p> <p>If you are on Windows, you might fail to actually test anything as reported here and here. A possible workaround consists in switching to WSL2.</p> <p>Hint 1</p> <p>If your build process is particularly heavy, during the test phase (step 4) it might remain stuck in <code>Waiting for DOWNLOAD_SOURCE</code> step. Indeed, the default agent behaviour is to copy the source directory: you can instead mount it by using <code>-m</code> option in test script, as suggested here.</p> <p>Doing so, each build action which interacts with the file system will actually take place in the source directory.</p> <p>Hint 2</p> <p>If you want CodeBuild local agent to use a local named profile, you can execute <code>codebuild_build.sh</code> with options <code>-c -p &lt;PROFILE_NAME&gt;</code>, as suggested here.</p>","tags":["AWS","DevOps"]},{"location":"2022/02/02/a-comparison-between-aws-databases/","title":"A comparison between AWS databases","text":"<p>Main databases types:</p> <ul> <li>Relational: data are stored in tabular form (rows and columns), where each row represents a unique record. Tables can be put in relation with each other through joins and queried via SQL;</li> <li>Key-value: non-relational database where each record stored as a unique key with its associated value, resembling a dictionary-like structure;</li> <li>Document: semi-structured and hierarchical databases for catalogs and content management systems, often stored as JSON;</li> <li>Graph: the way the data are stored is graph-based, with nodes and edges connecting each data source with the others;</li> <li>Time-series: database optimized for records which indices are timestamps.</li> </ul> Service Type Query language Use cases Athena Structured, semi-structured and unstructured SQL based on HiveQL DDL and Presto DML Log analysis, OLAP, BI Aurora<sup>1</sup> Relational MySQL, PostgreSQL eCommerce, CRM DocumentDB Document compatible with MongoDB query language product catalogs, images and videos, application data platform DynamoDB Key-value NoSQL Mobile and web apps, gaming, IoT Neptune Graph GQL (Apache TinkerPop Gremlin, SPARQL) Fraud detection, social netowkrs, knowledge graph, recommendation engines Timestream Time-series ANSI SQL IoT, DevOps, telemetry, forecasting, analytics RDS Relational SQL DWH, CRM Redshift Relational SQL based on PostgreSQL Large-scale DWH, data migration, OLAP <p>Warning</p> <p>Athena and RDS are somewhat erroneously reported in the above table which refers to databases: a deep dive on the main differences is available below.</p>","tags":["AWS","Database"]},{"location":"2022/02/02/a-comparison-between-aws-databases/#amazon-rds","title":"Amazon RDS","text":"<p>From the official docs:</p> <p>Amazon Relational Database Service (Amazon RDS) is a web service that makes it easier to set up, operate, and scale a relational database in the AWS Cloud. It provides cost-efficient, resizable capacity for an industry-standard relational database and manages common database administration tasks.</p> <p>Amazon RDS is not therefore a database engine itself, rather than a tool that helps in managing relational databases on AWS. Essentially, can be thought as an AWS-managed, generally purpose RDBMS.</p> <p>It allows to manage and run six database engines:</p> <ul> <li>Amazon Aurora</li> <li>MySQL</li> <li>MariaDB</li> <li>PostgreSQL</li> <li>Oracle</li> <li>Microsoft SQL Server</li> </ul>","tags":["AWS","Database"]},{"location":"2022/02/02/a-comparison-between-aws-databases/#a-brief-comparison-between-open-source-databases","title":"A brief comparison between open source databases","text":"<p>A brief comparison between open source relational databases is available below (full credits to Soufiane L).</p> Feature MariaDB<sup>2</sup> MySQL PostgreSQL<sup>3</sup> Materialized Views \u274c \u274c \u2714\ufe0f Partial Indexes \u274c \u274c \u2714\ufe0f Array Data Type \u274c \u274c \u2714\ufe0f JSON Data Type \u2714\ufe0f \u2714\ufe0f \u2714\ufe0f CHECK constraints \u2714\ufe0f \u274c \u2714\ufe0f Replication \u2714\ufe0f \u2714\ufe0f \u2714\ufe0f Full-Text Search \u2714\ufe0f \u2714\ufe0f \u2714\ufe0f UPSERT \u2714\ufe0f \u2714\ufe0f \u2714\ufe0f Common Table Expressions \u2714\ufe0f \u2714\ufe0f \u2714\ufe0f Sequences \u2714\ufe0f \u274c \u2714\ufe0f Table Partitioning \u2714\ufe0f \u2714\ufe0f \u274c","tags":["AWS","Database"]},{"location":"2022/02/02/a-comparison-between-aws-databases/#amazon-athena","title":"Amazon Athena","text":"<p>Amazon Athena it's not a database engine itself but it's defined as an interactive query service based on Apache Presto that makes easy to analyze data stored into S3 via SQL. This means that compute and storage are separate and managed independently.</p> <p>It is completely serverless and cost-effective, and can be used together with AWS Glue - fully managed ETL service - which takes care of managing a related data catalog as a central source for metadata while preparing data for querying.</p> <p>In contrast, efficient querying requires data to be partitioned and purposely organized into S3 buckets upfront; moreover AWS Athena users compete for the same resources at the same time. While AWS provisions more resources as needed, it could mean that query performance fluctuates based on other users needs.</p>","tags":["AWS","Database"]},{"location":"2022/02/02/a-comparison-between-aws-databases/#resources","title":"Resources","text":"<ul> <li>Choosing an AWS database</li> <li>Amazon Athena vs traditional databases</li> <li>CloudZero blog on Athena</li> <li>AWS database comparison</li> <li>MariaDB vs PostgreSQL</li> <li>Open source databases comparison</li> </ul> <ol> <li> <p>can be run on both RDS and as Aurora serverless.\u00a0\u21a9</p> </li> <li> <p>based on MySQL and created after its acquisition by Oracle.\u00a0\u21a9</p> </li> <li> <p>PostgreSQL is generally considered to be the fastest one in terms of read/write speed.\u00a0\u21a9</p> </li> </ol>","tags":["AWS","Database"]},{"location":"2023/01/09/read-dynamodb-table-items-into-a-pandas-dataframe/","title":"Read DynamoDB table items into a Pandas Dataframe","text":"<p>For all the Python developers working on AWS: have you ever wanted to easily read a DynamoDB table directly into a pandas DataFrame?</p> <p>Check out the latest release of AWS SDK for pandas (formerly AWS Data Wrangler), where I contributed with a brand new read method for DynamoDB module!</p>","tags":["AWS","Database","Open Source","Python"]},{"location":"2023/01/09/read-dynamodb-table-items-into-a-pandas-dataframe/#features","title":"Features","text":"<ul> <li>automatically switch between available DynamoDB read actions, choosing the optimal one (aka \"no more headaches fighting with boto3\") as defined in this hierarchy <code>get_item &gt; batch_get_item &gt; query &gt; scan</code> (inspiration from here and here)</li> <li>support filtering both on keys and attributes</li> <li>automatically sanitize DynamoDB reserved keywords</li> <li>prevent unwanted full table scan</li> <li>allow attributes selection via columns kwarg</li> <li>support limiting the number of returned items with the <code>max_items_evaluated</code> kwarg (a sort of an <code>head()</code> method for the table!)</li> <li>...and more!</li> </ul> <p>Read here the full API reference.</p>","tags":["AWS","Database","Open Source","Python"]},{"location":"2023/01/09/read-dynamodb-table-items-into-a-pandas-dataframe/#history","title":"History","text":"<p>I found myself putting some effort in trying to handle reading items from a DynamoDB table and returning a Pandas Dataframe. Basically, I wanted to abstract some complexity away from available Boto3 read actions, and handle once for all the headache of thinking about keys, query, scan, etc.: since I was pretty happy with the result, I decided to submit a PR with a candidate for <code>wr.dynamodb.read_items</code> in aws/aws-sdk-pandas#1867.</p> <p>I was aware of the addition of <code>wr.dynamodb.read_partiql_query</code> in aws/aws-sdk-pandas#1390, as well as the related issues as reported in aws/aws-sdk-pandas#1571, but the proposed solution does not involve PartiQL: my goal was to avoid as much as possible the risks that come with its usage towards a DynamoDB table, regarding possible translation of a given query to a full scan op (see for example the disclaimer in the docs).</p>","tags":["AWS","Database","Open Source","Python"]},{"location":"2021/12/21/an-introduction-to-amazon-dynamodb/","title":"An introduction to Amazon DynamoDB","text":"<p>An overview of Amazon DynamoDB NoSQL database.</p>","tags":["AWS","Database"]},{"location":"2021/12/21/an-introduction-to-amazon-dynamodb/#usage-modes","title":"Usage modes","text":"<p>Each Dynamo table has two different usage modes which differ on desired reading and writing capabilities: on-demand and provisioned.</p> <p>Despite the selected mode, interactions with DynamoDb tables are managed abiding the following consumption schema:</p> <ul> <li>1 writing capacity unit (WCU) for each writing operation (up to 1KB)</li> <li>0,5 reading capacity unit (RCU) for each eventually consistent <sup>1</sup> reading operation (up to 4KB)</li> <li>1 reading capacity unit for each strongly consistent <sup>2</sup> reading operation (up to 4KB)</li> <li>2 reading/writing capacity units for each transational operation</li> <li>multiple capacity units for each operation which exceeds above size limits</li> </ul>","tags":["AWS","Database"]},{"location":"2021/12/21/an-introduction-to-amazon-dynamodb/#pricing","title":"Pricing","text":"<p>As per <code>eu-central-1</code> region and as of 2021, the pricing schema is:</p> <ul> <li>on-demand: 1,525 USD per million units</li> <li>provisioned: 0,000793 USD per RCU/hour (or WCU/hour)</li> </ul> <p>Simplifying:</p> <ul> <li> <p>on-demand mode bills operations on the table at their incoming rate</p> <p>Example</p> <p>80M writing operations cost 122 USD</p> </li> <li> <p>provisioned mode requires assignment of RCU and WCU available per hour, and then bills accordingly</p> <p>Example</p> <p>80M writing operations on a provisioned table with 1000 WCU assigned are managed roughly in 22 hours (80M / (1000 WCU * 3600) and cost 22 * 1000 * 0,000793 ~ 17 USD</p> </li> </ul> <p>If no latency in operations management is allowed, on-demand mode ensures that at a price point roughly 7x the baseling provisioned mode. On the other hand, provisioned mode can be more reliable in terms of costs planning (thanks to the capacity assignment made beforehand), but implies a cap on operations manageable and generates fixed costs even when no operations are needed on the table.</p>","tags":["AWS","Database"]},{"location":"2021/12/21/an-introduction-to-amazon-dynamodb/#autoscaling","title":"Autoscaling","text":"<p>Provisioned mode comes with the possibility of setting up autoscaling feature, which can increase operations rate when needed (particularly useful in operation peaks management). Autoscaling setup requires:</p> <ul> <li>min capacity</li> <li>max capacity</li> <li>target usage rate (ratio between consumed units and available units)</li> </ul> <p>Important</p> <p>Autoscaling features is in charge of scaling the provisioned capacity within [min, max] range so that the actual usage rate is mantained close to the specified target.</p> <p>Autoscaling is based on CloudWatch metrics linked to read and write operations: as soon as these metrics detect a usage rate far from the target, a trigger fires a CloudWatch alarm that in turn triggers table autoscaling (the autoscaling feature pricing is based only on the pricing of the involved resources, see here). Therefore, this mechanism suffers of a warm-up period.</p> <p>If an operation is requested but not performed on a provisioned table (e.g. no autoscaling, incoming rate greater than target, ...) will result as throttled request.</p> <p>Failed to set write capacity units to 5. Reason: Failed updating table: Subscriber limit exceeded: Provisioned throughput decreases are limited within a given UTC day. After the first 4 decreases, each subsequent decrease in the same UTC day can be performed at most once every 3600 seconds. Number of decreases today: 4</p> <p>If operations traffic towards the table stops suddenly, autoscaling does its best to reduce provisioned capacity from current to the specified minimum (5 in the above example): after first 4 decreases, it is limited to 1 decrease per hour. This behaviour is somehow a \"hidden cost\" of provisioned mode: in such situations, you will be billed for an entire hour for the residual peak capacity, even if it is not needed anymore.</p>","tags":["AWS","Database"]},{"location":"2021/12/21/an-introduction-to-amazon-dynamodb/#lambda-trigger-fails","title":"Lambda trigger fails","text":"<p>Assume you have the following scenario:</p> <ul> <li>an on-demand dynamo table</li> <li>Dynamo stream enabled with <code>NEW_IMAGE</code> mode (stream contains only records after table updates)</li> <li>a trigger for a consequent operation implemented by Lambda function watching the stream with <code>batch_size = 1</code> and <code>latest starting position</code></li> </ul> <p>Question</p> <p>What if the Lambda function fails for any reason?</p> <p>Standard Lambda functions have a 3x retry policy. But when it comes to Lambda watching streams, as stated here and here:</p> <p>If the invocation for one record times out, is throttled, or encounters any other error, Lambda will retry until it succeeds (or the record reaches its 24-hour expiration).</p> <p>If your function returns an error, Lambda retries the batch until processing succeeds or the data expires. To avoid stalled shards, you can configure the event source mapping to retry with a smaller batch size, limit the number of retries, or discard records that are too old.</p> <p>To customize this behaviour you can specify <code>DynamoEventSource</code> parameters as suggested in the docs and as available in CDK - in particular:</p> <ul> <li><code>retry_attempts</code>: Maximum number of retry attempts Valid Range: *. Minimum value of 0 *. Maximum value of 10000. Default: - retry until the record expires</li> <li><code>max_record_age</code>: The maximum age of a record that Lambda sends to a function for processing. Valid Range: - Minimum value of 60 seconds - Maximum value of 7 days Default: - the retention period configured on the stream</li> </ul>","tags":["AWS","Database"]},{"location":"2021/12/21/an-introduction-to-amazon-dynamodb/#lambda-and-vpc-subnets","title":"Lambda and VPC Subnets","text":"<p>If an AWS Lambda raises timeout connection error while trying to reach a Dynamo DB table, despite inside a VPC with endpoint towards DynamoDB enabled, please refer to this issue: the reason might be related to public subnets randomly assigned to the lambda in a given availability zone.</p>","tags":["AWS","Database"]},{"location":"2021/12/21/an-introduction-to-amazon-dynamodb/#main-takeaways","title":"Main takeaways","text":"<ul> <li>on-demand mode lets you pay for what you actually use, ensuring no performance issue at the cost of an higher price-point</li> <li>provisioned mode essentially limits operations costs while turning on user-side the possible performance degradation</li> </ul>","tags":["AWS","Database"]},{"location":"2021/12/21/an-introduction-to-amazon-dynamodb/#notes","title":"Notes","text":"<ol> <li><code>put_df</code> method of AWS Data Wrangler is nothing but a wrapper of boto3 <code>batch_write_item</code></li> <li>using the above method to write on Dynamo a Pandas Dataframe coming from <code>pd.read_json</code> requires you to cast <code>np.array</code> to <code>list</code> as well as <code>float</code> to <code>Decimal</code></li> <li>each read operation performed via query can be monitored in terms of consumed RCU by parsing the related response looking for <code>ConsumedCapacity</code> field</li> </ol>","tags":["AWS","Database"]},{"location":"2021/12/21/an-introduction-to-amazon-dynamodb/#aws-cdk","title":"AWS CDK","text":"<p>To give write (resp. read) permission to a Lambda on a Dynamo table, both the CDK docs and some snippets refer to <code>grant_write_data</code> method of the table.</p> <p>This method should ensure:</p> <ol> <li>Lambda permission to perform operations on the table</li> <li>Lambda access to the (possible) KMS key for encrypt/decrypt operations</li> </ol> <p>For the latter there is this issue though, which demonstrates the additional need for:</p> <pre><code>if table.encryption_key:\n    table.encryption_key.grant_decrypt(lambda)\n</code></pre>","tags":["AWS","Database"]},{"location":"2021/12/21/an-introduction-to-amazon-dynamodb/#resources","title":"Resources","text":"<ul> <li>DynamoDB and auto-scaling docs</li> <li>AWS blog post about auto-scaling</li> <li>on-demand mode blog post</li> <li>pricing vs mode comparison</li> <li>on-demand mode stress tests</li> </ul> <ol> <li> <p>Reading operations which can suffer of latency if performed close to table updates, returning outdated records.\u00a0\u21a9</p> </li> <li> <p>Reading operations which are always up-to-date w.r.t. table updates.\u00a0\u21a9</p> </li> </ol>","tags":["AWS","Database"]},{"location":"2022/01/19/amazon-ec2-instance-debug/","title":"Amazon EC2 instance debug","text":"<p>To check instance initialization:</p> <ul> <li>establish an SSH connection;</li> <li>inspect logs located at <code>/var/log/cloud-init-output.log</code> as suggested here.</li> </ul>","tags":["AWS"]},{"location":"2021/10/15/how-to-display-aws-cloudwatch-logs-in-streamlit/","title":"How to display AWS CloudWatch logs in Streamlit","text":"<p>Let's dive in the following scenario:</p> <ul> <li>we have some job/task running on AWS</li> <li>we have already built a Streamlit frontend to launch jobs</li> <li>we want to monitor AWS CloudWatch logs generated by the job execution</li> <li>we don't want to neither switch from our Streamlit frontend to AWS Console, nor become crazy in following right log groups/streams to track our job</li> </ul> <p>A possible custom solution is presented below.</p>","tags":["AWS","Streamlit"]},{"location":"2021/10/15/how-to-display-aws-cloudwatch-logs-in-streamlit/#requirements","title":"Requirements","text":"<pre><code>streamlit        # to build monitor frontend\nboto3            # to interact with CloudWatch\npandas           # to manipulate logs as dataframes\npytz             # to set local timezones to logs timestamp\nstreamlit-aggrid # to enhance logs viz experience\n</code></pre>","tags":["AWS","Streamlit"]},{"location":"2021/10/15/how-to-display-aws-cloudwatch-logs-in-streamlit/#source-code","title":"Source code","text":"<p>The solution consists in a Streamlit monitor which tracks last job execution (a custom widget to filter execution by date should be a straightforward addition).</p> <pre><code>import os\nfrom datetime import datetime\nfrom typing import Optional\n\nimport boto3\nimport pandas as pd\nimport pytz\nimport streamlit as st\nfrom st_aggrid import AgGrid, GridOptionsBuilder, JsCode\n\n\ndef gmt2rome(date: str, fmt: str = \"%a, %d %b %Y %H:%M:%S GMT\") -&gt; datetime:\n    \"\"\"Convert GMT timestamp to EU/Rome.\n\n    Args:\n        date (str): [description]\n        fmt (str, optional): [description]. Defaults to \"%a, %d %b %Y %H:%M:%S GMT\".\n\n    Returns:\n        EU/Rome datetime\n    \"\"\"\n    gmt = pytz.timezone(\"GMT\")\n    return gmt.localize(datetime.strptime(date, fmt)).astimezone(pytz.timezone('Europe/Rome'))\n\n\ndef get_last_log(cloudwatch: boto3.client, log_group: str) -&gt; pd.DataFrame:\n    \"\"\"Build most recent logs dataframe for the given AWS resource.\n\n    # SEE: https://gist.github.com/eldondevcg/fffff4b7909351b19a53 for credits.\n\n    Args:\n        cloudwatch (boto3.client): cloudwatch client.\n        log_group (str): log group name.\n\n    Returns:\n        Most recent logs dataframe.\n    \"\"\"\n    # Initialize stream batch\n    stream_batch = cloudwatch.describe_log_streams(\n                logGroupName=log_group, orderBy='LastEventTime')\n\n    all_streams = []\n    # Retrieve all streams\n    all_streams += stream_batch['logStreams']\n    while 'nextToken' in stream_batch:\n        stream_batch = cloudwatch.describe_log_streams(\n            logGroupName=log_group, nextToken=stream_batch['nextToken'], orderBy='LastEventTime')\n        all_streams += stream_batch['logStreams']\n\n    if all_streams:\n        # Select only the last stream\n        stream = all_streams[-1]\n        st.info(f\"**Log stream name**: `{stream['logStreamName']}`\")\n        # Get log events\n        events = []\n        logs_batch = cloudwatch.get_log_events(\n            logGroupName=log_group, logStreamName=stream['logStreamName'])\n        for event in logs_batch['events']:\n            events.append(event)\n        while 'nextToken' in logs_batch:\n            logs_batch = cloudwatch.get_log_events(\n                logGroupName=log_group, logStreamName=stream['logStreamName'], nextToken=logs_batch['nextToken'])\n            for event in logs_batch['events']:\n                events.append(event)\n\n        # Return dataframe with log timestamp and message\n        df = (\n            pd.DataFrame(\n                map(\n                    lambda x: dict((k, v) for k, v in x.items()\n                                if k in ['timestamp', 'message']),\n                    events\n                )\n            )        \n        )\n        df['timestamp'] = df['timestamp'].apply(lambda x: gmt2rome(str(datetime.utcfromtimestamp(x/1000.)).split('.')[0], fmt='%Y-%m-%d %H:%M:%S'))\n        return df        \n\n\ndef get_log_groups(cloudwatch: boto3.client, prefix: str, env: Optional[str]) -&gt; list:\n    \"\"\"Retrieve log groups given prefix.\n\n    Args:\n        cloudwatch (boto3.client): cloudwatch client.\n        prefix (str): log group prefix.\n        env (Optional[str]): AWS environment.\n\n    Returns:\n        Matching log groups.\n    \"\"\"\n    group_batch = cloudwatch.describe_log_groups(logGroupNamePrefix=prefix)\n    all_groups = []\n    all_groups += group_batch['logGroups']\n    while 'nextToken' in group_batch:\n        group_batch = cloudwatch.describe_log_groups(\n            logGroupNamePrefix=prefix, nextToken=group_batch['nextToken'])\n        all_groups += group_batch['logGroups']\n    if env:\n        return list(filter(lambda x: f'-{env}' in x, map(lambda x: x['logGroupName'], all_groups)))\n    else:\n        return list(map(lambda x: x['logGroupName'], all_groups))\n\n\ndef _configure_aggrid(df: pd.DataFrame) -&gt; GridOptionsBuilder:\n    \"\"\"Configure AgGrid options.\n\n    Args:\n        df (pd.DataFrame): dataframe to display.\n\n    Returns:\n        Configured options builder.\n    \"\"\"\n    # Builder initialization\n    gb = GridOptionsBuilder.from_dataframe(df)\n    # Streamlit dark theme options\n    gb.configure_grid_options(\n        rowStyle={'color': '#FAFAFA', 'background': '#0E1117'})\n    # (Optional) custom js code to inject to conditionally highlight log records\n    # FIXME: as of now, unable to inject string to match via f-string\n    # due to AgGrid custom component error... defaults to 'ERROR'\n    highlight_style_jscode = JsCode('''\n    function(params) {\n        if (params.value.includes('ERROR')) {\n            return {\n                'color': 'white',\n                'backgroundColor': '#f63366'\n            }\n        } else {\n            return {\n                'color': 'white',\n                'backgroundColor': '#0E1117'\n            }\n        }\n    };\n    ''')\n    gb.configure_column(\"message\", cellStyle=highlight_style_jscode)\n    return gb\n\n\ndef display_logs(df: pd.DataFrame) -&gt; AgGrid:\n    \"\"\"Display logs via AgGrid.\n\n    Args:\n        df (pd.DataFrame): logs dataframe.\n\n    Returns:\n        AgGrid table.\n    \"\"\"\n    return AgGrid(\n        df,\n        gridOptions=_configure_aggrid(df).build(),\n        allow_unsafe_jscode=True\n    )\n\n\ndef load_sidebar():\n    with st.sidebar:\n        st.markdown('# \u2601\ufe0f AWS CloudWatch Logs')\n        profile = st.text_input('AWS named profile', value='')\n        try:\n            session = boto3.session.Session(\n                profile_name=profile,\n                region_name=os.environ.get('AWS_REGION', 'eu-central-1')\n                )\n            env = profile.split('-')[-1]\n            return env, session.client('logs')\n        except Exception as e:\n            st.error(e)\n            return None, None\n\n\ndef main():\n    env, cloudwatch = load_sidebar()\n    if env and cloudwatch:\n        cols = st.columns(2)\n        with cols[0]:\n            resource_type = st.text_input(\n                'Resource type', \n                help='AWS resource type as per log groups naming (e.g. `lambda`, `codebuild`, `ecs`, ...)'\n                )\n        with cols[1]:\n            resource_prefix = st.text_input(\n                'Common prefix',\n                help='Possible common prefix to resources (e.g. use case name)'\n                )\n        with cols[0]:\n            env = env if st.checkbox(f'Filter log groups containing -{env}') else None\n\n        if resource_type:\n            prefix = f'/aws/{resource_type}/'\n            if resource_prefix:\n                prefix += f'{resource_prefix}-'\n            matching_groups = get_log_groups(cloudwatch, prefix, env)\n            if matching_groups:\n                format_group = lambda x: x.replace(prefix, '').replace(f'-{env}', '')\n                log_group = st.selectbox(\n                    'Matching resources', \n                    options=matching_groups, \n                    format_func=format_group)\n\n                # Log display\n                last_logs = get_last_log(cloudwatch, log_group)\n                if last_logs is not None:\n                    st.markdown(f'## Most recent log for `{format_group(log_group)}`')\n                    display_logs(last_logs)\n                else:\n                    st.error(f\"No streams for log group `{log_group}`\")\n            else:\n                st.error('No matching log groups for given resource type and prefix.')\n\n\nif __name__ == \"__main__\":\n    st.set_page_config(page_title='AWS CloudWatch logs',\n                       page_icon='\u2601\ufe0f', layout='wide')\n    main()\n</code></pre>","tags":["AWS","Streamlit"]},{"location":"2021/10/15/how-to-display-aws-cloudwatch-logs-in-streamlit/#structure","title":"Structure","text":"<p>Given a virtual environment with the above requirements already installed and the AWS CLI installed and configured with (at least) a named profile, you should be good to go.</p> <p>Usage:</p> <ol> <li>in the sidebar you can insert the named profile name as per <code>~/.aws/credentials</code></li> <li>in the Resource type text input you can insert the \"type\" of resource whose logs you want to retrieve (e.g. lambda, ecs, ...)</li> <li>you can further filter logs by request a match with a common prefix</li> <li>matching resources will be available in the subsequent selectbox</li> <li>selected resource logs will be shown through AgGrid, with (possible) errors line highlighted by default</li> </ol>","tags":["AWS","Streamlit"]},{"location":"2021/12/21/aws-s3-presigned-urls/","title":"AWS S3 presigned URLs","text":"<p>Solutions to common problems when working with S3 presigned URLs.</p>","tags":["AWS"]},{"location":"2021/12/21/aws-s3-presigned-urls/#signaturedoesnotmatch-error","title":"<code>SignatureDoesNotMatch</code> error","text":"<p>The error can be spotted visiting presigned URL and receiving:</p> <pre><code>This XML file does not appear to have any style information associated with it. The document tree is shown below.\n&lt;Error&gt;\n&lt;Code&gt;SignatureDoesNotMatch&lt;/Code&gt;\n&lt;Message&gt;The request signature we calculated does not match the signature you provided. Check your key and signing method.&lt;/Message&gt;\n</code></pre> <p>A possible solution is given in this issue: specifying in s3 client configuration <code>s3={\u200b\u200b\u200b\u200b\u200b\u200b'addressing_style': 'virtual'}\u200b\u200b\u200b\u200b\u200b\u200b</code>.</p> <p>More on the topic here.</p>","tags":["AWS"]},{"location":"2021/12/21/aws-s3-presigned-urls/#credentials-and-expiration","title":"Credentials and expiration","text":"<p>Even if presigned URL creation lets you specify the URL duration via <code>ExpiresIn</code> parameter, you can experience different url durations, capped to 12 hours despite longer requested value.</p> <p>The reason behind such behaviour is that credentials used to create the presigned url take precedence - in terms of validity duration - over any parameters specified at creation time. At each authentication method corresponds a different timeout, which hits the maximum with of 7 days with access key e secret access key authentication.</p> <p>If a given presigned url has been created by a Lambda function with a standard role, it should have a <code>max_session_duration</code> which defaults to 1 hour. Despite this default, the CDK IAM Role docs states</p> <p>[...] Anyone who assumes the role from the AWS CLI or API can use the DurationSeconds API parameter or the duration-seconds CLI parameter to request a longer session. [...]</p> <p>As confirmed in this issue, boto3 S3 client - while creating a presigned url - performs a request for a temporary access token to STS, with a default <code>DurationSeconds</code> of 12 hours. Moreover, in this table, the only STS access methods with 12 hours default duration seem to be the ones involving tokens.</p>","tags":["AWS"]},{"location":"2021/12/21/build-lambda-layers-with-aws-sam/","title":"Build Lambda layers with AWS SAM","text":"<p>The AWS Serverless Application Model (AWS SAM) is an open-source framework that you can use to build serverless applications on AWS. A useful tutorial can be found here.</p> <p>Lambda layers builds can be automated through the code in aws-lambda-layer repo. The idea is forcing AWS SAM to build layers in the same way it builds Lambdas as described here and here.</p> <p>The SAM app structure should look like the following:</p> <pre><code>sam-app/\n\u2502\n\u251c\u2500\u2500 lambdas/\n\u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u251c\u2500\u2500 lambda_1.py\n\u2502   \u251c\u2500\u2500 lambda_2.py\n\u2502   \u2514\u2500\u2500 requirements.txt\n\u2502\n\u251c\u2500\u2500 layers/\n\u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u251c\u2500\u2500 dummy_lambda.py\n\u2502   \u2514\u2500\u2500 requirements.txt\n\u2502\n\u2514\u2500\u2500 template.yaml\n</code></pre> <p>You basically have to:</p> <ol> <li>define a dummy Lambda function in <code>template.yaml</code> with a related <code>requirements.txt</code> which is supposed to contain the packages to be included in the layer;</li> <li>define the related layer in <code>template.yaml</code> which ContentUri must point to the build path of the dummy lambda;</li> <li>modify any (actual) Lambda source code adding <code>sys.path.append('/opt')</code> before importing the required packages.</li> </ol> <p>The addition made in the template should look like this:</p> <pre><code>  DummyLambda:\n    Type: AWS::Serverless::Function\n    Properties:\n      CodeUri: layers/\n      Handler: dummy_lambda.lambda_handler\n  CustomLayer:\n    Type: AWS::Serverless::LayerVersion\n    Properties:\n      LayerName: CustomLayer\n      Description: Simple layer containing custom library\n      ContentUri: ./.aws-sam/build/DummyLambda\n      CompatibleRuntimes:\n        - python3.7\n        - python3.8\n        - python3.9\n      RetentionPolicy: Delete\n    DependsOn: DummyLambda\n</code></pre>","tags":["AWS"]},{"location":"2021/12/21/build-lambda-layers-with-aws-sam/#w-custom-local-module","title":"w/ custom local module","text":"<p>The following methods are possible ways to overcome errors related to the import of custom local scripts within AWS Lambda functions, such as <code>attempted relative import with no known parent package</code>, <code>attempted relative import beyond top-level package</code>, etc.</p> <p>Info</p> <p>Here you can find a complete overview of relative imports, difference between modules and scripts and more.</p> <p>In the simplest case in which the custom script <code>custom_script.py</code> is a dependency of just one Lambda, it is sufficient to put it in the lambdas folder, and importing it within the lambda source code with an implicit relative import as <code>from custom_script import stuff</code>. The project tree looks like the following:</p> <pre><code>sam-app/\n\u2502\n\u251c\u2500\u2500 lambda_1/\n\u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u251c\u2500\u2500 lambda_1.py\n\u2502   \u251c\u2500\u2500 custom_script.py\n\u2502   \u2514\u2500\u2500 requirements.txt\n\u2502\n\u251c\u2500\u2500 lambda_2/\n\u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u251c\u2500\u2500 lambda_2.py\n\u2502   \u2514\u2500\u2500 requirements.txt\n\u2502\n\u251c\u2500\u2500 layers/\n\u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u251c\u2500\u2500 dummy_lambda.py\n\u2502   \u2514\u2500\u2500 requirements.txt\n\u2502\n\u2514\u2500\u2500 template.yaml\n</code></pre> <p>For further reference see this gist.</p> <p>As of early 2020, it seems there's no standard/straightforward way to build a custom script as shared dependency across two or more lambdas. A possible workaround - inspired from this thread - consists in exploiting the (possibly already created) dummy lambda. Since SAM builds every lambda within the app root folder, you can put the custom script within dummy lambda folder, and import the script with an implicit relative import in the dummy lambda source code, such as <code>import custom_script</code>. When SAM builds the layer associated to the dummy lambda, your custom script will be included within the layer as well and can be served as dependecy across all lambdas.</p> <p>The project tree looks like the following:</p> <pre><code>sam-app/\n\u2502\n\u251c\u2500\u2500 lambda_1/\n\u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u251c\u2500\u2500 lambda_1.py\n\u2502   \u2514\u2500\u2500 requirements.txt\n\u2502\n\u251c\u2500\u2500 lambda_2/\n\u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u251c\u2500\u2500 lambda_2.py\n\u2502   \u2514\u2500\u2500 requirements.txt\n\u2502\n\u251c\u2500\u2500 layers/\n\u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u251c\u2500\u2500 dummy_lambda.py\n\u2502   \u251c\u2500\u2500 custom_script.py\n\u2502   \u2514\u2500\u2500 requirements.txt\n\u2502\n\u2514\u2500\u2500 template.yaml\n</code></pre>","tags":["AWS"]},{"location":"2022/10/13/best-practices-per-aws-cdk-l3-constructs/","title":"Best practices per AWS CDK L3 constructs","text":"<p>Nell'utilizzo avanzato di AWS CDK, si realizza prima o poi l'esigenza di centralizzare alcune logiche e risorse in maniera da poterle riutilizzare in maniera rapida, riducendo il codice boilerplate. Anche se una prima analisi potrebbe suggerire che la soluzione sia l'implementazione di una \"casalinga\" factory - pythonica s\u00ec, ma non conforme alle best practices di CDK - la risposta probabilmente pi\u00f9 corretta potrebbe riguardare l'implementazione di un costrutto L3, descritto come:</p> <p>designed to help you complete common tasks in AWS, often involving multiple kinds of resources.</p>","tags":["ITA","AWS","IaC"]},{"location":"2022/10/13/best-practices-per-aws-cdk-l3-constructs/#implementazione","title":"Implementazione","text":"<p>Per cercare di aderire il pi\u00f9 possibile alla CDK-way nella gestione dei costrutti, \u00e8 utile ispirarsi al sorgente di patterns built-in, come ad esempio LambdaRestApi. Prendere ispirazione non sempre \u00e8 un'attivit\u00e0 lineare, visto che a forza di scavare under the hood prima o poi ci si scontra con la traduzione operata da jsii, ma le best practices che \u00e8 possibile estrapolare si possono ridurre a:</p> <ol> <li>il costrutto L3 che si vuole implementare deve estendere la classe <code>Construct</code>, es. <code>class Pattern(Construct)</code></li> <li>la configurazione del costrutto avviene tramite <code>kwargs</code>, passati esplicitamente nell'<code>__init__</code> della classe</li> <li>le logiche di gestione e validazione della configurazione di un costrutto vanno separate dalla classe che implementa il costrutto stesso, in una  classe ad hoc che ne eredita il nome con il suffix Props, es. <code>class PatternProps</code></li> <li>la classe che gestisce la configurazione si occupa di validare gli input ricevuti e settarli come managed attributes via <code>@property</code></li> <li>dopo aver wrappato le configurazioni nella classe deputata, esse vengono bindate alla classe che definisce il costrutto, che viene anche \"triggerata\" (a deploy-time) tramite un metodo <code>create</code></li> </ol> PatternPatternPropsBasePropscheck_type <pre><code>from constructs import Construct\n\n\nclass Pattern(Construct):\n\n    def __init__(self,\n                 scope: Construct,\n                 id: str,\n                 *,\n                 ... # kwargs only!\n                 ):\n        super().__init__(scope, id)\n\n        # Register properties\n        PatternProps(...).register(self)\n</code></pre> <pre><code>class PatternProps(BaseProps):\n\n    def __init__(self,\n                *,\n                ... # &lt;- kwarg_1_name=kwarg_1_value, ...\n                ) -&gt; None:\n\n        self._values = dict()\n        self._values['kwarg_1_name'] = kwarg_1_value\n        ...\n\n    @property\n    def kwarg_1_name(self) -&gt; ...:\n        result = self._values.get('kwarg_1_name')\n        check_type(\n            attr='kwarg_1_name',\n            value=result,\n            expected_types=...,                \n        )\n        return result\n</code></pre> <pre><code>class BaseProps:\n\n    def __init__(self) -&gt; None:\n        pass\n\n    def register(self, other: object) -&gt; None:\n        for attr in self._values:\n            setattr(other, attr, getattr(self, attr))\n</code></pre> <pre><code>from typing import Any, Tuple\n\nJSII_TYPE_ATTR = '__jsii_type__'\n\n\ndef check_type(attr: str,\n               value: object,\n               expected_types: Tuple[Any],\n               skip_if_missing: bool\n               ) -&gt; None:\n    if skip_if_missing and value is None:\n        return\n    else:\n        if hasattr(expected_types[0], JSII_TYPE_ATTR):\n            _expected_types = list(\n                map(lambda x: getattr(x, JSII_TYPE_ATTR), expected_types))\n            if (not hasattr(value, JSII_TYPE_ATTR)) or (getattr(value, JSII_TYPE_ATTR) not in _expected_types):\n                _type = getattr(value, JSII_TYPE_ATTR) if hasattr(\n                    value, JSII_TYPE_ATTR) else type(value)\n                raise TypeError(\n                    f\"Property '{attr}' type must be in {_expected_types}, received a {_type}.\")\n        else:\n            if not isinstance(value, expected_types):\n                raise TypeError(\n                    f\"Property '{attr}' type must be in {expected_types}, received a {type(value)}.\")\n</code></pre> Warning <p>Una scelta apparentemente naturale per organizzare i costrutti nella codebase potrebbe essere di inserirli in un folder <code>/constructs</code>, come nella seguente alberatura:</p> <pre><code>/infra\n    /constructs\n        __init__.py\n        my_construct.py\n    /stacks\n        __init__.py\n        my_stack.py\n    app.py\n    cdk.json\n/src\n    ...\n</code></pre> <p>Con una configurazione come quella sopra, purtroppo, a deploy-time ci si scontra con l'errore <code>ModuleNotFoundError: No module named 'constructs._jsii'</code>. A fare chiarezza ci pensa questa issue: essenzialmente, nel folder in cui si esegue <code>cdk deploy</code> non pu\u00f2 esserci un folder con nome \"constructs\".</p>","tags":["ITA","AWS","IaC"]},{"location":"2022/10/13/best-practices-per-aws-cdk-l3-constructs/#utilizzo","title":"Utilizzo","text":"<p>Una volta creato il costrutto, si pu\u00f2 utilizzare esattamente come gli altri costrutti L1, L2 e L3 nativi, ovvero istanziandolo in uno stack fornendogli quindi uno scope (il <code>self</code> dello stack stesso), un id e gli eventuali parametri di configurazione.</p> <pre><code>from aws_cdk import Stack as BaseStack\nfrom infra.patterns import Pattern\n\nclass Stack(BaseStack):\n\n    def __init__(self,\n                 scope: Construct,\n                 construct_id: str,\n                 **kwargs) -&gt; None:        \n        super().__init__(scope, construct_id, **kwargs)\n\n        Pattern(\n            self,\n            id=...,\n            ...\n        )\n</code></pre>","tags":["ITA","AWS","IaC"]},{"location":"2022/10/13/best-practices-per-aws-cdk-l3-constructs/#takeaway","title":"Takeaway","text":"<p>L'esperienza di refactoring di parti di codice CDK utilizzate spesso in costrutti L3 \u00e8 decisamente consigliabile: \u00e8 senz'altro time-consuming (per lo meno la prima volta) e rischia di sembrare fine a se stessa, ma oltre che educativa consegna al termine un codice di pi\u00f9 facile manutenzione e, soprattutto, riutilizzabile!<sup>1</sup>.</p> <p>Trasformare in costrutti gli snippets che vengono continuamente riciclati da un progetto all'altro permette di standardizzare le best practices del proprio lavoro, ed effettuare il design di una applicazione CDK per costrutti anzich\u00e8 per stack permette inoltre di aderire ad un'altra best practice di CDK, ovvero:</p> <p>composition is preferred over inheritance when developing AWS CDK constructs.<sup>2</sup></p>","tags":["ITA","AWS","IaC"]},{"location":"2022/10/13/best-practices-per-aws-cdk-l3-constructs/#resources","title":"Resources","text":"<ul> <li>https://blog.phillipninan.com/a-no-nonsense-guide-to-aws-cloud-development-kit-cdk</li> <li>https://blog.phillipninan.com/when-to-use-aws-cdk-constructs-vs-stacks</li> <li>https://blog.phillipninan.com/insider-secrets-of-aws-cdk-the-base-stack</li> <li>https://aws-blog.com/2020/09/deployment-issues-with-cross-stack-dependencies-and-the-cdk.html</li> <li>https://bobbyhadz.com/blog/cdk-constructs-tutorial</li> </ul> <ol> <li> <p>Essenzialmente perch\u00e8 \"sganciato\" da logiche puntuali di un dato stack.\u00a0\u21a9</p> </li> <li> <p>Come indicato qui e qui.\u00a0\u21a9</p> </li> </ol>","tags":["ITA","AWS","IaC"]},{"location":"2022/01/05/how-to-survive-a-forced-reset-of-local-development-environment/","title":"How to survive a forced reset of local development environment","text":""},{"location":"2022/01/05/how-to-survive-a-forced-reset-of-local-development-environment/#cmder","title":"cmder","text":""},{"location":"2022/01/05/how-to-survive-a-forced-reset-of-local-development-environment/#startuptasks","title":"Startup/Tasks","text":"<ul> <li>Task parameters: <code>/dir \"C:\\Users\\USERNAME\\Documents\\projects\"</code>.</li> <li>Cmd: <code>cmd -new_console:s /k \"\"%ConEmuDir%\\..\\init.bat\" \" &amp; C:\\Users\\USERNAME\\AppData\\Local\\Continuum\\anaconda3\\Scripts\\activate.bat C:\\Users\\USERNAME\\AppData\\Local\\Continuum\\anaconda3</code></li> </ul>"},{"location":"2022/01/05/how-to-survive-a-forced-reset-of-local-development-environment/#configuser_aliasescmd","title":"config/user_aliases.cmd","text":"<pre><code>conda-activate = C:/Users/USERNAME/Miniconda3/Scripts/activate.bat $*\nact-env = make activate-env\nuc11 = cd IAM/uc11-justiren\nuc11-env = cd IAM/uc11-justiren &amp; make activate-env\naws-login = pushd . &amp;&amp; cd C:/Users/USERNAME/Documents/projects/advana/advana-aws-iren-temp-credential-docker/aws_cli_temporary_credentials/Docker/container-mode-advana &amp;&amp; make docker-run ACCOUNT=$1 -n &amp;&amp; popd\n</code></pre>"},{"location":"2022/01/05/how-to-survive-a-forced-reset-of-local-development-environment/#gnu-make","title":"GNU Make","text":"<code>config.mk</code> <pre><code>include .env\nexport $(cat .env)\n\n# split AWS_PROFILE to get AWS_ENV\nPROFILE = $(shell echo $(AWS_PROFILE) | cut -f3 -d\"-\")\n\nENV_NAME = ... # conda env name\nCLIP_MESSAGE = \"Command stored! You can past and run it in the CLI.\"\nSECRET_MESSAGE = \"Secret stored!\"\nPY_VERSION = 3.8\nAWS_SECRET = ...\nSECRET_FIELD = ...\nAPP = ...\nSTACKS = ...\nAWS_ENV = ...-$(PROFILE)\n...\n</code></pre> <code>Makefile</code> <pre><code>include config.mk\n## \n## -------------------------------------------\n## |                Makefile                 |\n## -------------------------------------------\n## \n## create-env\n##     initialize python virtual environment (LAUNCH FROM BASE ENV!)\n.PHONY: create-env\ncreate-env:\n    @echo $(CLIP_MESSAGE)\n    @echo \"conda create --name $(ENV_NAME) python=$(PY_VERSION)\" | clip\n## \n## unregister-env\n##     unregister virtual environment in jupyter suite (LAUNCH FROM BASE ENV!)\n.PHONY: unregister-env\nunregister-env:\n    jupyter kernelspec uninstall $(ENV_NAME)\n## \n## activate-env\n##     activate python virtual environment\n.PHONY: activate-env\nactivate-env:\n    @echo $(CLIP_MESSAGE)\n    @echo \"conda-activate $(ENV_NAME)\" | clip\n## \n## init-env\n##     initialize miniconda environment installing pip\n.PHONY: init-env\ninit-env:\n    @echo $(CLIP_MESSAGE)\n    @echo \"conda install pip\" | clip\n## \n## init\n##     initialize package basic dependencies\n.PHONY: init\ninit:\n    python -m pip install -r ./requirements.txt\n## \n## register-env\n##     register virtual environment in jupyter suite\n.PHONY: register-env\nregister-env:\n    python -m ipykernel install --user --name=$(ENV_NAME)\n## \n## reqs\n##     save requirements.txt with pipreqs\n.PHONY: reqs\nreqs:\n    pipreqs ./ --encoding latin --ignore cdk-app,notebook,data\n## \n## install-package\n##     install python package in edit mode\n.PHONY: install-package\ninstall-package:\n    python -m pip install -e .\n## \n## st-run [APP]\n##     run streamlit app\n##     APP=sandbox or monitor\n.PHONY: st-run\nst-run:\n    cd ./dashboard &amp;&amp; streamlit run $(APP).py\n## \n## docs-serve\n##     serve package docs on localhost\n.PHONY: docs-serve\ndocs-serve:\n    mkdocs serve\n## \n## docs-build\n##     build package docs as static html website\n.PHONY: docs-build\ndocs-build:\n    mkdocs build --no-directory-urls\n## \n## test\n##     execute tests with pytest and dump html report\n.PHONY: test\ntest:\n    cd tests &amp;&amp; pytest\n##\n## cdk-deploy [PROFILE, STACKS | STACK]\n##     deploy cdk app\n##     PROFILE=dev, test or prod\n##     STACKS='*'\n##     STACK=stack suffix name\n.PHONY: cdk-deploy\ncdk-deploy:\n    cd ./cdk-app &amp;&amp; cdk deploy $(STACKS) --profile $(AWS_ENV)\n## \n## st-pswd [PROFILE, USER]\n##     retrieve password to connect to Streamlit app\n##     PROFILE=dev, test or prod\n##     USER=advana, business or cartografia\n.PHONY: st-pswd\nst-pswd:\n    @echo AWS_PROFILE: $(AWS_ENV)\n    @aws secretsmanager get-secret-value --secret-id $(AWS_SECRET) --profile $(AWS_ENV) \\\n    | jq '.SecretString' \\\n    | awk '{print substr($$0,2,length($$0)-2)}' \\\n    | sed 's|[\\\\]||g' \\\n    | jq '.$(SECRET_FIELD)' \\\n    | sed 's|[\"]||g' \\\n    | clip\n    @echo $(CLIP_MESSAGE)\n## \n## gource-play\n##     shows git history as gource animation\n.PHONY: gource-play\ngource-play:\n    git log --pretty=format:\"%at|%s\" --reverse --no-merges &gt; gource-caption.txt \\\n    &amp;&amp; gource --key \\\n    --user-image-dir 'PATH_TO_AVATARS' \\\n    --seconds-per-day 1 \\\n    --auto-skip-seconds 2 \\\n    --title \"TITLE\" \\\n    --caption-file gource-caption.txt \\\n    --caption-offset -90 \\\n    --caption-duration 4 \\\n    --logo 'PATH_TO_LOGO' \\\n    --logo-offset 50x1050 -f\n## \n## gource-build\n##     save git history as gource video\n.PHONY: gource-build\ngource-build:\n    git log --pretty=format:\"%at|%s\" --reverse --no-merges &gt; gource-caption.txt \\\n    &amp;&amp; gource --key \\\n    --user-image-dir 'PATH_TO_AVATARS' \\\n    --seconds-per-day .5 \\\n    --auto-skip-seconds 1 \\\n    --title \"TITLE\" \\\n    --caption-file gource-caption.txt \\\n    --caption-offset -90 \\\n    --caption-duration 2 \\\n    --logo 'PATH_TO_LOGO' \\\n    --logo-offset 50x1050 -f \\\n    -o gource.ppm \\\n    &amp;&amp; ffmpeg \\\n    -y \\\n    -r 60 \\\n    -f image2pipe \\\n    -vcodec ppm \\\n    -i gource.ppm \\\n    -vcodec libx264 \\\n    -preset ultrafast \\\n    -pix_fmt yuv420p \\\n    -crf 17 \\\n    -threads 0 \\\n    -bf 0 development-history.mp4 \\\n    &amp;&amp; rm gource.ppm\n## \n## help\n##     show this help\n.PHONY: help\nhelp: Makefile\n    @sed -n 's/^## //p' $&lt;\n</code></pre>"},{"location":"2022/01/05/how-to-survive-a-forced-reset-of-local-development-environment/#jupyterlab-extensions","title":"JupyterLab Extensions","text":"<ul> <li>jupyterlab-execute-time</li> <li>@aquirdturtle/collapsible_headings</li> <li>jupyterlab-chart-editor</li> <li>jupyterlab-plotly</li> <li>jupyterlab-tailwind-theme</li> <li>simpledark</li> </ul>"},{"location":"2022/01/05/how-to-survive-a-forced-reset-of-local-development-environment/#visual-studio-code","title":"Visual Studio Code","text":"<code>settings.json</code> <pre><code>{\n    \"telemetry.telemetryLevel\": \"off\",\n    \"workbench.colorTheme\": \"Dracula\",\n    \"python.pythonPath\": \"C:\\\\Users\\\\USERNAME\\\\Miniconda3\\\\envs\\\\ENV\\\\python.exe\",\n    \"workbench.colorCustomizations\": {\n\n\n    },\n      \"editor.semanticTokenColorCustomizations\": {\n          \"[Dracula Soft]\": { // Apply to this theme only\n              \"enabled\": false,\n              \"rules\": {\n                  \"magicFunction:python\": \"#ee0000\",\n                  \"function.declaration:python\": \"#87E570\",\n                  \"class.declaration:python\": \"#87E570\",\n                  \"function.call.python\": \"#66D9EF\",\n                  \"*.decorator:python\": \"#0000dd\",\n                  \"*.typeHint:python\": \"#6ED5D3\",\n                  \"*.typeHintComment:python\": \"#aaaaaa\"\n              }\n          }\n      },\n    \"editor.tokenColorCustomizations\": {\n        \"textMateRules\": [\n          {\n            \"scope\": \"meta.function-call.generic.python\",\n            \"settings\": {\n              \"foreground\": \"#66D9EF\"\n            }\n          },\n          {\n            \"scope\": [\"string.quoted.docstring.multi.python\", \"punctuation.definition.string.begin.python\", \"punctuation.definition.string.end.python\"],\n            \"settings\":{\n              \"foreground\": \"#E7EE98\"\n            }\n          }\n        ]\n      },\n      \"workbench.editorAssociations\": {\n        \"*.ipynb\": \"jupyter-notebook\"\n      },\n      \"python.languageServer\": \"Pylance\",\n      \"codetags.custom\": [\n      {\"name\": \"see\", \"body\": \"For reference see [here]()\"}\n      ],\n      \"todohighlight.keywords\": [{\n        \"text\": \"SEE\",\n        \"backgroundColor\": \"#282A36\",\n        \"overviewRulerColor\": \"grey\"\n    },\n  ],\n  \"todo-tree.tree.showScanModeButton\": false,\n  \"todo-tree.highlights.enabled\": false,\n  \"files.eol\": \"\\n\",\n  \"todo-tree.general.tags\": [\n    \"BUG\",\n    \"HACK\",\n    \"FIXME\",\n    \"TODO\",\n    \"XXX\",\n    \"[ ]\",\n    \"[x]\"\n  ],\n  \"todo-tree.regex.regex\": \"(//|#|&lt;!--|;|/\\\\*|^|^\\\\s*(-|\\\\d+.))\\\\s*($TAGS)\",\n  \"security.workspace.trust.untrustedFiles\": \"open\",\n  \"notebook.cellToolbarLocation\": {\n    \"default\": \"right\",\n    \"jupyter-notebook\": \"left\"\n  },\n  \"aws.profile\": \"profile:AWS_PROFILE\",\n  \"aws.sam.enableCodeLenses\": false,\n  \"gitlens.hovers.currentLine.over\": \"line\",\n  \"gitlens.codeLens.enabled\": false,\n  \"json.schemas\": [],\n  \"terminal.integrated.profiles.windows\": {\n    \"PowerShell\": {\n      \"source\": \"PowerShell\",\n      \"icon\": \"terminal-powershell\"\n    },\n    \"Command Prompt\": {\n      \"path\": [\n        \"${env:windir}\\\\Sysnative\\\\cmd.exe\",\n        \"${env:windir}\\\\System32\\\\cmd.exe\"\n      ],\n      \"args\": [],\n      \"icon\": \"terminal-cmd\"\n    },\n    \"Git Bash\": {\n      \"source\": \"Git Bash\"\n    },\n      \"cmder\": {\n        \"path\": [\n          \"${env:windir}\\\\Sysnative\\\\cmd.exe\",\n          \"${env:windir}\\\\System32\\\\cmd.exe\"\n        ],\n        \"args\": [\"/k\", \"C:/Users/USERNAME/Documents/projects/cmder_mini/vendor/init.bat\"],\n        \"overrideName\": true,\n        \"icon\": \"pulse\",\n        \"color\": \"terminal.ansiGreen\"\n      }\n    },\n    \"terminal.integrated.defaultProfile.windows\": \"cmder\",\n    \"mypy.dmypyExecutable\": \"C:\\\\Users\\\\USERNAME\\\\.mypyls\\\\Scripts\\\\dmypy.exe\"\n}\n</code></pre>"},{"location":"2022/01/05/how-to-survive-a-forced-reset-of-local-development-environment/#extensions","title":"Extensions","text":"<ul> <li>Ace Palenight theme</li> <li>AWS Toolkit</li> <li>Better Jinja</li> <li>Better TOML</li> <li>codetags</li> <li>Docker</li> <li>Dracula Official</li> <li>Excel Viewer</li> <li>Git Graph</li> <li>GitLens</li> <li>Jupyter</li> <li>Jupyter Keymap</li> <li>Jupyter Notebook Renderers</li> <li>Markdown Preview Enhanced</li> <li>markdownlint</li> <li>Notepad++ keymap</li> <li>Pylance</li> <li>Python</li> <li>Python Docstring Generator</li> <li>Remote - Containers</li> <li>Remote - WSL</li> <li>TODO Highlight</li> <li>Todo Tree</li> </ul>"},{"location":"2022/01/05/how-to-survive-a-forced-reset-of-local-development-environment/#key-bindings","title":"Key bindings","text":"<ul> <li>To switch focus between editor and terminal, please refer to this thread</li> </ul>"},{"location":"2022/01/05/how-to-survive-a-forced-reset-of-local-development-environment/#windows-terminal","title":"Windows Terminal","text":"<code>settings.json</code> <pre><code>{\n    \"$schema\": \"https://aka.ms/terminal-profiles-schema\",\n    \"actions\": \n    [\n        // {\n        //     \"command\": \n        //     {\n        //         \"action\": \"copy\",\n        //         \"singleLine\": false\n        //     },\n        //     \"keys\": \"ctrl+c\"\n        // },\n        {\n            \"command\": \"paste\",\n            \"keys\": \"ctrl+v\"\n        },\n        {\n            \"command\": \"find\",\n            \"keys\": \"ctrl+shift+f\"\n        },\n        {\n            \"command\": \n            {\n                \"action\": \"splitPane\",\n                \"split\": \"auto\",\n                \"splitMode\": \"duplicate\"\n            },\n            \"keys\": \"alt+shift+d\"\n        },\n        {\n            \"command\": \n            {\n                \"action\": \"splitPane\",\n                \"profile\": \"Node.js\",\n                \"split\": \"auto\"\n            },\n            \"keys\": \"ctrl+alt+n\"\n        },\n        {\n            \"command\": \n            {\n                \"action\": \"splitPane\",\n                \"profile\": \"Ubuntu-18.04\",\n                \"split\": \"auto\"\n            },\n            \"keys\": \"ctrl+alt+u\"\n        },\n        {\n            \"command\": \n            {\n                \"action\": \"splitPane\",\n                \"profile\": \"PowerShell 7\",\n                \"split\": \"auto\"\n            },\n            \"keys\": \"ctrl+alt+s\"\n        }\n    ],\n    \"alwaysOnTop\": false,\n    \"copyFormatting\": \"none\",\n    \"copyOnSelect\": false,\n    \"defaultProfile\": \"{5b4ef9a8-4506-4ac9-930a-5eb1fd0ebf20}\",\n    \"multiLinePasteWarning\": false,\n    \"profiles\": \n    {\n        \"defaults\": \n        {\n            \"startingDirectory\": \"C:/Users/USERNAME/Documents/projects/\"\n        },\n        \"list\": \n        [\n            {\n                \"commandline\": \"powershell.exe\",\n                \"guid\": \"{61c54bbd-c2c6-5271-96e7-009a87ff44bf}\",\n                \"hidden\": false,\n                \"name\": \"Windows PowerShell\"\n            },\n            {\n                \"commandline\": \"cmd.exe\",\n                \"guid\": \"{0caa0dad-35be-5f56-a8ff-afceeeaa6101}\",\n                \"hidden\": false,\n                \"name\": \"Command Prompt\"\n            },\n            {\n                \"guid\": \"{b453ae62-4e3d-5e58-b989-0a998ec441b8}\",\n                \"hidden\": false,\n                \"name\": \"Azure Cloud Shell\",\n                \"source\": \"Windows.Terminal.Azure\"\n            },\n            {\n                \"colorScheme\": \"synthwave-everything\",\n                \"guid\": \"{c6eaf9f4-32a7-5fdc-b5cf-066e8a4b1e40}\",\n                \"hidden\": false,\n                \"name\": \"Ubuntu-18.04\",\n                \"source\": \"Windows.Terminal.Wsl\"\n            },\n            {\n                \"backgroundImage\": \"PATH_TO_IMAGE\",\n                \"backgroundImageAlignment\": \"right\",\n                \"backgroundImageOpacity\": 0.20000000000000001,\n                \"backgroundImageStretchMode\": \"uniform\",\n                \"colorScheme\": \"Sakura\",\n                \"commandline\": \"cmd.exe /k C:/Users/USERNAME/Documents/projects/cmder_mini/vendor/init.bat &amp;&amp; C:/Users/USERNAME/Miniconda3/Scripts/activate.bat C:/Users/USERNAME/Miniconda3\",\n                \"guid\": \"{5b4ef9a8-4506-4ac9-930a-5eb1fd0ebf20}\",\n                \"hidden\": false,\n                \"icon\": \" C:/Users/USERNAME/Documents/projects/cmder_mini/icons/cmder.ico\",\n                \"name\": \"Cmder\",\n                \"cursorShape\": \"vintage\"\n            },\n            {\n                \"commandline\": \"C:/Program Files/nodejs/node.exe\",\n                \"icon\": \"C:/Program Files/nodejs/node_modules/npm/docs/public/icons/icon-48x48.png\",\n                \"name\": \"Node.js\"\n            },\n            {\n                \"commandline\": \"C:/Users/USERNAME/Documents/projects/PowerShell-7.1.0-win-x64/pwsh.exe\",\n                \"icon\": \"C:/Users/USERNAME/Documents/projects/PowerShell-7.1.0-win-x64/assets/Square150x150Logo.png\",\n                \"name\": \"PowerShell 7\"\n            }\n        ]\n    },\n    \"schemes\": \n    [\n        {\n            \"name\": \"NightLionV2\",\n            \"black\": \"#4c4c4c\",\n            \"red\": \"#bb0000\",\n            \"green\": \"#04f623\",\n            \"yellow\": \"#f3f167\",\n            \"blue\": \"#64d0f0\",\n            \"purple\": \"#ce6fdb\",\n            \"cyan\": \"#00dadf\",\n            \"white\": \"#bbbbbb\",\n            \"brightBlack\": \"#555555\",\n            \"brightRed\": \"#ff5555\",\n            \"brightGreen\": \"#7df71d\",\n            \"brightYellow\": \"#ffff55\",\n            \"brightBlue\": \"#62cbe8\",\n            \"brightPurple\": \"#ff9bf5\",\n            \"brightCyan\": \"#00ccd8\",\n            \"brightWhite\": \"#ffffff\",\n            \"background\": \"#171717\",\n            \"foreground\": \"#bbbbbb\",\n            \"selectionBackground\": \"#b5d5ff\",\n            \"cursorColor\": \"#bbbbbb\"\n          },\n        {\n            \"name\": \"Sakura\",\n            \"black\": \"#000000\",\n            \"red\": \"#d52370\",\n            \"green\": \"#41af1a\",\n            \"yellow\": \"#bc7053\",\n            \"blue\": \"#6964ab\",\n            \"purple\": \"#c71fbf\",\n            \"cyan\": \"#939393\",\n            \"white\": \"#998eac\",\n            \"brightBlack\": \"#786d69\",\n            \"brightRed\": \"#f41d99\",\n            \"brightGreen\": \"#22e529\",\n            \"brightYellow\": \"#f59574\",\n            \"brightBlue\": \"#9892f1\",\n            \"brightPurple\": \"#e90cdd\",\n            \"brightCyan\": \"#eeeeee\",\n            \"brightWhite\": \"#cbb6ff\",\n            \"background\": \"#18131e\",\n            \"foreground\": \"#dd7bdc\",\n            \"selectionBackground\": \"#c05cbf\",\n            \"cursorColor\": \"#ff65fd\"\n          },\n        {\n            \"name\": \"Laser\",\n            \"black\": \"#626262\",\n            \"red\": \"#ff8373\",\n            \"green\": \"#b4fb73\",\n            \"yellow\": \"#09b4bd\",\n            \"blue\": \"#fed300\",\n            \"purple\": \"#ff90fe\",\n            \"cyan\": \"#d1d1fe\",\n            \"white\": \"#f1f1f1\",\n            \"brightBlack\": \"#8f8f8f\",\n            \"brightRed\": \"#ffc4be\",\n            \"brightGreen\": \"#d6fcba\",\n            \"brightYellow\": \"#fffed5\",\n            \"brightBlue\": \"#f92883\",\n            \"brightPurple\": \"#ffb2fe\",\n            \"brightCyan\": \"#e6e7fe\",\n            \"brightWhite\": \"#ffffff\",\n            \"background\": \"#030d18\",\n            \"foreground\": \"#f106e3\",\n            \"selectionBackground\": \"#2e206a\",\n            \"cursorColor\": \"#00ff9c\"\n          },\n          {\n            \"name\": \"Aurelia\",\n            \"background\": \"#1A1A1A\",\n            \"black\": \"#000000\",\n            \"blue\": \"#579BD5\",\n            \"brightBlack\": \"#797979\",\n            \"brightBlue\": \"#9CDCFE\",\n            \"brightCyan\": \"#2BC4E2\",\n            \"brightGreen\": \"#1AD69C\",\n            \"brightPurple\": \"#975EAB\",\n            \"brightRed\": \"#EB2A88\",\n            \"brightWhite\": \"#EAEAEA\",\n            \"brightYellow\": \"#E9AD95\",\n            \"cursorColor\": \"#FFFFFF\",\n            \"cyan\": \"#00B6D6\",\n            \"foreground\": \"#EA549F\",\n            \"green\": \"#4EC9B0\",\n            \"purple\": \"#714896\",\n            \"red\": \"#E92888\",\n            \"selectionBackground\": \"#FFFFFF\",\n            \"white\": \"#EAEAEA\",\n            \"yellow\": \"#CE9178\"\n        },\n          {\n            \"name\": \"Horizon\",\n            \"black\": \"#0a0a0d\",\n            \"red\": \"#E95678\",\n            \"green\": \"#29D398\",\n            \"yellow\": \"#FAB795\",\n            \"blue\": \"#26BBD9\",\n            \"purple\": \"#EE64AC\",\n            \"cyan\": \"#59E1E3\",\n            \"white\": \"#e5e5e5\",\n            \"brightBlack\": \"#848484\",\n            \"brightRed\": \"#EC6A88\",\n            \"brightGreen\": \"#3FDAA4\",\n            \"brightYellow\": \"#FBC3A7\",\n            \"brightBlue\": \"#3FC4DE\",\n            \"brightPurple\": \"#F075B5\",\n            \"brightCyan\": \"#6BE4E6\",\n            \"brightWhite\": \"#e5e5e5\",\n            \"background\": \"#1c1e26\",\n            \"foreground\": \"#bdc0c2\"\n          },\n        {\n            \"name\": \"synthwave-everything\",\n            \"black\": \"#fefefe\",\n            \"red\": \"#f97e72\",\n            \"green\": \"#72f1b8\",\n            \"yellow\": \"#fede5d\",\n            \"blue\": \"#6d77b3\",\n            \"purple\": \"#c792ea\",\n            \"cyan\": \"#f772e0\",\n            \"white\": \"#fefefe\",\n            \"brightBlack\": \"#fefefe\",\n            \"brightRed\": \"#f88414\",\n            \"brightGreen\": \"#72f1b8\",\n            \"brightYellow\": \"#fff951\",\n            \"brightBlue\": \"#36f9f6\",\n            \"brightPurple\": \"#e1acff\",\n            \"brightCyan\": \"#f92aad\",\n            \"brightWhite\": \"#fefefe\",\n            \"background\": \"#2a2139\",\n            \"foreground\": \"#f0eff1\",\n            \"selectionBackground\": \"#181521\",\n            \"cursorColor\": \"#72f1b8\"\n          },\n          {\n            \"name\": \"Dracula\",\n            \"black\": \"#000000\",\n            \"red\": \"#ff5555\",\n            \"green\": \"#50fa7b\",\n            \"yellow\": \"#f1fa8c\",\n            \"blue\": \"#bd93f9\",\n            \"purple\": \"#ff79c6\",\n            \"cyan\": \"#8be9fd\",\n            \"white\": \"#bbbbbb\",\n            \"brightBlack\": \"#555555\",\n            \"brightRed\": \"#ff5555\",\n            \"brightGreen\": \"#50fa7b\",\n            \"brightYellow\": \"#f1fa8c\",\n            \"brightBlue\": \"#bd93f9\",\n            \"brightPurple\": \"#ff79c6\",\n            \"brightCyan\": \"#8be9fd\",\n            \"brightWhite\": \"#ffffff\",\n            \"background\": \"#1e1f29\",\n            \"foreground\": \"#f8f8f2\",\n            \"selectionBackground\": \"#44475a\",\n            \"cursorColor\": \"#bbbbbb\"\n          }\n    ],\n    \"theme\": \"dark\"\n}\n</code></pre>"},{"location":"2022/01/05/how-to-survive-a-forced-reset-of-local-development-environment/#tools","title":"Tools","text":"<ul> <li>cmder</li> <li>draw.io</li> <li>Sourcetree</li> <li>StackEdit</li> <li>Sublime Text</li> <li>Trello</li> <li>Visual Studio Code</li> <li>Windows Terminal</li> <li>WSL2</li> <li>Lightshot</li> <li>Just Color Picker</li> </ul>"},{"location":"2022/01/05/how-to-survive-a-forced-reset-of-local-development-environment/#bookmarks","title":"Bookmarks","text":""},{"location":"2022/01/05/how-to-survive-a-forced-reset-of-local-development-environment/#libraries","title":"Libraries","text":"<ul> <li>AWS CDK</li> <li>OR-Tools</li> <li>pyjanitor</li> <li>Apache Echarts</li> <li>Streamlit changelog</li> </ul>"},{"location":"2022/01/05/how-to-survive-a-forced-reset-of-local-development-environment/#press-review","title":"Press review","text":"<ul> <li>discuss.streamlit</li> <li>Practical Business Python</li> <li>StackOverflow Blog</li> <li>Quanta Magazine</li> <li>Integrable Differentials</li> <li>Domino Data Science blog</li> <li>Netflix Technology Blog</li> <li>Linkedin Engineering</li> <li>O'Reilly Radar</li> <li>Towards AI</li> <li>TowardsDataScience</li> </ul>"},{"location":"2022/01/05/how-to-survive-a-forced-reset-of-local-development-environment/#misc","title":"Misc","text":"<ul> <li>Coolors palette generator</li> <li>Streamlit emoji</li> <li>Streamlitopedia</li> <li>pwdhash</li> <li>matplotlib colors</li> <li>matplotlib colormaps</li> <li>JSON formatter</li> <li>Unicode table</li> <li>Fontawesome icons</li> <li>Markdown guide</li> <li>Bootstrap icons</li> </ul>"},{"location":"2022/01/05/how-to-survive-a-forced-reset-of-local-development-environment/#macos","title":"macOS","text":"<ul> <li>How to setup Python on ARM machines</li> <li>MacOS terminal makeover</li> <li>How to dedup conda env name in terminal</li> <li>Warp terminal</li> </ul>"},{"location":"2022/01/05/how-to-survive-a-forced-reset-of-local-development-environment/#troubleshooting","title":"Troubleshooting","text":""},{"location":"2022/01/05/how-to-survive-a-forced-reset-of-local-development-environment/#jupyter-lab","title":"Jupyter Lab","text":"<ul> <li>If Plotly charts are not rendered into JupyterLab, execute <code>jupyter labextension install jupyterlab-plotly</code> in the server environment for JupyterLab.</li> <li>To disable new undo/redo behaviour, see this thread.</li> <li>To enable auto closing brackets, see this issue.</li> <li>If ipywidgets aren't display properly (e.g. tqdm), see this issue</li> <li>To activate conda in a PowerShell shell run <code>.\\shell\\condabin\\conda-hook.ps1</code>, which can be found in Miniconda3 installation directory (see this thread)</li> <li>On Windows, to fix the error <code>ImportError: DLL load failed while importing _ssl: The specified module could not be found.</code> refer to this thread and copy the DLLs to the path of each Python venv which result broken</li> </ul>"},{"location":"2020/06/11/a-brief-guide-to-gnu-make/","title":"A brief guide to GNU Make","text":"<p><code>make</code> is a build tool which tracks the dependencies between the resources it manages, updating the successors whenever a change in one or more predecessors is detected.</p> <p>It was originally developed by Stuart Feldman in 1976 as a Bell Labs summer intern - he then received the 2003 ACM Software System Award for the authoring of this widespread tool.</p> <p>The inspiration came from the experience of a coworker of Feldman who futilely debugged a program where the executable was accidentally not being updated after bug had been fixed in the source code.</p>"},{"location":"2020/06/11/a-brief-guide-to-gnu-make/#makefile","title":"Makefile","text":"<p><code>make</code> reads and executes instructions contained in files called Makefile. They essentially store the description of a pipeline, as well as dependencies among pipeline blocks.</p> <p>The main concept in Makefile is represented by rules. A rule consists of three components:</p> <ul> <li>a target, the objective of the rule;</li> <li>a recipe, which consists in a set of actions to be performed to achieve the target:</li> <li>the dependencies, which are a list of prerequisites (other targets) that must be matched before the recipe can be executed.</li> </ul> <p>The syntax to declare a rule is the following</p> <pre><code>target: dependencies\n    recipe\n</code></pre> <p>where, by default, a tab stands as prefix of every recipe line.</p> <p>Each target can be then executed by calling <code>make</code>: the specified dependencies, if any, will be checked - and executed, if needed - and the recipe will be then executed. <p>For example, the following Makefile</p> <pre><code>hello:\n    echo \"hello world\"\n</code></pre> <p>can be executed by calling <code>make hello</code>.</p>"},{"location":"2020/06/11/a-brief-guide-to-gnu-make/#how-make-reads-a-makefile","title":"How <code>make</code> reads a Makefile","text":"<p>(paragraph 3.7 of GNU make user manual)</p> <p><code>make</code> does its work in two distinct phases.</p> <p>During the first phase it reads all the makefiles, included makefiles, etc. and internalizes all the variables and their values and implicit and explicit rules, and builds a dependency graph of all the targets and their prerequisites. During the second phase, <code>make</code> uses this internalized data to determine which targets need to be updated and run the recipes necessary to update them.</p> <p>It\u2019s important to understand this two-phase approach because it has a direct impact on how variable and function expansion happens. We say that expansion is immediate if it happens during the first phase: <code>make</code> will expand that part of the construct as the makefile is parsed. We say that expansion is deferred if it is not immediate. Expansion of a deferred construct part is delayed until the expansion is used: either when it is referenced in an immediate context, or when it is needed during the second phase.</p>"},{"location":"2020/06/11/a-brief-guide-to-gnu-make/#basics","title":"Basics","text":"<ul> <li>you can change the tab as default recipe prefix by overriding it with <code>.RECIPEPREFIX =</code> <li>you can break recipe lines with <code>\\</code></li> <li>by default, the simple execution of <code>make</code> in a directory which contains a Makefile will execute its first target. You can override this behaviour by specifying in the Makefile <code>.DEFAULT_GOAL :=</code> <li>you can ask to <code>make</code> to execute also other files which respect Makefile syntax by executing <code>make -f</code><code>.mk</code>, where mk is the standard extension for Makefiles <li>you can import other Makefiles within a given one by stating <code>include</code><code>.mk</code> <li><code>make</code>, by default, redirects to stdout all the action of a recipe before the execution. To avoid such a behaviour (for example, in the case of an <code>echo</code> action) you can prefix a <code>@</code> to the action</li> <li>comments in Makefile are inserted with a heading <code>#</code></li> <p>Last but not least, <code>make</code> offers a dry run mode which shows the steps that would be executed starting from a given Makefile without actually executing them. It can be achieved through <code>make --dry-run</code> or <code>make -n</code>.</p>"},{"location":"2020/06/11/a-brief-guide-to-gnu-make/#variables","title":"Variables","text":"<p>Makefile syntax supports variables. Basic usage consists in:</p> <ul> <li>deferred assignment with <code>var_name = var_value</code> (or immediate assignment with <code>var_name := var_value</code>)</li> <li>recall via <code>$(var_name)</code></li> </ul> <p><code>make</code> does variable substitution on recipe actions before they are passed to the shell for execution. That means that anything that looks like a variable will get replaced with the appropriate value. Therefore, to protect a variable intended to be interpreted by the shell rather than <code>make</code>, you need to double the dollar sign.</p> <p>In short: <code>make</code> variables have a single dollar sign, shell variables have a double dollar sign.</p>"},{"location":"2020/06/11/a-brief-guide-to-gnu-make/#automatic-variables","title":"Automatic variables","text":"<p>Some variables are automatically computed for each rule and made accessible in the recipe through handy syntax shortcuts. This means that automatic variables have a limited scope of availability i.e., are available only within each rule scope (which is, indeed, defined by its recipe).</p> <p>Some of them are:</p> <ul> <li><code>$@</code> , which refers to the target of the rule;</li> <li><code>$^</code> , which refers to the complete list of dependencies;</li> <li><code>$&lt;</code> , which refers to the first dependency.</li> </ul> <p>In turn, <code>%</code> is a wildcard that can be used within both target and dependencies: the matched pattern can be recalled within the recipe using the automatic variable <code>$*</code>.</p> <p>It\u2019s also possible to pass a variable to <code>make</code> directly at the command line, by calling <code>make</code><code></code><code>=</code>: this is useful for example to modify the execution of a given recipe without permanently altering it."},{"location":"2020/06/11/a-brief-guide-to-gnu-make/#phony-targets","title":"Phony targets","text":"<p>Standard Makefile rules expect the target to be built by the rule execution i.e., a rule with a given target is expected to somehow create the target (if needed).</p> <p>At the same time, <code>make</code> functionalities can represent a set of handy tools also for managing sequences of steps in a given (more \u201cabstract\u201d) pipeline, possibly without the need of managing concrete targets (files) or without the limitation of having a unique (preferred) target per rule.</p> <p>To overcome this situation, any target can be labelled as phony to inform <code>make</code> that no file/directory is actually linked to that target. This can be achieved by specifying</p> <pre><code>.PHONY: target\ntarget: dependencies\n    recipe\n</code></pre> <p>However, this choice as a huge effect on how <code>make</code> will interpret the rule associated to the phony target: since no actual file is linked to the target, from <code>make</code> perspective there is no way to determine whether or not the rule has been already executed. This lead to the consequence that rules with phony targets are always executed (somehow locally breaking the change tracking feature of the tool itself).</p> <p>Conversely, since the default nature of a rule is expecting the creation of a file which name coincides with the rule target, a standard non-PHONY rule which abides this nature should use a plain <code>$@</code> somewhere in its recipe to indicate the file it creates.</p> <p>See more in this useful thread.</p>"},{"location":"2020/06/11/a-brief-guide-to-gnu-make/#phony-targets-as-aliases","title":"Phony targets as aliases","text":"<p>Despite the above discussion, phony targets can be very useful in Makefiles, for example to manage aliases that can be recalled with <code>make</code>.</p> <p>For example, in a Makefile which contains a build rule can be useful to recall this rule with <code>make build</code> - while preserving the change tracking feature - despite the fact that the build folder is actually named \u201cbuild\u201d.</p> <p>In such a case, we can define a phony target called <code>build</code> with no recipe but a single dependency pointing to the actual building rule.</p> <pre><code>.PHONY: build\nbuild: build_dir_name\n\nbuild_dir_name: dependencies\n    recipe\n</code></pre> <p>In this case, the first call to <code>make build</code> will check for the dependency <code>build_dir_name</code> and will execute it. Then, a second attempt of calling <code>make build</code> will led to this message: <code>make: Nothing to be done for 'build'</code>.</p> <p>This does not mean that <code>make</code> knows that <code>build</code> has already been executed (we must remember that <code>build</code> is a phony target, so <code>make</code> has no way to track it!), but simply that build rule comes with no actions to be performed (empty recipe). So, why in the first execution the build has been actually performed? Basically, thanks to the automated dependency tracking of <code>make</code>, which triggered the execution of <code>build_dir_name</code>. At the second attempt, <code>make</code> recognized that the dependency has already been executed and simply \u201clacks\u201d to inform us about this awareness, limiting the stdout log to the <code>build</code> scope.</p> <p>Conversely, a call to <code>make build_dir_name</code> after <code>make build</code> would have led to this log: <code>make: 'build_dir_name' is up to date.</code> (because, now, <code>make</code> has been invoked over a trackable rule which has already been executed, so the log scope referring to this same rule is closer to what has happened).</p> <p>This usage of phony targets obviously shows some limitations, but can be anyway useful in order to obtain a balance between change tracking functionalities and ease of use.</p> <p>More on the topic here.</p>"},{"location":"2020/06/11/a-brief-guide-to-gnu-make/#make-help-trick","title":"<code>make help</code> trick","text":"<p>In order to obtain an automated documentation of a Makefile and be able to recall it through <code>make help</code> you can:</p> <ul> <li>comments each line that must be included in the help with <code>##</code> (instead of the standard single hash)</li> <li>define a custom <code>help</code> rule with the following syntax:</li> </ul> <pre><code>.PHONY: help\nhelp: Makefile\n    @sed -n 's/^## //p' $&amp;lt\n</code></pre> <p>This rule recipe passes the whole Makefile (the unique dependency) to the stream editor <code>sed</code> through the automatic variable <code>$&lt;</code>. The editor then looks for the specified pattern and returns the lines which match with the pattern to stdout.</p>"},{"location":"2020/06/11/a-brief-guide-to-gnu-make/#parallelization","title":"Parallelization","text":"<p>(paragraph 5.4 of GNU make user manual)</p> <p>Normally, <code>make</code> will execute only one recipe at a time, waiting for it to finish before executing the next. However, the <code>-j</code> or <code>--jobs</code> option tells <code>make</code> to execute many recipes simultaneously.</p> <p>If the <code>-j</code> option is followed by an integer, this is the number of recipes to execute at once; this is called the number of job slots. If there is nothing looking like an integer after the <code>-j</code> option, there is no limit on the number of job slots. The default number of job slots is one, which means serial execution (one thing at a time).</p>"},{"location":"2020/06/11/a-brief-guide-to-gnu-make/#makefile-vs-script","title":"Makefile vs script","text":"<p>Why (and when) a Makefile should be chosen instead of a simple automation script?</p> <p>Generally speaking, we can think to a script as a way to automate a process, while <code>make</code> uses Makefile to define a process and build everything needed within that process scope: it basically provides an executable description of the process pipeline.</p> <p>Moreover, <code>make</code> automatically determines which pieces of a large program need to be recompiled, and issues commands to recompile just them, but is not limited to programs. We can use it to describe any task where some files must be updated automatically from others whenever the others change.</p> <p>This automated behavior of dependency awareness and change tracking could be achieved also with scripts, but would require a lot more work. <code>make</code> achieves to do it automatically by performing topological sorting on the DAG built over a given Makefile.</p> <p>References </p> <ul> <li>Why use make over a shell script?</li> <li>Is a Makefile basically the same thing as a batch file?</li> <li>Script or makefile for automation?</li> </ul>"},{"location":"2020/06/11/a-brief-guide-to-gnu-make/#resources","title":"Resources","text":"<ul> <li>Make novice course \u279c ~3 hours introductive lesson to automation with <code>make</code> (highly recommended as a good place to start)</li> <li>GNU Make manual \u279c official GNU <code>make</code> manual (~200 pages...)</li> <li>Usage in Python projects \u279c brief showcase of usage in a Python project</li> <li>Override directive</li> </ul>"},{"location":"2019/08/12/a-brief-guide-to-pythons-pulp/","title":"A brief guide to Python's PuLP","text":"<p>PuLP is a Python library for linear programming written in a pythonic way.</p>","tags":["Python","OR"]},{"location":"2019/08/12/a-brief-guide-to-pythons-pulp/#taxonomy-and-general-approach","title":"Taxonomy and general approach","text":"","tags":["Python","OR"]},{"location":"2019/08/12/a-brief-guide-to-pythons-pulp/#linear-integer-and-mixed-integer-programming","title":"Linear, Integer and Mixed-integer programming","text":"<p>For a mathematical program to be a linear program you need the following conditions to be true:</p> <ul> <li>the decision variables must be real variables</li> <li>the objective must be a linear expression (wrt. the decision variables)</li> <li>the constraints must be linear expressions (wrt. the decision variables)</li> </ul> <p>An integer program is a linear program in which all the decision variables need to have only integer values. Since most integer programs contain a mix of continuous variables and integer variables they are often known as mixed integer programs.</p> <p>Note</p> <p>Integer programs can be very difficult problems to solve and there is a lot of current research finding \u201cgood\u201d ways to solve integer programs. Integer programs can be solved using the branch-and-bound process. For MIPs of any reasonable size the solution time grows exponentially as the number of integer variables increases.</p>","tags":["Python","OR"]},{"location":"2019/08/12/a-brief-guide-to-pythons-pulp/#the-optimisation-process","title":"The Optimisation Process","text":"<p>source: PuLP docs</p> <ol> <li>Getting the problem description</li> <li> <p>Formulating the (equivalent) mathematical program</p> <ul> <li>Identify the Decision Variables paying particular attention to units</li> <li>Formulate the Objective Function using the decision variables, we can construct a minimise or maximise objective function. The objective function typically reflects the total cost, or total profit, for a given value of the decision variables</li> <li>Formulate the Constraints, either logical or explicit to the problem description. Again, the constraints are expressed in terms of the decision variables.</li> <li>Identify the Data needed for the objective function and constraints. To solve your mathematical program you will need to have some \"hard numbers\" as variable bounds and/or variable coefficients in your objective function and/or constraints</li> </ul> </li> <li> <p>Solving the mathematical program</p> </li> <li> <p>Performing some post-optimal analysis</p> <ul> <li>how the optimal solution would change under various changes to the formulation?</li> <li>what the solution\u2019s variable values mean in terms of the original problem description?</li> </ul> </li> </ol>","tags":["Python","OR"]},{"location":"2019/08/12/a-brief-guide-to-pythons-pulp/#pulp-syntax","title":"PuLP syntax","text":"","tags":["Python","OR"]},{"location":"2019/08/12/a-brief-guide-to-pythons-pulp/#variables-definition","title":"Variables definition","text":"<p>To define a set of variables we can declare a dictionary through <code>LpVariable.dicts(var_name, var_index, lowBound, upBound, cat)</code> where:</p> <ul> <li>var_name is a string containing the name of the variable</li> <li>var_index contains the indices on which variables will be indexed (and will be used to set keys of the dictionary)</li> <li>lowBound is the lower bound of the domain of the variables</li> <li>upBound is the upper bound of the domain of the variables</li> <li>cat is the category of the variable (Integer, Binary or Continuous)</li> </ul> <p>Example</p> <p>To define an 10x1 array of binary variables \\(x\\) we can declare</p> <pre><code>x = LpVariable.dicts(\n    'my_binary_array', \n    range(10), \n    lowBound=0, \n    upBound=1, \n    cat='Binary'\n    )\n</code></pre> <p>To define \\(X\\) as a 5x4 matrix of integer variables \\(x_{ij}\\) such that \\(0\\leq x_{ij}\\leq 7\\) we can declare</p> <pre><code>X = LpVariable.dicts(\n    'my_integer_matrix', \n    [(i, j) for i in range(5) for j in range(4)], \n    lowBound=0, \n    upBound=7, \n    cat='Integer'\n    )\n</code></pre>","tags":["Python","OR"]},{"location":"2019/08/12/a-brief-guide-to-pythons-pulp/#problem-definition","title":"Problem definition","text":"<p>To define an instance of a given problem we first need to initialize it through <code>problem = LpProblem(problem_name, problem_sense)</code> where:</p> <ul> <li>problem_name is a string containing the name of the problem</li> <li>problem_sense can be either LpMinimize (default) or LpMaximize</li> </ul> <p>Example</p> <p>To define a minimization problem, we can declare</p> <pre><code>my_problem = LpProblem(\"The most difficult problem ever\", LpMinimize)\n</code></pre> <p>To add the objective function into the defined instance, we can use the following syntax <code>problem += objective_function, objective_function_desc</code> where:</p> <ul> <li>objective_function is the objective function expressed in terms of decision variables and possibly through the use of PuLP built in classes like <code>lpSum</code> and/or <code>LpAffineExpression</code></li> <li>objective_function_desc is a string containing the description of the objective function to be minimized/maximized</li> </ul> <p>Example</p> <p>To add the (possible) function to be minimized \\(\\sum_{i\\in I}a_ix_i\\) to our problem we can set</p> <pre><code>my_problem += lpSum([a[i]*x[i] for i in my_indices]),\\\n\"minimized this affine expression with coefficients a_i and variables x_i\"\n</code></pre>","tags":["Python","OR"]},{"location":"2019/08/12/a-brief-guide-to-pythons-pulp/#constraints","title":"Constraints","text":"<p>For our problem to be completely defined we must add also the constraints related to the initialized instance using <code>problem += constraint, constraint_desc</code> where:</p> <ul> <li>constraint is the expression which implements the constraint to be added possibly via the usage of the built-in class <code>LpConstraint</code></li> <li>constraint_desc is a string containing the description of the constraint</li> </ul> <p>Example</p> <p>To add to our problem a constraint in the form \\(\\sum_{i\\in I}x_i\\leq b\\) we can set</p> <pre><code>my_problem += lpSum([x[i] for i in my_indices]) &lt;= b\n</code></pre>","tags":["Python","OR"]},{"location":"2019/08/12/a-brief-guide-to-pythons-pulp/#solution-debug","title":"Solution &amp; debug","text":"<p>To write a (verbose) file with the complete representation of the given problem, we can use <code>problem.writeLP(\"problem_name.lp\")</code>. Similarly, to solve the problem and obtain a log with the trace of the optimization process we can use the following code:</p> <pre><code>my_problem.writeLP(\"my_problem_name.lp\")\n\nfrom os import dup, dup2, close\n\nlogf = open('./optimization_log.txt', 'w')\norig_std_out = dup(1)\ndup2(logf.fileno(), 1)\n\nmy_problem.solve(pulp.PULP_CBC_CMD(maxSeconds=90, msg=True)) \n\ndup2(orig_std_out, 1)\nclose(orig_std_out)\nlogf.close()\n</code></pre> <p>where <code>problem.solve(pulp.PULP_CBC_CMD(maxSeconds=max_seconds, msg=True))</code> corresponds to the actual call for the solution of the problem, where the default back-end solver has been called with the <code>msg</code> keyword set to True (to actually produce the output log) and the <code>maxSeconds</code> keyword set to 90 seconds to limit the calculation time.</p> <p>After the resolution, the objective function value can be obtained by calling:</p> <pre><code>my_problem.objective.value()\n</code></pre> <p>In a similar way, we can then check the value(s) assumed by the various decision variables by calling for example:</p> <pre><code>for i in my_indices:\n    print(x[i].value())\n</code></pre> <p>To check the status of the problem, both before and after the resolution process, we can use:</p> <pre><code>LpStatus[my_problem.status]\n</code></pre> <p>which passes to the built-in dictionary <code>LpStatus</code> the actual problem status, which can assume one of the following value: Optimal, Not Solved, Infeasible, Unbounded, Undefined.</p>","tags":["Python","OR"]},{"location":"2019/08/12/a-brief-guide-to-pythons-pulp/#tips-tricks","title":"Tips &amp; Tricks","text":"","tags":["Python","OR"]},{"location":"2019/08/12/a-brief-guide-to-pythons-pulp/#dummy-is-good","title":"Dummy is good","text":"<p>After the (mathematical) formulation of the problem and the related PuLP implementation, it's very useful to test the program over several dummy input datasets of growing complexity having a known ground-truth. This helps to identify possible implementation mistakes and/or to unveil limitations in the theoretical formulation.</p> <p>In doing this, the creation of auxiliary data structures to store decision variables output values is often very useful to not get lost within the (possibly) counterintuitive formulation of the problem (see tip below). The following two functions might be useful in monitor variables values:</p> <pre><code>def print_variable_values(LpVariable, exception=0):\n\n    '''\n    this function can be used to print the values of a given LpVariable\n    which do not equal the exception value (default=0)\n\n    INPUT\n    LpVariable (dict) --&gt; an LpVariable defined through the related PuLP class\n    exception --&gt; the exception value that will cause the variable value not to be printed\n    '''\n\n    for key in LpVariable:\n        value = LpVariable.get(key).value()\n        if value != exception:\n            print(key,':',value) \n    return\n\ndef filter_variable_values(LpVariable, exception=0):\n\n    '''\n    this function can be used to filter the values of a given LpVariable\n    which do not equal the exception value (default=0)\n\n    INPUT\n    LpVariable (dict) --&gt; an LpVariable defined through the related PuLP class\n    exception --&gt; the exception value that will cause the variable value to be filtered out\n\n    OUTPUT\n    filtered_values (dict) --&gt; a filtered dictionary which contains only the values of the given variable which do not equal the exception value\n    '''\n\n    filtered_values = {}\n    for key in LpVariable:\n        value = LpVariable.get(key).value()\n        if value != exception:\n            filtered_values[key] = value \n    return filtered_values\n</code></pre>","tags":["Python","OR"]},{"location":"2019/08/12/a-brief-guide-to-pythons-pulp/#change-the-point-of-view","title":"Change the point of view","text":"<p>The most straightforward implementation of a given minimization (resp. maximization) problem might sometimes involve a non-linear function of the decision variables. For example, we can think about a bin-packing problem in which the cost to be minimized depends in a non-linear way on the number of items contained in each bin. In a more detailed way, we are referring to the problem</p> <p>\\(\\min\\limits_{x}\\sum\\limits_{j\\in\\text{bins}} c\\left(\\sum\\limits_{i\\in\\text{items}}x_{ij}\\right)\\)</p> <p>being \\(c(\\cdot)\\) a non-linear function and \\(x_{ij}\\) a binary variable which indicates if the item \\(i\\) belongs to the bin \\(j\\).</p> <p>In such occasions, the linearity of the problem can be \"manually\" restored with the introduction of indicator variables defined over the possible values assumed by the above summation. Given for example that \\(\\sum_{i\\in\\text{items}}x_{ij}\\in\\{0,\\dots,N\\}\\), the problem can be written as</p> <p>\\(\\min \\sum\\limits_{j\\in\\text{bins}}\\sum\\limits_{n=0}^Nc(n)y_{nj}\\)</p> <p>where \\(y_{nj}\\) is a binary variable such that</p> <p>\\(y_{nj}=1\\Leftrightarrow \\sum\\limits_{i\\in\\text{items}}x_{ij}=n\\)</p> <p>subject to the following constraint</p> <p>\\(\\sum\\limits_{n=0}^Ny_{nj}=1\\;\\forall j\\in\\text{bins}\\)</p>","tags":["Python","OR"]},{"location":"2019/08/12/a-brief-guide-to-pythons-pulp/#the-more-the-better","title":"The more the better","text":"<p>In the first PuLP implementation, I found useful to write \"more\" constraints (even if redundant) rather than \"less\". This forced me to carefully reason about relations between decision variables during the formulation phase, as well as to be sure that I had implemented all the constraints required without missing any (even if in two or more different ways each).</p>","tags":["Python","OR"]},{"location":"2019/08/12/a-brief-guide-to-pythons-pulp/#latex-is-your-friend","title":"LaTeX is your friend","text":"<p>Before the implementation phase I found extremely useful to write down the full problem formulation in a clean and clear way (for example, with usage of \\(\\LaTeX\\) within Jupyter notebook markdown cells). Again, this forced me to be really sure about the theoretical framework of the problem, making clear all the assumptions and the modelization choices I have made. Moreover, this habit really helps the implementation serving as a to-do-list in terms of constraints to be added within the PuLP problem.</p> <p>In doing so, I strongly recommend to use a coherent indexing and notation between the theory (markdown cells) and the practice (PuLP code), to avoid transliteration mistakes and help your System 1 in doing its job.</p>","tags":["Python","OR"]},{"location":"2019/08/12/a-brief-guide-to-pythons-pulp/#linearize-linearize-linearize","title":"Linearize, linearize, linearize","text":"<p>If you desire (or must) stick to PuLP, you want every non-linear part of your formulation to disappear. In doing so, be confident and optimistic that many non-linear formulations can be properly linearized! For example:</p> <ul> <li>linearize a product between a binary variable and a bounded one</li> <li>linearize a logical implication or an equivalence</li> </ul> <p>In a similar way, you can bypass some PuLP limitations in the implementation. For example:</p> <ul> <li>to implement absolute values (refused by PuLP by default through a raise Error) you can refer to this as well as this</li> <li>to implement strict inequalities (refused by PuLP by default through a raise Error), if the involved variables can assume only integer values you can follow this tip.</li> </ul>","tags":["Python","OR"]},{"location":"2019/08/12/a-brief-guide-to-pythons-pulp/#resources","title":"Resources","text":"","tags":["Python","OR"]},{"location":"2019/08/12/a-brief-guide-to-pythons-pulp/#general","title":"General","text":"<ul> <li>PuLP official docs</li> <li>introductive paper by Stuart Mitchell et al.</li> <li>quadratic terms linearization</li> <li>blog with tutorials, explanations and tips &amp; tricks</li> <li>logical implication and equivalence linearization</li> <li>logical implication and equivalence linearization</li> <li>lecture notes MIP UniRoma</li> <li>lecture notes UniPD operations research and branch-and-bound method</li> <li>lecture notes MIP UniPD</li> </ul>","tags":["Python","OR"]},{"location":"2019/08/12/a-brief-guide-to-pythons-pulp/#bin-packing-related","title":"Bin packing related","text":"<ul> <li>paper with an implementation which exploits items fragmentation</li> <li>bin packing chapter in the online book Mathematica Optimization: Solving Problems using SCIP and Python</li> <li>introductive LinkedIn post</li> </ul>","tags":["Python","OR"]},{"location":"2019/08/12/a-brief-guide-to-pythons-pulp/#scheduling-related","title":"Scheduling related","text":"<ul> <li>post about workers scheduling to minimize cost of shifts</li> <li>slides about optimal scheduling with PuLP</li> <li>paper about Nurse Scheduling Problem</li> <li>post about conferences scheduling with PuLP</li> <li>post about Bus Driver Scheduling Problem</li> </ul>","tags":["Python","OR"]},{"location":"2019/08/12/a-brief-guide-to-pythons-pulp/#cbc-optimal-status","title":"CBC optimal status","text":"<p>I discover that CBC solver used via PuLP sometimes exits with <code>OPTIMAL</code> status even if the actual cause is the given time limit: this lead to an incoherent solver status with a globally non-optimum solution.</p> <p>Below some possible explanations.</p> <p>Following this issue, one of PuLP authors (at least from v2.1 on) states:</p> <p>In the case of GUROBI and CPLEX solvers (at least in the CMD interface), pulp returns 1 ('optimal') when an integer solution has been found in the time limit.</p> <p>This is not the behavior I get from the CBC solver, which returns 0 ['not solved', ndr].</p> <p>Since having found an integer solution when the time stops is neither \"optimal\" nor \"not solved\", both are at the same time misleading and inconsistent.</p> <p>One possibility is to at least make all solvers return the same status when finishing in the same status. This would make CBC return 1 instead of 0 when at least one integer &gt; solution was found. This is easy to change.</p> <p>The second, more ambitious possibility, would be to create a new \"Integer solution\" status in pulp that differentiates from \"optimal\" and \"no solution\". This would then be used in the solver interfaces as an additional status to return.</p> <p>A double check on PuLP constants confirms that:</p> <ul> <li>exists a dictionary of PuLP problem statuses with values in <code>[Not Solved, Optimal, Infeasible, Unbounded, Undefined]</code></li> <li>exists a dictionary of PuLP solution statuses with values in <code>[No Solution Found, Optimal Solution Found, Solution Found, No Solution Exists, Solution is Unbounded]</code></li> <li><code>LpSolutionIntegerFeasible = 2</code> has been mapped to solution status <code>Solution Found</code> but it's not the map value for any problem status in <code>LpStatusToSolution</code></li> </ul> <p>Looking into the source code of PuLP interface to CBC, we can check the <code>get_status</code> function definition:</p> <pre><code>def get_status(self, filename):\n    cbcStatus = {\n        \"Optimal\": constants.LpStatusOptimal,\n        \"Infeasible\": constants.LpStatusInfeasible,\n        \"Integer\": constants.LpStatusInfeasible,\n        \"Unbounded\": constants.LpStatusUnbounded,\n        \"Stopped\": constants.LpStatusNotSolved,\n    }\n\n    cbcSolStatus = {\n        \"Optimal\": constants.LpSolutionOptimal,\n        \"Infeasible\": constants.LpSolutionInfeasible,\n        \"Unbounded\": constants.LpSolutionUnbounded,\n        \"Stopped\": constants.LpSolutionNoSolutionFound,\n    }\n\n    with open(filename) as f:\n        statusstrs = f.readline().split()\n\n    status = cbcStatus.get(statusstrs[0], constants.LpStatusUndefined)\n    sol_status = cbcSolStatus.get(\n        statusstrs[0], constants.LpSolutionNoSolutionFound\n    )\n    # here we could use some regex expression.\n    # Not sure what's more desirable\n    if status == constants.LpStatusNotSolved and len(statusstrs) &gt;= 5:\n        if statusstrs[4] == \"objective\":\n            status = constants.LpStatusOptimal\n            sol_status = constants.LpSolutionIntegerFeasible\n    return status, sol_status\n</code></pre> <p>In one of the last lines we can clearly see that if the problem status is <code>LpStatusNotSolved</code>, the same is reassigned to <code>LpSolutionOptimal</code> but solution status is not (it is override with <code>LpSolutionIntegerFeasible</code>).</p>","tags":["Python","OR"]},{"location":"2024/02/01/a-visual-comparison-of-aws-certifications/","title":"A visual comparison of AWS Certifications","text":"<p>Following my previous post, the quest for AWS Certifications continues.</p> <p>In this episode, my goal is to quantitatively compare the three Associate certifications I'm focusing on: Solutions Architect, Developer and Data Engineer. So, I did some scraping to extract the exhaustive list of AWS services in scope for each certifications for the time being.</p>","tags":["AWS","Python"]},{"location":"2024/02/01/a-visual-comparison-of-aws-certifications/#gathering-the-data","title":"Gathering the data","text":"<p>The first data-gathering attempt consisted in using <code>pypdf</code> to extract text from exams guides: unfortunately, the result after few minutes of experiments wasn't good enough, so I manually copied the lists that can be found in the \"In-scope AWS services and features\" section of each guide's Appendix.</p> <p>After some processing, I obtained the following JSON:</p> services.json <pre><code>{\n    \"Solutions Architect\": {\n        \"Analytics\": [\n            \"Amazon Athena\",\n            \"AWS Data Exchange\",\n            \"AWS Data Pipeline\",\n            \"Amazon EMR\",\n            \"AWS Glue\",\n            \"Amazon Kinesis\",\n            \"AWS Lake Formation\",\n            \"Amazon Managed Streaming for Apache Kafka (Amazon MSK)\",\n            \"Amazon OpenSearch Service\",\n            \"Amazon QuickSight\",\n            \"Amazon Redshift\"\n        ],\n        \"Application Integration\": [\n            \"Amazon AppFlow\",\n            \"AWS AppSync\",\n            \"Amazon EventBridge\",\n            \"Amazon MQ\",\n            \"Amazon Simple Notification Service (Amazon SNS)\",\n            \"Amazon Simple Queue Service (Amazon SQS)\",\n            \"AWS Step Functions\"\n        ],\n        \"AWS Cost Management\": [\n            \"AWS Budgets\",\n            \"AWS Cost and Usage Report\",\n            \"AWS Cost Explorer\",\n            \"Savings Plans\"\n        ],\n        \"Compute\": [\n            \"AWS Batch\",\n            \"Amazon EC2\",\n            \"Amazon EC2 Auto Scaling\",\n            \"AWS Elastic Beanstalk\",\n            \"AWS Outposts\",\n            \"AWS Serverless Application Repository\",\n            \"VMware Cloud on AWS\",\n            \"AWS Wavelength\"\n        ],\n        \"Containers\": [\n            \"Amazon ECS Anywhere\",\n            \"Amazon EKS Anywhere\",\n            \"Amazon EKS Distro\",\n            \"Amazon Elastic Container Registry (Amazon ECR)\",\n            \"Amazon Elastic Container Service (Amazon ECS)\",\n            \"Amazon Elastic Kubernetes Service (Amazon EKS)\"\n        ],\n        \"Database\": [\n            \"Amazon Aurora\",\n            \"Amazon Aurora Serverless\",\n            \"Amazon DocumentDB (with MongoDB compatibility)\",\n            \"Amazon DynamoDB\",\n            \"Amazon ElastiCache\",\n            \"Amazon Keyspaces (for Apache Cassandra)\",\n            \"Amazon Neptune\",\n            \"Amazon Quantum Ledger Database (Amazon QLDB)\",\n            \"Amazon RDS\",\n            \"Amazon Redshift\"\n        ],\n        \"Developer Tools\": [\n            \"AWS X-Ray\"\n        ],\n        \"Frontend Web and Mobile\": [\n            \"AWS Amplify\",\n            \"Amazon API Gateway\",\n            \"AWS Device Farm\",\n            \"Amazon Pinpoint\"\n        ],\n        \"Machine Learning\": [\n            \"Amazon Comprehend\",\n            \"Amazon Forecast\",\n            \"Amazon Fraud Detector\",\n            \"Amazon Kendra\",\n            \"Amazon Lex\",\n            \"Amazon Polly\",\n            \"Amazon Rekognition\",\n            \"Amazon SageMaker\",\n            \"Amazon Textract\",\n            \"Amazon Transcribe\",\n            \"Amazon Translate\"\n        ],\n        \"Management and Governance\": [\n            \"AWS Auto Scaling\",\n            \"AWS CloudFormation\",\n            \"AWS CloudTrail\",\n            \"Amazon CloudWatch\",\n            \"AWS Command Line Interface (AWS CLI)\",\n            \"AWS Compute Optimizer\",\n            \"AWS Config\",\n            \"AWS Control Tower\",\n            \"AWS Health Dashboard\",\n            \"AWS License Manager\",\n            \"Amazon Managed Grafana\",\n            \"Amazon Managed Service for Prometheus\",\n            \"AWS Management Console\",\n            \"AWS Organizations\",\n            \"AWS Proton\",\n            \"AWS Service Catalog\",\n            \"AWS Systems Manager\",\n            \"AWS Trusted Advisor\",\n            \"AWS Well-Architected Tool\"\n        ],\n        \"Media Services\": [\n            \"Amazon Elastic Transcoder\",\n            \"Amazon Kinesis Video Streams\"\n        ],\n        \"Migration and Transfer\": [\n            \"AWS Application Discovery Service\",\n            \"AWS Application Migration Service\",\n            \"AWS Database Migration Service (AWS DMS)\",\n            \"AWS DataSync\",\n            \"AWS Migration Hub\",\n            \"AWS Snow Family\",\n            \"AWS Transfer Family\"\n        ],\n        \"Networking and Content Delivery\": [\n            \"AWS Client VPN\",\n            \"Amazon CloudFront\",\n            \"AWS Direct Connect\",\n            \"Elastic Load Balancing (ELB)\",\n            \"AWS Global Accelerator\",\n            \"AWS PrivateLink\",\n            \"Amazon Route 53\",\n            \"AWS Site-to-Site VPN\",\n            \"AWS Transit Gateway\",\n            \"Amazon VPC\"\n        ],\n        \"Security, Identity, and Compliance\": [\n            \"AWS Artifact\",\n            \"AWS Audit Manager\",\n            \"AWS Certificate Manager (ACM)\",\n            \"AWS CloudHSM\",\n            \"Amazon Cognito\",\n            \"Amazon Detective\",\n            \"AWS Directory Service\",\n            \"AWS Firewall Manager\",\n            \"Amazon GuardDuty\",\n            \"AWS IAM Identity Center (AWS Single Sign-On)\",\n            \"AWS Identity and Access Management (IAM)\",\n            \"Amazon Inspector\",\n            \"AWS Key Management Service (AWS KMS)\",\n            \"Amazon Macie\",\n            \"AWS Network Firewall\",\n            \"AWS Resource Access Manager (AWS RAM)\",\n            \"AWS Secrets Manager\",\n            \"AWS Security Hub\",\n            \"AWS Shield\",\n            \"AWS WAF\"\n        ],\n        \"Serverless\": [\n            \"AWS AppSync\",\n            \"AWS Fargate\",\n            \"AWS Lambda\"\n        ],\n        \"Storage\": [\n            \"AWS Backup\",\n            \"Amazon Elastic Block Store (Amazon EBS)\",\n            \"Amazon Elastic File System (Amazon EFS)\",\n            \"Amazon FSx (for all types)\",\n            \"Amazon S3\",\n            \"Amazon S3 Glacier\",\n            \"AWS Storage Gateway\"\n        ]\n    },\n    \"Developer\": {\n        \"Analytics\": [\n            \"Amazon Athena\",\n            \"Amazon Kinesis\",\n            \"Amazon OpenSearch Service\"\n        ],\n        \"Application Integration\": [\n            \"AWS AppSync\",\n            \"Amazon EventBridge\",\n            \"Amazon Simple Notification Service (Amazon SNS)\",\n            \"Amazon Simple Queue Service (Amazon SQS)\",\n            \"AWS Step Functions\"\n        ],\n        \"Compute\": [\n            \"Amazon EC2\",\n            \"AWS Elastic Beanstalk\",\n            \"AWS Lambda\",\n            \"AWS Serverless Application Model (AWS SAM)\"\n        ],\n        \"Containers\": [\n            \"AWS Copilot\",\n            \"Amazon Elastic Container Registry (Amazon ECR)\",\n            \"Amazon Elastic Container Service (Amazon ECS)\",\n            \"Amazon Elastic Kubernetes Service (Amazon EKS)\"\n        ],\n        \"Database\": [\n            \"Amazon Aurora\",\n            \"Amazon DynamoDB\",\n            \"Amazon ElastiCache\",\n            \"Amazon MemoryDB for Redis\",\n            \"Amazon RDS\"\n        ],\n        \"Developer Tools\": [\n            \"AWS Amplify\",\n            \"AWS Cloud9\",\n            \"AWS CloudShell\",\n            \"AWS CodeArtifact\",\n            \"AWS CodeBuild\",\n            \"AWS CodeCommit\",\n            \"AWS CodeDeploy\",\n            \"Amazon CodeGuru\",\n            \"AWS CodePipeline\",\n            \"AWS CodeStar\",\n            \"Amazon CodeWhisperer\",\n            \"AWS X-Ray\"\n        ],\n        \"Management and Governance\": [\n            \"AWS AppConfig\",\n            \"AWS CLI\",\n            \"AWS Cloud Development Kit (AWS CDK)\",\n            \"AWS CloudFormation\",\n            \"AWS CloudTrail\",\n            \"Amazon CloudWatch\",\n            \"Amazon CloudWatch Logs\",\n            \"AWS Systems Manager\"\n        ],\n        \"Networking and Content Delivery\": [\n            \"Amazon API Gateway\",\n            \"Amazon CloudFront\",\n            \"Elastic Load Balancing (ELB)\",\n            \"Amazon Route 53\",\n            \"Amazon VPC\"\n        ],\n        \"Security, Identity, and Compliance\": [\n            \"AWS Certificate Manager (ACM)\",\n            \"Amazon Cognito\",\n            \"AWS Identity and Access Management (IAM)\",\n            \"AWS Key Management Service (AWS KMS)\",\n            \"AWS Private Certificate Authority\",\n            \"AWS Secrets Manager\",\n            \"AWS Security Token Service (AWS STS)\",\n            \"AWS WAF\"\n        ],\n        \"Storage\": [\n            \"Amazon Elastic Block Store (Amazon EBS)\",\n            \"Amazon Elastic File System (Amazon EFS)\",\n            \"Amazon S3\",\n            \"Amazon S3 Glacier\"\n        ]\n    },\n    \"Data Engineer\": {\n        \"Analytics\": [\n            \"Amazon Athena\",\n            \"Amazon EMR\",\n            \"AWS Glue\",\n            \"AWS Glue DataBrew\",\n            \"AWS Lake Formation\",\n            \"Amazon Kinesis\",\n            \"Amazon Managed Service for Apache Flink\",\n            \"Amazon Managed Streaming for Apache Kafka (Amazon MSK)\",\n            \"Amazon OpenSearch Service\",\n            \"Amazon QuickSight\"\n        ],\n        \"Application Integration\": [\n            \"Amazon AppFlow\",\n            \"Amazon EventBridge\",\n            \"Amazon Managed Workflows for Apache Airflow (Amazon MWAA)\",\n            \"Amazon Simple Notification Service (Amazon SNS)\",\n            \"Amazon Simple Queue Service (Amazon SQS)\",\n            \"AWS Step Functions\"\n        ],\n        \"Cloud Financial Management\": [\n            \"AWS Budgets\",\n            \"AWS Cost Explorer\"\n        ],\n        \"Compute\": [\n            \"AWS Batch\",\n            \"Amazon EC2\",\n            \"AWS Lambda\",\n            \"AWS Serverless Application Model (AWS SAM)\"\n        ],\n        \"Containers\": [\n            \"Amazon Elastic Container Registry (Amazon ECR)\",\n            \"Amazon Elastic Container Service (Amazon ECS)\",\n            \"Amazon Elastic Kubernetes Service (Amazon EKS)\"\n        ],\n        \"Database\": [\n            \"Amazon DocumentDB (with MongoDB compatibility)\",\n            \"Amazon DynamoDB\",\n            \"Amazon Keyspaces (for Apache Cassandra)\",\n            \"Amazon MemoryDB for Redis\",\n            \"Amazon Neptune\",\n            \"Amazon RDS\",\n            \"Amazon Redshift\"\n        ],\n        \"Developer Tools\": [\n            \"AWS CLI\",\n            \"AWS Cloud9\",\n            \"AWS Cloud Development Kit (AWS CDK)\",\n            \"AWS CodeBuild\",\n            \"AWS CodeCommit\",\n            \"AWS CodeDeploy\",\n            \"AWS CodePipeline\"\n        ],\n        \"Frontend Web and Mobile\": [\n            \"Amazon API Gateway\"\n        ],\n        \"Machine Learning\": [\n            \"Amazon SageMaker\"\n        ],\n        \"Management and Governance\": [\n            \"AWS CloudFormation\",\n            \"AWS CloudTrail\",\n            \"Amazon CloudWatch\",\n            \"Amazon CloudWatch Logs\",\n            \"AWS Config\",\n            \"Amazon Managed Grafana\",\n            \"AWS Systems Manager\",\n            \"AWS Well-Architected Tool\"\n        ],\n        \"Migration and Transfer\": [\n            \"AWS Application Discovery Service\",\n            \"AWS Application Migration Service\",\n            \"AWS Database Migration Service (AWS DMS)\",\n            \"AWS DataSync\",\n            \"AWS Schema Conversion Tool (AWS SCT)\",\n            \"AWS Snow Family\",\n            \"AWS Transfer Family\"\n        ],\n        \"Networking and Content Delivery\": [\n            \"Amazon CloudFront\",\n            \"AWS PrivateLink\",\n            \"Amazon Route 53\",\n            \"Amazon VPC\"\n        ],\n        \"Security, Identity, and Compliance\": [\n            \"AWS Identity and Access Management (IAM)\",\n            \"AWS Key Management Service (AWS KMS)\",\n            \"Amazon Macie\",\n            \"AWS Secrets Manager\",\n            \"AWS Shield\",\n            \"AWS WAF\"\n        ],\n        \"Storage\": [\n            \"AWS Backup\",\n            \"Amazon Elastic Block Store (Amazon EBS)\",\n            \"Amazon Elastic File System (Amazon EFS)\",\n            \"Amazon S3\",\n            \"Amazon S3 Glacier\"\n        ]\n    }\n}\n</code></pre>","tags":["AWS","Python"]},{"location":"2024/02/01/a-visual-comparison-of-aws-certifications/#visualization","title":"Visualization","text":"","tags":["AWS","Python"]},{"location":"2024/02/01/a-visual-comparison-of-aws-certifications/#heatmap","title":"Heatmap","text":"<p>From the data it's easy to extract a raw count of in-scope services for each area/certification, and visualize it with the following heatmap.</p> <p></p> <p>Some high-level considerations:</p> <ul> <li>the Solutions Architect certification involves by far the highest number of AWS services;</li> <li>the Developer Tools services are distinctive of the Developer certification;</li> <li>\"Security, Identity and Compliance\" and \"Management and Governance\" areas are well represented in all certifications.</li> </ul>","tags":["AWS","Python"]},{"location":"2024/02/01/a-visual-comparison-of-aws-certifications/#upset-plot","title":"UpSet plot","text":"<p>By comparing the raw count of in-scope services, however, we miss the potential overlapping between certifications. Visually speaking, we can be interested in a Venn diagram to catch the magnitude of common services. In the true spirit of TIL, I conversely chose to explore the awesome UpSet framework, in particular through the UpSetPlot implementation.</p> <p></p>","tags":["AWS","Python"]},{"location":"2024/02/01/a-visual-comparison-of-aws-certifications/#interactive-tree","title":"Interactive tree","text":"<p>With the UpSet plot at our disposal, the last question is: which are the specific services in each intersection?</p> <p>I already had all the data required for the answer, but I decided to take a further step forward and building an interactive tree with Apache ECharts.</p> <p>Available interaction</p> <p>The chart lets you move (click-and-drag) and zoom (scroll wheel), in addition to expand/collapse actions available at each node.</p> <p>Expanding a service area node you can see up to three children nodes:</p> <ul> <li>common services i.e., the ones in-scope of all certifications (degree=3);</li> <li>peculiar services i.e., the ones in-scope of only one certification (degree=1);</li> <li>paired services i.e., the ones in-scope of exactly two certifications (degree=2).</li> </ul>","tags":["AWS","Python"]},{"location":"2024/01/29/aws-certification-skill-tree/","title":"AWS Certification Skill Tree","text":"<p>As a professional with more than 4 years of experience with AWS, I might attempt to get an AWS Certification sooner or later this year, so I'm evaluating all the possibilities out there.</p> <p>AWS itself provides a useful guide to the recommended AWS Certification Paths, where all the top cloud job roles are listed together with a bried description of their responsibilities.</p> <p>Even if such a resource is more than welcome, I find that the big picture is not as clear as it should be: I decided to help myself building a skill tree with the aid of the awesome <code>diagrams</code>.</p> <p>After having manually scraped the internet to get AWS Certification icons<sup>1</sup>, I started experimenting with <code>diagrams</code> and I finally came up with this result (click to enlarge).</p> <p></p> Source code <pre><code>from diagrams import Cluster, Diagram, Edge\nfrom diagrams.custom import Custom\n\nADVANCED_NETWORKING = \"advanced_networking\"\nCLOUD_PRACTITIONER = \"cloud_practitioner\"\nDATA_ENGINEER = \"data_engineer\"\nDEVELOPER = \"developer\"\nDEVOPS_ENGINEER = \"devops_engineer\"\nMACHINE_LEARNING = \"machine_learning\"\nSECURITY = \"security\"\nSOLUTIONS_ARCHITECT_ASSOCIATE = \"solutions_architect_associate\"\nSOLUTIONS_ARCHITECT_PROFESSIONAL = \"solutions_architect_professional\"\nSYSOPS_ADMIN = \"sysops_admin\"\n\nSOURCE = \"https://d1.awsstatic.com/training-and-certification/docs/AWS_certification_paths.pdf\"\n\n\ndef build_node(name: str, label: str = \"\") -&gt; Custom:\n    return Custom(\n        label=label,\n        # This requires you to have an assets folder\n        # with the icons named after the above literals\n        icon_path=f\"./assets/{name}.png\",\n    )\n\n\nwith Diagram(\n    name=f\"AWS Certification Paths\\n{SOURCE}\",\n    filename=\"aws_certification_paths\",\n    direction=\"TB\",\n):\n    DiveDeep = Edge(color=\"magenta\", style=\"dashed\")\n    with Cluster(\"Optional for IT/STEM/Cloud professionals\"):\n        cloud_practitioner = build_node(CLOUD_PRACTITIONER)\n    solutions_architect_associate = build_node(SOLUTIONS_ARCHITECT_ASSOCIATE)\n    developer = build_node(DEVELOPER)\n    sysops_admin = build_node(SYSOPS_ADMIN)\n    cloud_practitioner &gt;&gt; solutions_architect_associate\n    cloud_practitioner &gt;&gt; developer\n    cloud_practitioner &gt;&gt; sysops_admin\n    with Cluster(\"Architecture\"):\n        with Cluster(\"Solutions Architect\"):\n            (\n                solutions_architect_associate\n                &gt;&gt; build_node(SOLUTIONS_ARCHITECT_PROFESSIONAL)\n                &gt;&gt; DiveDeep\n                &gt;&gt; build_node(SECURITY)\n            )\n        with Cluster(\"Application Architect\"):\n            (\n                solutions_architect_associate\n                &gt;&gt; build_node(DEVELOPER)\n                &gt;&gt; build_node(DEVOPS_ENGINEER)\n                &gt;&gt; DiveDeep\n                &gt;&gt; build_node(SOLUTIONS_ARCHITECT_PROFESSIONAL)\n            )\n    with Cluster(\"Data Analytics\"):\n        with Cluster(\"Cloud Data Engineer\"):\n            (\n                solutions_architect_associate\n                &gt;&gt; build_node(DATA_ENGINEER)\n                &gt;&gt; DiveDeep\n                &gt;&gt; build_node(SECURITY)\n            )\n    with Cluster(\"Development\"):\n        with Cluster(\"Software Development/Test Engineer\"):\n            (developer &gt;&gt; build_node(DEVOPS_ENGINEER))\n    with Cluster(\"Operations\"):\n        with Cluster(\"Systems Administrator\"):\n            (sysops_admin &gt;&gt; DiveDeep &gt;&gt; build_node(DEVOPS_ENGINEER))\n        with Cluster(\"Cloud Security Engineer\"):\n            (\n                sysops_admin\n                &gt;&gt; build_node(SECURITY)\n                &gt;&gt; DiveDeep\n                &gt;&gt; build_node(DEVOPS_ENGINEER)\n                &gt;&gt; DiveDeep\n                &gt;&gt; build_node(ADVANCED_NETWORKING)\n            )\n    with Cluster(\"DevOps\"):\n        with Cluster(\"Cloud DevOps Engineer\"):\n            (\n                developer\n                &gt;&gt; build_node(SYSOPS_ADMIN, label=\"(Optional)\")\n                &gt;&gt; DiveDeep\n                &gt;&gt; build_node(DEVOPS_ENGINEER)\n            )\n        with Cluster(\"DevSecOps Engineer\"):\n            (sysops_admin &gt;&gt; build_node(DEVOPS_ENGINEER) &gt;&gt; build_node(SECURITY))\n    with Cluster(\"Security\"):\n        with Cluster(\"Cloud Security Architect\"):\n            (\n                solutions_architect_associate\n                &gt;&gt; build_node(SECURITY)\n                &gt;&gt; DiveDeep\n                &gt;&gt; build_node(SOLUTIONS_ARCHITECT_PROFESSIONAL)\n            )\n    with Cluster(\"Networking\"):\n        with Cluster(\"Networking Engineer\"):\n            (\n                solutions_architect_associate\n                &gt;&gt; build_node(ADVANCED_NETWORKING)\n                &gt;&gt; DiveDeep\n                &gt;&gt; build_node(SECURITY)\n            )\n    with Cluster(\"AI/ML\"):\n        with Cluster(\"Machine Learning Engineer\"):\n            (\n                solutions_architect_associate\n                &gt;&gt; build_node(DEVELOPER)\n                &gt;&gt; build_node(DATA_ENGINEER)\n                &gt;&gt; build_node(MACHINE_LEARNING)\n            )\n</code></pre> <p>I am mostly a visual learner: the following table shows some property I wanted to retain in the skill tree next to the visual element I chose for the encoding.</p> Property Encoded with Optionality of Cloud Practitioner certification dedicated <code>diagrams.Cluster</code> Job area <code>diagrams.Cluster</code> Job title <code>diagrams.Cluster</code> Dive Deep layer styled <code>diagrams.Edge</code> <p>With this skill tree available, some considerations are now straightforward:</p> <ul> <li>after the optional Cloud Practitioner, you basically have three front doors: Solutions Architect, Developer or SysOps Administrator;</li> <li>you are expected to know how to architecture first, and only later start implementing;</li> <li>the so-called Security by Design approach is enforced also ensuring that many certified professionals have measured themselves with Security specialty;</li> <li>the Development, DevOps and Operations paths seem to be more general-purpose than the ones departing from the Solutions Architect front door;</li> <li>in this AWS vision, a Machine Learning Engineer is a specialized Cloud Data Engineer;</li> <li>these paths suggest that the people building and fine-tuning data solutions should try to stick to their role and to avoid wearing too many hats (e.g. DevOps certifications are not listed in their paths).</li> </ul> <p>Finally, I tried to answer my original question: which certifications I should try pursuing first? To do so, it's useful reinterpreting the skill tree as a proper graph, e.g. by removing redundant edges and merging redundant nodes<sup>2</sup>. After playing around with <code>diagrams</code> options, I highlighted the three paths that look closer to my experience so far (and thus represent the most probable choices I will invest time in): Cloud Data Engineer, Machine Learning Engineer and Application Architect.</p> <p></p> <p>Certifications to start with</p> <p>Ignoring the retiring certifications, I think the first ones to pursue given my current role and interests should be chosen amongst Cloud Practitioner (to familiarize with exams process), and the \"Associate trinity\" made of Solutions Architect, Developer and Data Engineer.</p> <p>The bottom line: there are many suggested ways to reach a given certification, you can either follow these recommended/recognized paths or build your own. Enjoy!</p> <ol> <li> <p>The entire collection is already available somewhere for sure, but I didn't search that much.\u00a0\u21a9</p> </li> <li> <p>This rendition make also clearer the four tiers of certification and their increasing difficulty: Foundational, Associate, Professional and Specialty. To further deepen their features and the differences in scope/depth assessed, you can refer to this useful post.\u00a0\u21a9</p> </li> </ol>","tags":["AWS","Python"]},{"location":"2024/01/24/all-you-need-is-closure/","title":"All you need is closure","text":"<p>Decorators are well known examples of Python syntactic sugar, which basically let you change the behaviour of a function without modifying its definition, thanks to a handy syntax based on the <code>@</code> symbol followed by the decorator name, everything put just above your function definition.</p> <p>Sometimes, however, you can't exploit this syntax, for example because you don't have the function definition at your disposal - let's think at the case in which the function you want to decorate lives in another codebase (the latter might be one of the libraries your project depends on).</p> <p>The syntactic sugar approach, generally speaking, gives a lot of advantages in terms of experimentation, reusability and reversibility. However, in cases like the ones mentioned above, this approach can do more harm than good, forcing you to wrap a function invocation in another function with the only aim of providing a function definition to decorate, with the risk of reduce the readability and maintainability of your codebase<sup>1</sup>.</p> <p>What you can do instead is take a step back and use the decorator function directly for what it is: a closure<sup>2</sup>.</p> ScenarioClosure approachSyntactic sugar approach <pre><code>from external_lib import some_func\n\ndef main():\n    # ... complex logic that you can't refactor\n    # which defines inputs for some_func  ...\n    response = some_func(inputs)\n</code></pre> <pre><code>from external_lib import some_func\n\ndef decorator(func):\n    # ... custom logic ...\n\ndef main():\n    # ... complex logic that you can't refactor\n    # which defines inputs for some_func  ...\n    response = decorator(some_func)(inputs)\n</code></pre> <pre><code>from external_lib import some_func\n\ndef decorator(func):\n    # ... custom logic ...\n\ndef main():\n    # ... complex logic that you can't refactor\n    # which defines inputs for some_func  ...\n    @decorator\n    def pointless_wrapper():\n        return some_func(inputs)\n\n    response = pointless_wrapper()\n</code></pre>","tags":["Python","AWS"]},{"location":"2024/01/24/all-you-need-is-closure/#a-real-world-example","title":"A real world example","text":"<p>I came across the above reasonings while I was working on error handling in a serverless architecture based on AWS.</p> <p>Specifically, my need was to catch and retry a specific error raised by awswrangler (aws-sdk-pandas) when an Athena query execution fails i.e., <code>awswrangler.exceptions.QueryFailed</code>. This error is often raised by <code>awswrangler.athena.read_sql_query</code> or <code>awswrangler.athena.start_query_execution</code>, the latter being used with <code>wait=True</code>.</p> <p>I recently read and enjoy Robust Python by Patrick Viafore - which I totally recommend to seasoned Python developers, for a lot of reasons far beyond the scope of this post - where the author recommends the <code>backoff</code> library for such tasks.</p> <p>Backoff offers a handy decorator-based approach to handle retry logic in a wide range of different situations, with some customization options to be feed as decorator kwargs.</p> <p>Thanks to the intuitive and well documented API, after few minutes of experiments I came up with this setup which seemed to do the job:</p> <pre><code>import awswrangler as wr\nimport backoff\n\n@backoff.on_exception(backoff.expo, wr.exceptions.QueryFailed, max_tries=3)\n</code></pre> <p>I was ready to add the customized decorator to my codebase, but I then realized that I do not have access to awswrangler.athena functions definition. I suddenly found myself wondering whether or not I can decorate function invocation instead: a quick Google search gave me the simple (yet forgotten) answer.</p> <p>All I had to do was aliasing my custom decorator and then use it wherever required by simply wrapping original function call with the defined alias<sup>3</sup>.</p> BeforeAfter <pre><code>import awswrangler as wr\n\nresponse = wr.athena.read_sql_query(sql, database)\n</code></pre> <pre><code>import awswrangler as wr\nimport backoff\n\nretry_when_query_fails = backoff.on_exception(\n    backoff.expo,\n    wr.exceptions.QueryFailed,\n    max_tries=3\n)\n\nresponse = retry_when_query_fails(wr.athena.read_sql_query)(sql, database)\n</code></pre> <ol> <li> <p>This can be referred to as syntactic diabetes.\u00a0\u21a9</p> </li> <li> <p>This blog post gives well explained details about both closures and decorators in Python.\u00a0\u21a9</p> </li> <li> <p>Since backoff library exposes functions which can be used as decorators, this ensures that they also can be used as plain closures.\u00a0\u21a9</p> </li> </ol>","tags":["Python","AWS"]},{"location":"2023/11/30/prestotrino-unix-timestamp-window-functions-e-daylight-saving-time/","title":"Presto/Trino, unix timestamp, window functions e daylight saving time","text":"<p>Se si usano window functions (es. <code>LAG</code>) per calcolare delta tra timestamp Unix, il risultato \"ignora\" eventuali switch di ora legale/solare (correttamente, dato che un timestamp Unix conta esclusivamente il tempo che scorre).</p> <p>Non \u00e8 stato immediato trovare una soluzione che tenesse conto dello switch e che, quindi, aggiungesse/sottraesse l'ora di delta, e anche <code>DATE_DIFF</code> non ha aiutato.</p> <p>Una soluzione manuale \u00e8 per\u00f2 possibile tramite la utils <code>TIMEZONE_HOUR</code>, che restituisce il delta rispetto a UTC, quindi 1 o 2 ore a seconda del periodo dell'anno.</p> <p>Example</p> <pre><code>SELECT\n  TIMEZONE_HOUR(unix_timestamp) - LAG(TIMEZONE_HOUR(unix_timestamp), 1, 0) OVER (\n    PARTITION BY partition_key\n    ORDER BY unix_timestamp\n  )\nFROM my_table\n</code></pre>","tags":["ITA","SQL"]},{"location":"2024/01/08/convert-a-markdown-file-to-docx-with-pandoc/","title":"Convert a markdown file to docx with pandoc","text":"<p>Today I rediscover an amazing tool: pandoc, which correctly presents itself as</p> <p>your swiss-army knife to convert files from one markup format into another.</p> <p>In these days I am working on the redaction of a complex tender notice, which must be delivered as an editable <code>docx</code> and then exported (with all the fancy stuff and theming) into <code>pdf</code>. Unfortunately, I find the user experience of writing documents with Microsoft Word really unsatisfying and cluttered.</p> <p>Therefore I decided to project this task to a space where I feel more comfortable: markdown editing. In doing so, I also took the chance to explore a nice tool I discovered some months ago: Obsidian.</p> <p>Elephant in the room</p> <p>The main question obviously was: can I easily (and perhaps nicely) convert my markdown sources into the requested docx format?</p> <p>Pandoc to the rescue! With an awesome one-liner provided among the documented examples, the conversion takes seconds - and thanks to the <code>--reference-doc</code> option the reference theme is enforced with no effort.</p> <pre><code>pandoc --reference-doc reference.docx -o output.docx obsidian_vault/input.md\n</code></pre> <p>Of course, the above one-liner has been already listed as a target into the project Makefile.</p>"},{"location":"2024/01/02/cross-account-full-table-copy-options-for-amazon-dynamodb/","title":"Cross-account full table copy options for Amazon DynamoDB","text":"<p>There are several recommended options to perform a cross-account full copy of a DynamoDB table.</p> <p>It seems reasonable to compare these options based on several different properties: setup time (low is better), approach (serverless is better), involved resources (few is better), costs estimate (low is better) and new code possibly required (none is better).</p> <p>Given the above requirements, one of the best available option seems to be the one based on AWS Backup. This solution requires to enable cross-account backup in AWS Backup, but this particular feature might not be available in a developer's hands (e.g. for security or compliance reasons).</p> <p>The second best might be this other approach based on Spark jobs handled by Glue. Basically, this requires to create:</p> <ul> <li>in the target account:<ul> <li>a policy which gives write permission to the target DynamoDB table<sup>1</sup>;</li> <li>a (cross-account) role with the source account as trusted entity, equipped with the above policy;</li> </ul> </li> <li>in the source account:<ul> <li>a policy which grants <code>sts:AssumeRole</code> on the above mentioned cross-account role;</li> <li>a role with AWS Glue as principal, equipped with the above policy and read permissions on the source DynamoDB table and S3<sup>2</sup>;</li> <li>a Glue job as described here in the section \"For a read and cross-account write across regions\", equipped with the above role.</li> </ul> </li> </ul> <p>How to handle throttled requests</p> <p>With this solution, Glue will generate a high rate of write operations, which might led to throttled requests. To avoid <code>DynamoDB write exceeds max retry</code> kind of error, two possible solutions are:</p> <ul> <li>increase the number of retries to handle possible throttled DynamoDB write operations to the target table, as suggested here;</li> <li>prepare the target table with a \"pre-warm\" phase.</li> </ul> <p>For reference, a test made with a 4,5 GB table took about 35 minutes, generating a total cost of 17 USD:</p> <ul> <li>7,4 USD for the execution of the Glue job (source account)</li> <li>2 USD for the read operations onto the source DynamoDB table (source account)</li> <li>7,6 USD for the write operations onto the target DynamoDB table (target account)</li> </ul> <ol> <li> <p>This table must already exists.\u00a0\u21a9</p> </li> <li> <p>This is needed to let Glue download the job script from S3 assets bucket.\u00a0\u21a9</p> </li> </ol>","tags":["AWS","Database"]},{"location":"2024/01/03/terminal-user-interface/","title":"Terminal User Interface","text":"<p>If you have an already up-and-running Typer app, you might want to extend it to some sort of GUI (Graphical User Interface).</p> <p>While building a full GUI can be time-consuming, there is a really fast utility which can be adopted to get somewhere in between.</p> <p>We can indeed take advantage of Click, the command line interfaces builder underlying Typer itself. Since the former has been eagerly adopted almost anywhere a CLI is required, it represents a leader in the Python ecosystem.</p> <p>Given so, other libraries have built on-top of Click as Typer did: one of them is Trogon, which basically provides TUI (Terminal User Interface) based on Textual around Click apps.</p> <p>As pointed out in this thread, Trogon can therefore do his job also on Typer apps:</p> <pre><code>import typer\nfrom trogon import Trogon\nfrom typer.main import get_group\n\napp = typer.Typer()\n\n# ... pre-existing Typer app\n\n@app.command()\ndef launch_tui(ctx: typer.Context):\n    Trogon(get_group(app), click_context=ctx).run()\n</code></pre> <p>This is a nice add-on for Typer apps, which still remain completely available: Trogon's TUI just corresponds to a brand new command in a Typer app i.e., <code>launch-tui</code> in the above example.</p>","tags":["Python"]},{"location":"2020/05/12/a-guide-to-transportation-problems/","title":"A guide to transportation problems","text":"","tags":["OR"]},{"location":"2020/05/12/a-guide-to-transportation-problems/#classic-formulation","title":"Classic formulation","text":"<p>Let \\(\\mathcal{G}\\) be a complete bipartite directed graph, with disjoint sets of vertices \\(\\mathcal{S}=\\{s_i\\}_{i=1}^{m}\\) and \\(\\mathcal{D}=\\{d_j\\}_{j=1}^{n}\\) interpreted respectively as supply nodes and demand nodes.</p> <p>For all \\(i=1,\\dots,m,\\;j=1,\\dots,n\\) let:</p> <ul> <li>\\(c_{ij}\\) represent the (unitary) transportation cost between     \\(s_i\\) and \\(d_j\\) and \\(C=\\left(c_{ij}\\right)\\) the corresponding     \\(m\\times n\\) matrix</li> <li>\\(x_{ij}\\geq 0\\) represent the amount of product transported between     \\(s_i\\) and \\(d_j\\)</li> <li>\\(S_i\\) amount of available product (supply) at node \\(s_i\\)</li> <li>\\(D_j\\) amount of required product (demand) at node \\(d_j\\)</li> </ul> <p>We then define the transportation problem as the linear programming problem of minimize the total transportation cost subject to supply and demand constraints i.e.,</p> <p>\\(\\min\\limits_{x}\\sum\\limits_{i=1}^m\\sum\\limits_{j=1}^n c_{ij}x_{ij}\\) s.t.</p> <ul> <li>supply constraint:     \\(\\sum\\limits_{j=1}^n x_{ij}\\leq S_i \\;\\;\\forall i=1,\\dots,m\\)</li> <li>demand constraint:     \\(\\sum\\limits_{i=1}^m x_{ij}\\geq D_j \\;\\;\\forall j=1,\\dots,n\\)</li> </ul>","tags":["OR"]},{"location":"2020/05/12/a-guide-to-transportation-problems/#balancing","title":"Balancing","text":"<p>We define two quantities that play a crucial role within transportation problem framework: total supply and total demand in the network, respectively expressed as \\(S^*=\\sum_{i=1}^m S_i\\) and analogously \\(D^*=\\sum_{j=1}^n D_j\\). The problem is said to be balanced if \\(S^* = D^*\\) and unbalanced otherwise. In case of an unbalanced transportation problem, is convenient to distinguish two cases:</p> <ul> <li>if \\(D^* &gt; S^*\\) the problem is infeasible because there is not     enough supply to satisfy the given demand</li> <li>if \\(S^* &gt; D^*\\) the problem is in turn feasible thanks to the     excess supply which makes no harm to any of the constraints</li> </ul> <p>Since in the former case is possible to state a priori that the problem will result in an infeasible one, is convenient to propose a general balancing method for a transportation problem:</p> <ul> <li>if \\(D^* &gt; S^*\\), we can add a dummy supply which is accountable     for unmet demand i.e., a node \\(s_{m+1}\\) such that     \\(S_{m+1}=D^* - S^*\\). In this case, we are expanding costs matrix     \\(C\\) by adding a new row. Each of its elements \\(c_{m+1,j}\\) will     represent the cost penalty associated with unmet demand for demand     node \\(d_j\\). In a proper supply chain framework, this penalty can     be thought as the financial loss for the unmet demand, as well as     the buying-in cost for satisfying the (otherwise unmet) demand. In a     costs minimization perspective, the higher is \\(c_{m+1,j}\\) the     lower will be \\(x_{m+1,j}\\): this means that we have a first way to     influence the shape of the solution according to our (business)     needs.</li> <li>if \\(S^* &gt; D^*\\), even if the problem would be feasible, is     convenient to mirror the above technique by adding a dummy demand     accountable for unexploited supply i.e., a node \\(d_{n+1}\\) such     that \\(D_{n+1}=S^* - D^*\\). Again, we are implicitly expanding costs     matrix by adding a new column in which each element \\(c_{i, n+1}\\)     will represent cost associated with unexploited supply. In a supply     chain framework, this can be interpreted as storage cost for excess     supply, and all the considerations made above about the relationship     with \\(x_{i,n+1}\\) still hold.</li> </ul> <p>In the following we will consider only balanced transportation problems, in which the balancing has might been restored with one of the above procedures. In particular, we will therefore consider both the constraints as equalities. For such a problem the following holds:</p>","tags":["OR"]},{"location":"2020/05/12/a-guide-to-transportation-problems/#theorem-1","title":"Theorem 1","text":"<p>Given a balanced transportation problem assigned over a complete bipartite directed graph \\(\\mathcal{G}\\), the problem admits at least one feasible solution.</p>","tags":["OR"]},{"location":"2020/05/12/a-guide-to-transportation-problems/#transportation-tableau","title":"Transportation tableau","text":"<p>Transportation problem data are often summarized and visualized on a table called transportation tableau (see picture above). It basically consists in the costs matrix \\(C\\), with the addition of a bottom row containing the demands and a right column containing the supplies. Moreover, it\u2019s useful also to hold the decision variables \\(x_{ij}\\) as well as the total supply \\(S^*\\) and the total demand \\(D^*\\).</p>","tags":["OR"]},{"location":"2020/05/12/a-guide-to-transportation-problems/#heuristics","title":"Heuristics","text":"<p>Based on the transportation tableau, several heuristics have been studied in order to find an initial basic feasible solution to the transportation problem. The most used are:</p> <ul> <li>North West Corner method</li> <li>Least Cost method</li> <li>Vogel\u2019s Approximation method</li> </ul> <p>They basically consist in algorithm than can be performed (also) by a human in order to match the problem constraints while distributing product amount amongst each \\(x_{ij}\\) (in a \u201cSudoku-like\u201d approach) see here. Given an initial basic feasible solution, several techniques can be used to improve it in order to lower the corresponding objective function value (e.g.\u00a0simplex method, evolutionary algorithms, Hungarian method).</p> <p>We have seen that a classic transportation problem can be solved through several heuristics, even if possibly not in an optimal way. It\u2019s anyway convenient, whenever possible, to approach it in a LP perspective, mostly to take advantages of all the linear programming techniques and libraries available.</p> <p>The transportation problem can be approach as:</p> <ul> <li>a classic LP problem with continuous decision variables i.e.,     \\(x_{ij}\\in\\mathbb{R}_{\\geq 0}\\);</li> <li>an ILP/MIP problem if \\(x_{ij}\\in\\mathbb{N}\\) i.e., if it\u2019s more     convenient to express the decision variables in terms of (integer)     number of transports needed to satisfy the constraints. In this     case, we must assume that the transportation costs do not depend on     the amount of product transported along each route - to preserve     linearity - and we also have to properly adjust objective function     and constraints formulation to behave accordingly with the change in     measurement units.</li> </ul>","tags":["OR"]},{"location":"2020/05/12/a-guide-to-transportation-problems/#lp-advantages","title":"LP advantages","text":"","tags":["OR"]},{"location":"2020/05/12/a-guide-to-transportation-problems/#sensitivity-analysis","title":"Sensitivity analysis","text":"<p>LP formulation and implementation can guarantee several advantages in approaching a transportation problem.</p> <p>One of them is the sensitivity analysis: defined \\(x^*\\) as the optimal solution (or the set of optimal solutions) and \\(f\\) the problem objective function, the sensitivity analysis leds to study changes in \\(x^*\\) and \\(f(x^*)\\) as functions of problem data.</p> <p>For example, in the transportation problem framework, one of the sensitivity analysis goal is to answer to questions such as:</p> <ul> <li>how much and how costs decrease when supply increases of 1 unit?</li> <li>how much and how costs increase when demand increases of 1 unit?</li> </ul>","tags":["OR"]},{"location":"2020/05/12/a-guide-to-transportation-problems/#slack-variables","title":"Slack variables","text":"<p>Another advantage of a LP approach is represented by slack variables, which enable the elastic relaxation of a given problem.</p> <p>For example, we can consider the supply constraint \\(\\sum_{j=1}^n x_{ij}\\leq S_i\\) for a given supply node \\(s_i\\). This constraint requires that the amount of product going out from \\(s_i\\) is at most equal to the node capacity i.e., \\(S_i\\). Another way to monitor such a request is to keep track of the difference \\(\\nu_i:= \\sum_{j=1}^n x_{ij} - S_i\\). If \\(\\nu_i\\leq 0\\), the constraint has been observed, if \\(\\nu_i&gt;0\\) the constraint has been violated.</p> <p>Having observed so, we can then relax the supply constraint by restating it as follows:</p> <p>\\(\\sum\\limits_{j=1}^n x_{ij}-\\nu_i\\leq S_i\\)</p> <p>where \\(\\nu_i\\) is a decision variable taking values in \\([0, U_i]\\) - called slack variable - which objective is to soften the constraint possibly allowing to excess the given supply \\(S_i\\).</p> <p>The main purpose of slack variables is to locate infeasibility causes: if the resolution of the problem seems impossible, we can add one slack variable for each constraint, taking care of adding it also to the objective function multiplying it by a (big) penalty factor. After the successful resolution procedure, whenever a slack variable hits a nonzero value it means that, despite its penalty factor in the objective function, its usage has been crucial to the resolution itself i.e., in making the problem actually feasible.</p> <p>In general:</p> <ul> <li>for a \\(\\leq\\) constraint we should subtract the slack variable from     the left side of the constraint i.e., where decision variables are     located;</li> <li>for a \\(\\geq\\) constraint we should add the slack variable to the     left side of the constraint;</li> <li>for a \\(=\\) constraint we should split the slack variable in its     positive and negative part and respectively add and subtract these     components to the left side of the constraint;</li> <li>the slack variable must be added (if the goal is to minimize) /     subtracted (if the goal is to maximize) from the objective function     by multiplying it with a (big) penalty factor - to ensure its usage     \u201conly if needed\u201d.</li> </ul> <p>If any slack variable has been introduced and has been used in problem resolution, we must refactor the objective function value to restore its meaning with respect to the underlying business framework and units of measurements.</p>","tags":["OR"]},{"location":"2020/05/12/a-guide-to-transportation-problems/#multi-objective-programming","title":"Multi-objective programming","text":"<p>LP framework enables also to address multi-objective problems, in which for example we are interested in chase both \\(\\min f_1\\) and \\(\\min f_2\\) - we can consider both as minimization objectives thanks to the equivalence \\(\\max(f) = -\\min(-f)\\). A more rigorous definition of chasing more objectives can be stated in a Pareto perspective: we could be interested in finding \\(x^*\\) such that, if there exists another \\(x'\\) such that \\(f_1(x')&lt;f_1(x^*)\\), then \\(f_2(x')&gt;f_2(x^*)\\). In other words our aim could be find a \\(x^*\\) which is Pareto-optimal i.e., a preferred solution such that any other candidate solution which significantly improves one of the objectives ends up worsening the other see here.</p> <p>In such cases we can exploit one of the following techniques:</p> <ul> <li>relaxed formulation: address one of the two objectives as the     \u201creal\u201d objective of our LP problem, by adding the relaxed version     of the other within the problem constraints. For example     \\(\\min f_1\\) subject to \\(f_2\\leq \\varepsilon\\) where     \\(\\varepsilon\\) is an upper bound on \\(f_2\\) known a priori;</li> <li>elastic formulation: mix the objectives with a convex combination     of parameters to encapsulate them into a single objective. For     example \\(\\min\\lambda f_1 + (1-\\lambda)f_2\\) where     \\(\\lambda\\in[0,1]\\) controls the weight given to each of the     original objectives;</li> <li>sequential formulation: solve a single objective problem with one     of the two objectives, for example \\(\\min f_1\\) finding \\(x^*\\) as     optimal solution, and then approaching a second single objective     problem, for example \\(\\min f_2\\), by adding a constraint to     preserve the former optimality i.e., \\(f_1(x)\\leq f_1(x^*)\\).</li> </ul>","tags":["OR"]},{"location":"2020/05/12/a-guide-to-transportation-problems/#problem-variations","title":"Problem variations","text":"","tags":["OR"]},{"location":"2020/05/12/a-guide-to-transportation-problems/#transshipment-nodes","title":"Transshipment nodes","text":"<p>The classic formulation can be extended to a more general case where the product goes from the supply nodes to the demand ones through one (resp. \\(k\\)) layer of intermediary nodes, which is implicitly equivalent to change the underlying graph structure to the union of two (resp. \\(k+1\\)) complete bipartite graphs which share one set of nodes. In such a case, we refer to the shared layer of nodes with \\(\\mathcal{T}=\\{t_k\\}_{k=1}^p\\) and the problem objective will change as follows</p> <p>\\(\\min\\limits_{x}\\sum\\limits_{i=1}^m\\sum\\limits_{k=1}^p c_{ik}x_{ik} + \\sum\\limits_{k=1}^p\\sum\\limits_{j=1}^n c_{kj}x_{kj}\\)</p> <p>Both the supply and demand constraints must be changed accordingly (since no longer exists a direct connection between \\(\\mathcal{S}\\) and \\(\\mathcal{D}\\)), and the transshipment constraint must be added in the following form</p> <p>\\(\\sum\\limits_{i=1}^m x_{ik}=\\sum\\limits_{j=1}^n x_{kj}\\;,\\;\\;\\forall k=1,\\dots,p\\)</p> <p>assuming no storage is allowed within transshipment nodes. </p>","tags":["OR"]},{"location":"2020/05/12/a-guide-to-transportation-problems/#sortation-centers","title":"Sortation centers","text":"<p>The intermediaries of the middle layer can be interpreted also as sortation centers. In this case, a mixture between transportation problem and assignment problem better fits our needs: the classic transportation problem can be applied to the transportation of products between supply nodes and sortation centers, and then an assignment problem can be used to optimize the accountability of sortation centers with respect to final customer demands (this strategy is a simple yet good model of Amazon logistics).</p> <p>In this case, the problem formulation can be changed as follows</p> <p>\\(\\min\\limits_{x,y}\\sum\\limits_{i=1}^m\\sum\\limits_{k=1}^p c_{ik}x_{ik} + \\sum\\limits_{k=1}^p\\sum\\limits_{j=1}^n c_{kj}y_{kj}\\)</p> <p>where the introduced new decision variables \\(y_{kj}\\in\\{0,1\\}\\) are binary variables which represent the assignment of sortation between \\(t_k\\) and \\(d_j\\), with corresponding sortation cost \\(c_{kj}\\). The constraint of such a model are the following:</p> <ul> <li>supply constraint:     \\(\\sum\\limits_{k=1}^p x_{ik}\\leq S_i \\;\\;\\forall i=1,\\dots,m\\)</li> <li>sortation decoupling:     \\(\\sum\\limits_{k=1}^p y_{kj} = 1\\;\\;\\forall j=1,\\dots,n\\)</li> <li>demand constraint:     \\(\\sum\\limits_{i=1}^m x_{ik} = \\sum\\limits_{j=1}^n y_{kj}\\cdot D_j \\;\\;\\forall k=1,\\dots,p\\)</li> </ul>","tags":["OR"]},{"location":"2020/05/12/a-guide-to-transportation-problems/#multi-commodity-transportation","title":"Multi-commodity transportation","text":"<p>In the case of a transportation problem which involves the transportation of more than one product, the \u201cproduct\u201d variable can be taken into account in the LP framework switching to a three-dimension tensor of decision variables \\(x_{ijh}\\), each representing the amount of product \\(p_h\\) transported from \\(s_i\\) to \\(d_j\\).</p>","tags":["OR"]},{"location":"2020/05/12/a-guide-to-transportation-problems/#duality","title":"Duality","text":"<p>For reference see this article.</p>","tags":["OR"]},{"location":"2020/05/12/a-guide-to-transportation-problems/#an-example","title":"An example","text":"<p>Let us consider the following maximization problem \\(\\max 2x_1 + 3x_2\\) s.t.</p> <ul> <li>\\(4x_1 + 8x_2 \\leq 12\\;\\;(1)\\)</li> <li>\\(2x_1 + x_2 \\leq 3\\;\\;(2)\\)</li> <li>\\(3x_1 + 2x_2 \\leq 4\\;\\;(3)\\)</li> <li>\\(x_1, x_2 \\geq 0\\;\\;(4)\\)</li> </ul> <p>Thanks to nonnegativity constraint (4), we can observe for example that the objective function has an upper bound given by the left side of (1): this ensures that the objective function is bounded by 12. Similarly, the same holds dividing the left side of (1) by 2: we have then a better upper bound on the objective function i.e., 6: this is the inspiration for the following discussion.</p> <p>Given \\(f\\) the objective function of our LP problem, is then possible to write \\(f\\) as a linear combination of variables \\(x_j\\) i.e., \\(f(x_1,\\dots,x_n)=\\sum_{j=1}^nc_jx_j\\), and the same holds for the left side of each constraint, which can be represented by a function \\(g_i\\) such that \\(g_i(x_1,\\dots,x_n)=\\sum_{j=1}^na_{ij}x_j\\leq b_i\\). As in the above example, we are then interested in finding a linear combination of the given constraints which constitutes an upper bound on \\(f\\) i.e., \\(f\\leq\\sum_{j=1}^nd_jx_j\\leq M\\) where \\(d_j\\geq c_j\\) for all \\(j=1,\\dots, n\\). In the example, we are looking for a combination</p> <p>\\(d_1x_1 + d_2x_2\\leq M\\)</p> <p>where \\(d_1\\geq 2\\) and \\(d_2\\geq 3\\).</p> <p>For doing so, we can consider a linear combination \\(\\sum_{j=1}^nd_j(y_1,\\dots,y_p)x_j=\\sum_{i=1}^py_ig_i(x_1,\\dots,x_n)\\leq\\sum_{i=1}^pb_iy_i=M\\) where \\(y_i\\geq 0\\) are brand new variables linked with the original constraints. In the example, the linear combination is</p> <p>\\(y_1\\left(4x_1 + 8x_2\\right) + y_2\\left(2x_1 + x_2\\right) + y_3\\left(3x_1 + 2x_2\\right) \\leq 12y_1 + 3y_2 + 4y_3\\)</p> <p>which correspondes to</p> <p>\\(\\left(4y_1+2y_2+3y_3\\right)x_1 + \\left(8y_1+y_2+2y_3\\right)x_2\\leq 12y_1 + 3y_2 + 4y_3\\)</p> <p>As per the intro of this section, our goal is to find the best possible upper bound on \\(f\\) i.e., to lower as much as we can the upper bound \\(M\\) which controls \\(f\\) from above while respecting the constraints \\(d_j\\geq c_j\\) for all \\(j=1,\\dots,n\\). We have then implicitly defined a new LP problem, corresponding to the original one, i.e. \\(\\min 12y_1 + 3y_2 + 4y_3\\) s.t.</p> <ul> <li>\\(4y_1+2y_2+3y_3 \\geq 2\\;\\;(1)\\)</li> <li>\\(8y_1+y_2+2y_3 \\geq 3\\;\\;(2)\\)</li> <li>\\(y_1, y_2, y_3 \\geq 0\\;\\;(3)\\)</li> </ul>","tags":["OR"]},{"location":"2020/05/12/a-guide-to-transportation-problems/#dual-problem","title":"Dual problem","text":"<p>We have just figured out that a minimization problem corresponds in a \u201cnatural way\u201d to a maximization one, and viceversa. In general we have that to a minimization problem \\(\\min b^Ty\\) s.t.</p> <ul> <li>\\(A^Ty\\geq c\\)</li> <li>\\(y\\geq 0\\)</li> </ul> <p>corresponds a maximization problem \\(\\max c^Tx\\) s.t.</p> <ul> <li>\\(Ax\\leq b\\)</li> <li>\\(x\\geq 0\\)</li> </ul> <p>Given the privileged perspective of the transportation problem framework (minimization), we will call the former primal problem \\(\\mathfrak{P}\\) and the latter its dual problem \\(\\mathfrak{D}\\).</p>","tags":["OR"]},{"location":"2020/05/12/a-guide-to-transportation-problems/#theorem-2","title":"Theorem 2","text":"<p>Any feasible solution of \\(\\mathfrak{D}\\) is a lower bound on the objective function of \\(\\mathfrak{P}\\).</p>","tags":["OR"]},{"location":"2020/05/12/a-guide-to-transportation-problems/#theorem-3","title":"Theorem 3","text":"<p>One of the following holds:</p> <ol> <li>both \\(\\mathfrak{P}\\) and \\(\\mathfrak{D}\\) are infeasible;</li> <li>\\(\\mathfrak{P}\\) is unbounded and \\(\\mathfrak{D}\\) is infeasible;</li> <li>\\(\\mathfrak{P}\\) is infeasible and \\(\\mathfrak{D}\\) is unbounded;</li> <li>both \\(\\mathfrak{P}\\) and \\(\\mathfrak{D}\\) are feasible.     Furthermore, for any \\(y^*\\) solution of \\(\\mathfrak{P}\\) and     \\(x^*\\) solution of \\(\\mathfrak{D}\\), the equation \\(b^Ty^*=c^Tx^*\\)     holds, which means that \\(\\min\\mathfrak{P}=\\max\\mathfrak{D}\\).</li> </ol>","tags":["OR"]},{"location":"2020/05/12/a-guide-to-transportation-problems/#transportation-dual-problem","title":"Transportation dual problem","text":"<p>A possible formulation of the dual problem of the (primal) classic transportation problem defined above, with equalities constraints, is the following \\(\\max\\sum\\limits_{j=1}^nD_jv_j-\\sum\\limits_{i=1}^mS_iu_i\\) s.t. \\(v_j-u_i\\leq c_{ij}\\)</p> <p>To understand and interpret this dual problem, let us refer to this notes.</p> <p>Consider the need of transportation expressed by the business stakeholders and modeled with the primal problem.</p> <p>Imagine now that the business wants to outsource the transportation and finds an external company which offers such a service in a particular way: it offers to buy product at price \\(u_i\\) at each supply nodes, transport it and resell the same amount at demand nodes at price \\(v_j\\). Since the original transportation cost from \\(s_i\\) to \\(d_j\\) was \\(c_{ij}\\), from a cost perspective the business should only ensure that \\(v_j - u_i\\) is lower than \\(c_{ij}\\): the dual constraint represents this condition. From the external company point of view, it represents a condition to be matched to make the proposal appealing for the customer (our business).</p> <p>The dual objective function represents the net revenue of the external company in managing transportation along the network while satisfying customer constraints in terms of supply and demand.</p>","tags":["OR"]},{"location":"2020/05/12/a-guide-to-transportation-problems/#extensions-to-other-graph-structures","title":"Extensions to other graph structures","text":"<p>This section goal is to discuss the following question: what happens to Theorem 1 if \\(\\mathcal{G}\\) is not a complete bipartite graph anymore? Or, in other words, which are minimal balancing actions needed to ensure problem feasibility at the change of the underlying graph structure?</p> <p>This is crucial because in a given business framework not all routes between \\(\\mathcal{S}\\) and \\(\\mathcal{D}\\) might be admissible. In such a case, graph connectivity can be \u201creduced\u201d and therefore the problem could reveals to be infeasible subject to the given constraint.</p>","tags":["OR"]},{"location":"2020/05/12/a-guide-to-transportation-problems/#theorem-4","title":"Theorem 4","text":"<p>Consider a feasible transportation problem assigned over a bipartite directed graph \\(\\mathcal{G}\\). For each demand node \\(d_j\\) let \\(\\mathcal{S}^j\\) be the set of indices of supply nodes adjacent to \\(d_j\\). Then we have</p> <p>\\(\\sum\\limits_{i\\in\\mathcal{S}^j} S_i\\geq D_j\\)</p> <p>This theorem provides a necessary condition to be checked in order to ensure feasibility for a transportation problem assigned over a generic bipartite graph: the sum of supplies of supply nodes adjacent to a given demand node must be at least equal to the demand of that node. This is a necessary condition which partially overcomes the possibly \u201cinsufficient\u201d graph connectivity.</p> <p>Unfortunately, since Theorem 1 does not hold if \\(\\mathcal{G}\\) isn\u2019t complete and Theorem 4 gives only a necessary condition, we are still  without a set of sufficient conditions for feasibility of a transportation problem assigned over a generic bipartite directed graph. Given the relationship between graph structure and supply-demand constraints, any useful condition must take into account the flow of product that can be assigned over the network (max-flow connectivity, min-cut connectivity, etc.).</p>","tags":["OR"]},{"location":"2020/05/12/a-guide-to-transportation-problems/#a-custom-heuristics","title":"A custom heuristics","text":"<p>In order to solve a transportation problem over a \u201cgeneric\u201d graph and to overcome the lack of a proper Theorem to ensure feasibility, a custom heuristics to \u201cbalance\u201d the given problem before submitting it to the actual solver is below.</p> <p>In particular, we search for \\(\\mathcal{D}^i\\) (defined similarly to \\(\\mathcal{S}^j\\)) sets for each \\(s_i\\) and define the maximal set of suppliers adjacent to nodes in \\(\\mathcal{D}^i\\), denoting this set as \\(\\mathcal{S}(\\mathcal{D}^i)\\). Then we refer to supplier nodes in \\(\\mathcal{S}(\\mathcal{D}^i)\\) as critical suppliers in the following cases:</p> <ul> <li>if \\(\\left|\\mathcal{D}^i\\right|=1\\);</li> <li>if \\(\\left|\\mathcal{D}^i\\right|=2\\) and     \\(\\left|\\mathcal{S}(\\mathcal{D}^i)\\right|=1\\).</li> </ul> <p>We then sum up the supply of all the critical suppliers and create a dummy supply node, adjacent to all demand nodes, accountable for this quantity: this helps preventing the unattainability of the critical suppliers, which might affect problem feasibility.</p>","tags":["OR"]},{"location":"2020/05/12/a-guide-to-transportation-problems/#resources","title":"Resources","text":"<ol> <li>TP in PuLP</li> <li>TP in Scipbook</li> <li>Min cost flow problem by OR-tools</li> <li>TP heuristics</li> <li>OR for programmers</li> </ol>","tags":["OR"]},{"location":"resources/","title":"Resources","text":"<p>Info</p> <p>Here you can find a curated (yet opinionated) collection of links to useful online resources.</p> <ul> <li>AWS: Amazon Web Service related stuff.</li> <li>Career: how to shape a data career and nail down job interviews!</li> <li>Data Engineering: data architectures, monitoring and observability, DevOps and others data engineering best practices.</li> <li>Data Science: data science, in the widest meaning of the term.</li> <li>Data Visualization: information and data visualization, both methodology and implementation.</li> <li>Education: collection of resources for an effective data education.</li> <li>Misc: a salad of math, physics and the rest of hard sciences.</li> <li>Python: Python, my actual programming language.</li> <li>Snippets: the temple of DRY, collection of snippets of reusable code.</li> <li>Tools: toolbox full of utilities.</li> <li>Training: books, MOOC, certifications and everything else about training.</li> </ul>"},{"location":"resources/aws/","title":"AWS","text":""},{"location":"resources/aws/#services","title":"Services","text":""},{"location":"resources/aws/#api-gateway","title":"API Gateway","text":"<ul> <li>Accessing API Gateway from VPC</li> </ul>"},{"location":"resources/aws/#athena","title":"Athena","text":"<ul> <li>Athena window functions (prestodb)</li> <li>Extend geospatial queries in Amazon Athena with UDFs and AWS Lambda</li> </ul>"},{"location":"resources/aws/#cdk","title":"CDK","text":"<ul> <li>AWS CDK best practices</li> <li>AWS CDK</li> <li>AWS CloudWatch custom metrics dashboard via CDK</li> <li>A no-nonsense guide to AWS CDK</li> <li>Constructs vs stacks</li> <li>AWS DDK: DataOps Development Kit</li> <li>Serverless AWS CDK Pipeline best practices</li> <li>How working with AWS CDK made me a better dev</li> <li>Optimize your AWS CDK Project Structure for Growth</li> <li>Self-destroying and ephemeral stacks</li> <li>Using AWS CloudFormation and AWS Cloud Development Kit to provision multicloud resources</li> <li>The Lambda trilogy</li> </ul>"},{"location":"resources/aws/#dependencies-between-stacks","title":"Dependencies between stacks","text":"<ul> <li>The base stack</li> <li>Deployment issue with cross-stack dependencies</li> <li>Nested stacks</li> <li>Share resources between stacks</li> <li>CDK dependsOn relation</li> </ul>"},{"location":"resources/aws/#codebuild","title":"CodeBuild","text":"<ul> <li>Docker layer caching for CodeBuild</li> <li>serving Sphinx docs on S3</li> <li>Continuous Deployment using AWS CodeBuild with CDK</li> </ul>"},{"location":"resources/aws/#codepipeline","title":"CodePipeline","text":"<ul> <li>AWS Pipeline for continuous deployment via Lambda</li> </ul>"},{"location":"resources/aws/#data-wrangler","title":"Data Wrangler","text":"<ul> <li>AWS Data Wrangler</li> </ul>"},{"location":"resources/aws/#dynamo-db","title":"Dynamo DB","text":"<ul> <li><code>LucidDynamodb</code> python wrapper</li> </ul>"},{"location":"resources/aws/#ec2","title":"EC2","text":"<ul> <li>EC2 ssh with <code>argparse</code></li> <li>Deploy Tiny-Llama on AWS EC2</li> </ul>"},{"location":"resources/aws/#fargate","title":"Fargate","text":"<ul> <li>ML pipeline on Fargate</li> </ul>"},{"location":"resources/aws/#iam","title":"IAM","text":"<ul> <li>All AWS managed policies</li> <li>IAMbic: Cloud IAM as Code</li> </ul>"},{"location":"resources/aws/#lambda","title":"Lambda","text":"<ul> <li>AWS Lambda power tuning</li> <li>AWS Lambda tests</li> <li>Lambda function with container image</li> <li>Optimizing Lambda functions</li> </ul>"},{"location":"resources/aws/#s3","title":"S3","text":"<ul> <li>Building and operating a pretty big storage system called S3</li> </ul>"},{"location":"resources/aws/#sagemaker","title":"SageMaker","text":"<ul> <li>KNN on SageMaker</li> <li>SageMaker ScriptProcessor</li> <li>Automatic canary releases for ML models</li> <li>Cross-validation via SageMaker and Step functions</li> <li>Run custom model via SageMaker (e.g. OR-Tools solver)</li> <li>Automating ML Training on AWS</li> </ul>"},{"location":"resources/aws/#shell","title":"Shell","text":"<ul> <li>AWS shell</li> </ul>"},{"location":"resources/aws/#utils","title":"Utils","text":""},{"location":"resources/aws/#devops","title":"DevOps","text":"<ul> <li>Deployment Pipeline Reference Architecture (DPRA) for AWS workloads</li> <li>DevOps Essentials</li> <li>12 DevOps Best Practices That Make Deploying on Fridays Less Scary</li> </ul>"},{"location":"resources/aws/#blogposts","title":"Blogposts","text":"<ul> <li>The history of Amazon forecasting algorithm</li> </ul>"},{"location":"resources/aws/#misc","title":"Misc","text":"<ul> <li>SLAM</li> <li>MOTO for local test of aws resources</li> <li>MOTO tutorial</li> <li>Steampipe: query the cloud with plain SQL</li> <li>Dynamoit: a custom frontend for DynamoDB</li> <li>Basti: a CLI tool for securely accessing AWS resources in private networks at almost no cost</li> <li>klotho: an open source tool that transforms plain code into cloud native code</li> </ul>"},{"location":"resources/aws/#streamlit-deployment","title":"Streamlit deployment","text":"<ul> <li>Streamlit deploy on EC2</li> <li>Streamlit deploy with Fargate</li> <li>Streamlit dashboard deployment via ECS</li> </ul>"},{"location":"resources/aws/#infographics","title":"Infographics","text":"<ul> <li>AWS Fundamentals</li> </ul>"},{"location":"resources/aws/services/","title":"Services","text":""},{"location":"resources/aws/services/#api-gateway","title":"API Gateway","text":"<ul> <li>Accessing API Gateway from VPC</li> </ul>"},{"location":"resources/aws/services/#athena","title":"Athena","text":"<ul> <li>Athena window functions (prestodb)</li> <li>Extend geospatial queries in Amazon Athena with UDFs and AWS Lambda</li> </ul>"},{"location":"resources/aws/services/#cdk","title":"CDK","text":"<ul> <li>AWS CDK best practices</li> <li>AWS CDK</li> <li>AWS CloudWatch custom metrics dashboard via CDK</li> <li>A no-nonsense guide to AWS CDK</li> <li>Constructs vs stacks</li> <li>AWS DDK: DataOps Development Kit</li> <li>Serverless AWS CDK Pipeline best practices</li> <li>How working with AWS CDK made me a better dev</li> <li>Optimize your AWS CDK Project Structure for Growth</li> <li>Self-destroying and ephemeral stacks</li> <li>Using AWS CloudFormation and AWS Cloud Development Kit to provision multicloud resources</li> <li>The Lambda trilogy</li> </ul>"},{"location":"resources/aws/services/#dependencies-between-stacks","title":"Dependencies between stacks","text":"<ul> <li>The base stack</li> <li>Deployment issue with cross-stack dependencies</li> <li>Nested stacks</li> <li>Share resources between stacks</li> <li>CDK dependsOn relation</li> </ul>"},{"location":"resources/aws/services/#codebuild","title":"CodeBuild","text":"<ul> <li>Docker layer caching for CodeBuild</li> <li>serving Sphinx docs on S3</li> <li>Continuous Deployment using AWS CodeBuild with CDK</li> </ul>"},{"location":"resources/aws/services/#codepipeline","title":"CodePipeline","text":"<ul> <li>AWS Pipeline for continuous deployment via Lambda</li> </ul>"},{"location":"resources/aws/services/#data-wrangler","title":"Data Wrangler","text":"<ul> <li>AWS Data Wrangler</li> </ul>"},{"location":"resources/aws/services/#dynamo-db","title":"Dynamo DB","text":"<ul> <li><code>LucidDynamodb</code> python wrapper</li> </ul>"},{"location":"resources/aws/services/#ec2","title":"EC2","text":"<ul> <li>EC2 ssh with <code>argparse</code></li> <li>Deploy Tiny-Llama on AWS EC2</li> </ul>"},{"location":"resources/aws/services/#fargate","title":"Fargate","text":"<ul> <li>ML pipeline on Fargate</li> </ul>"},{"location":"resources/aws/services/#iam","title":"IAM","text":"<ul> <li>All AWS managed policies</li> <li>IAMbic: Cloud IAM as Code</li> </ul>"},{"location":"resources/aws/services/#lambda","title":"Lambda","text":"<ul> <li>AWS Lambda power tuning</li> <li>AWS Lambda tests</li> <li>Lambda function with container image</li> <li>Optimizing Lambda functions</li> </ul>"},{"location":"resources/aws/services/#s3","title":"S3","text":"<ul> <li>Building and operating a pretty big storage system called S3</li> </ul>"},{"location":"resources/aws/services/#sagemaker","title":"SageMaker","text":"<ul> <li>KNN on SageMaker</li> <li>SageMaker ScriptProcessor</li> <li>Automatic canary releases for ML models</li> <li>Cross-validation via SageMaker and Step functions</li> <li>Run custom model via SageMaker (e.g. OR-Tools solver)</li> <li>Automating ML Training on AWS</li> </ul>"},{"location":"resources/aws/services/#shell","title":"Shell","text":"<ul> <li>AWS shell</li> </ul>"},{"location":"resources/aws/utils/","title":"Utils","text":""},{"location":"resources/aws/utils/#devops","title":"DevOps","text":"<ul> <li>Deployment Pipeline Reference Architecture (DPRA) for AWS workloads</li> <li>DevOps Essentials</li> <li>12 DevOps Best Practices That Make Deploying on Fridays Less Scary</li> </ul>"},{"location":"resources/aws/utils/#blogposts","title":"Blogposts","text":"<ul> <li>The history of Amazon forecasting algorithm</li> </ul>"},{"location":"resources/aws/utils/#misc","title":"Misc","text":"<ul> <li>SLAM</li> <li>MOTO for local test of aws resources</li> <li>MOTO tutorial</li> <li>Steampipe: query the cloud with plain SQL</li> <li>Dynamoit: a custom frontend for DynamoDB</li> <li>Basti: a CLI tool for securely accessing AWS resources in private networks at almost no cost</li> <li>klotho: an open source tool that transforms plain code into cloud native code</li> </ul>"},{"location":"resources/aws/utils/#streamlit-deployment","title":"Streamlit deployment","text":"<ul> <li>Streamlit deploy on EC2</li> <li>Streamlit deploy with Fargate</li> <li>Streamlit dashboard deployment via ECS</li> </ul>"},{"location":"resources/aws/utils/#infographics","title":"Infographics","text":"<ul> <li>AWS Fundamentals</li> </ul>"},{"location":"resources/career/","title":"Career","text":""},{"location":"resources/career/#career-development","title":"Career development","text":"<ul> <li>Roles in a Data Science team</li> <li>Measuring developer productivity</li> <li>Google: five keys to a successful team</li> <li>Google: what makes a great manager</li> <li>When and how build your data science team</li> <li>Data science leaders to follow</li> <li>Leading a software development team</li> <li>From Senior to Chief data scientist</li> <li>How to not lose tech skills being a Manager</li> <li>Career ladders and self-evaluation grid</li> <li>How to build and lead a Data Science team</li> <li>Diversity leads to better solutions</li> <li>15 habits for highly effective data scientists</li> <li>7 traits for incredibly efficient data scientists</li> <li>How to scale a data team</li> <li>How writing can advance your career</li> <li>Stretch work assignments for personal growth</li> <li>Code quality as a competitive advantage</li> <li>The Information Architect</li> <li>What you give up when moving into management</li> <li>How to build a data team</li> <li>Online revenue streams for Data Scientists</li> <li>Benefits of having at least two careers</li> <li>What to do if you are nervous about possible layoffs</li> <li>Awesome data leadership</li> <li>The Staff Engineer path</li> <li>The Best Learning Paths for AI and Data Leadership</li> <li>The Engineering Ladder: AgileLab way to provide people a professional growth path</li> <li>From MSc thesis to Lead Data Scientist</li> <li>A comprehensive guide to designing your technical career</li> <li>Decoding the Data Scientist Hierarchy From Junior to Senior: What Sets Them Apart?</li> <li>How to get promoted</li> <li>Elevate Your Data Science Career: How to become a Senior Data Scientist</li> <li>The Trimodal Nature of Software Engineering Salaries in the Netherlands and Europe</li> <li>Measuring Developer Productivity: Real-World Examples</li> <li>Career progression</li> </ul>"},{"location":"resources/career/#conferences","title":"Conferences","text":"<ul> <li>PyCon Italia</li> </ul>"},{"location":"resources/career/#jobs","title":"Jobs","text":"<ul> <li>Awesome Italia Remote</li> </ul>"},{"location":"resources/career/#genoa","title":"Genoa","text":"<ul> <li>Imavis</li> <li>ARPAL</li> <li>FlairBit</li> <li>OnAir</li> <li>algoWatt</li> <li>Cubbit</li> <li>EGO</li> <li>RINA</li> <li>Mywai</li> <li>Zenatek</li> <li>ENI</li> <li>Liguria Digitale</li> <li>Imprese liguri</li> </ul>"},{"location":"resources/career/#purposeful","title":"Purposeful","text":"<ul> <li>UNHCR</li> <li>Amnesty</li> <li>IOM</li> <li>CIR</li> <li>MSF</li> <li>Save The Children</li> <li>Emergency</li> <li>SOGEI</li> <li>DOXA</li> <li>INVALSI</li> <li>ISTAT</li> <li>Banca d'Italia</li> <li>INPS</li> </ul>"},{"location":"resources/career/#negotiation","title":"Negotiation","text":"<ul> <li>Ten rules for negotiating</li> <li>How not to bomb your offer negotiation</li> <li>Switch to AirBnB - part 1</li> <li>Switch to AirBnB - part 2</li> <li>How to double your salary</li> <li>Negotiation tactics for maximizing your worth</li> </ul>"},{"location":"resources/career/#portfolio","title":"Portfolio","text":"<ul> <li>How to build a DS portfolio</li> <li>Inspiration for DS projects</li> <li>Five minutes to your own website</li> <li>Virtual self driving car</li> <li>Hand geometric identification system</li> <li>Stop your project going off the rails</li> <li><code>mkdocs</code></li> <li>Publishing your own DS docs on the web</li> <li>Static website with <code>mkdocs</code> and S3</li> <li>Tools for DS portfolio</li> <li>Transform jupyter notebook to an ebook</li> <li>Win conditions for DS project</li> <li>Rebranding as data scientist</li> <li>Static website with github</li> <li>Effective DS portfolio</li> <li>Explore Github readme</li> <li>Build a stunning Github readme</li> <li>Data science portfolios collection</li> <li>Programming projects for DS</li> <li>Speed up data science writing</li> <li>How to make a website</li> <li>Claudia Tenhoope portfolio</li> <li>Donne Martin portfolio</li> <li>Auto update guthub profile</li> <li>Other tools for DS portfolio</li> <li>DS projects inspiration</li> <li>GitHub Actions for automated portfolio generation</li> <li>Portfolio maker repo</li> <li>Impressive GitHub profile</li> <li>gitbook</li> <li>21 tips for Data Scientists self-development</li> <li>Career docs</li> <li>Github profile toolset</li> <li>GitHub readme generator via Streamlit</li> <li>How to write a data science blog</li> <li>Tailor CV for job description</li> <li>Jupyter Book</li> <li>Private documentation</li> <li>Example personal website</li> <li>Come scrivere una newsletter di successo</li> <li>AWS Community</li> </ul>"},{"location":"resources/career/#resume","title":"Resume","text":"<ul> <li>JSON Resume: a walkthrough and some themes</li> </ul>"},{"location":"resources/career/#preparation","title":"Preparation","text":"<ul> <li>How to survive a layoff during challenging times</li> <li>Data science interview blueprint</li> <li>Hiring process for programmers</li> <li>Guide for hiring managers to hire better data scientists</li> <li>Amazon interview guide</li> <li>Interview checklist</li> <li>The Data Science Interview Project</li> </ul>"},{"location":"resources/career/#technical-skills","title":"Technical skills","text":"<ul> <li>DS and ML interview questions</li> <li>How to ace the in person DS interview</li> <li>DS interview questions</li> <li>How to land a DS job</li> <li>Comprehensive DS and ML interview guide</li> <li>Google interview brain teasers</li> <li>DS interview questions and answers</li> <li>Python interview questions and answers</li> <li>DS interview questions</li> <li>DS interview questions and answers 2</li> <li>Amazon questions for 2021</li> <li>Probability and statistics cheatsheet</li> </ul>"},{"location":"resources/career/career-development/","title":"Career development","text":"<ul> <li>Roles in a Data Science team</li> <li>Measuring developer productivity</li> <li>Google: five keys to a successful team</li> <li>Google: what makes a great manager</li> <li>When and how build your data science team</li> <li>Data science leaders to follow</li> <li>Leading a software development team</li> <li>From Senior to Chief data scientist</li> <li>How to not lose tech skills being a Manager</li> <li>Career ladders and self-evaluation grid</li> <li>How to build and lead a Data Science team</li> <li>Diversity leads to better solutions</li> <li>15 habits for highly effective data scientists</li> <li>7 traits for incredibly efficient data scientists</li> <li>How to scale a data team</li> <li>How writing can advance your career</li> <li>Stretch work assignments for personal growth</li> <li>Code quality as a competitive advantage</li> <li>The Information Architect</li> <li>What you give up when moving into management</li> <li>How to build a data team</li> <li>Online revenue streams for Data Scientists</li> <li>Benefits of having at least two careers</li> <li>What to do if you are nervous about possible layoffs</li> <li>Awesome data leadership</li> <li>The Staff Engineer path</li> <li>The Best Learning Paths for AI and Data Leadership</li> <li>The Engineering Ladder: AgileLab way to provide people a professional growth path</li> <li>From MSc thesis to Lead Data Scientist</li> <li>A comprehensive guide to designing your technical career</li> <li>Decoding the Data Scientist Hierarchy From Junior to Senior: What Sets Them Apart?</li> <li>How to get promoted</li> <li>Elevate Your Data Science Career: How to become a Senior Data Scientist</li> <li>The Trimodal Nature of Software Engineering Salaries in the Netherlands and Europe</li> <li>Measuring Developer Productivity: Real-World Examples</li> <li>Career progression</li> </ul>"},{"location":"resources/career/conferences/","title":"Conferences","text":"<ul> <li>PyCon Italia</li> </ul>"},{"location":"resources/career/jobs/","title":"Jobs","text":"<ul> <li>Awesome Italia Remote</li> </ul>"},{"location":"resources/career/jobs/#genoa","title":"Genoa","text":"<ul> <li>Imavis</li> <li>ARPAL</li> <li>FlairBit</li> <li>OnAir</li> <li>algoWatt</li> <li>Cubbit</li> <li>EGO</li> <li>RINA</li> <li>Mywai</li> <li>Zenatek</li> <li>ENI</li> <li>Liguria Digitale</li> <li>Imprese liguri</li> </ul>"},{"location":"resources/career/jobs/#purposeful","title":"Purposeful","text":"<ul> <li>UNHCR</li> <li>Amnesty</li> <li>IOM</li> <li>CIR</li> <li>MSF</li> <li>Save The Children</li> <li>Emergency</li> <li>SOGEI</li> <li>DOXA</li> <li>INVALSI</li> <li>ISTAT</li> <li>Banca d'Italia</li> <li>INPS</li> </ul>"},{"location":"resources/career/negotiation/","title":"Negotiation","text":"<ul> <li>Ten rules for negotiating</li> <li>How not to bomb your offer negotiation</li> <li>Switch to AirBnB - part 1</li> <li>Switch to AirBnB - part 2</li> <li>How to double your salary</li> <li>Negotiation tactics for maximizing your worth</li> </ul>"},{"location":"resources/career/portfolio/","title":"Portfolio","text":"<ul> <li>How to build a DS portfolio</li> <li>Inspiration for DS projects</li> <li>Five minutes to your own website</li> <li>Virtual self driving car</li> <li>Hand geometric identification system</li> <li>Stop your project going off the rails</li> <li><code>mkdocs</code></li> <li>Publishing your own DS docs on the web</li> <li>Static website with <code>mkdocs</code> and S3</li> <li>Tools for DS portfolio</li> <li>Transform jupyter notebook to an ebook</li> <li>Win conditions for DS project</li> <li>Rebranding as data scientist</li> <li>Static website with github</li> <li>Effective DS portfolio</li> <li>Explore Github readme</li> <li>Build a stunning Github readme</li> <li>Data science portfolios collection</li> <li>Programming projects for DS</li> <li>Speed up data science writing</li> <li>How to make a website</li> <li>Claudia Tenhoope portfolio</li> <li>Donne Martin portfolio</li> <li>Auto update guthub profile</li> <li>Other tools for DS portfolio</li> <li>DS projects inspiration</li> <li>GitHub Actions for automated portfolio generation</li> <li>Portfolio maker repo</li> <li>Impressive GitHub profile</li> <li>gitbook</li> <li>21 tips for Data Scientists self-development</li> <li>Career docs</li> <li>Github profile toolset</li> <li>GitHub readme generator via Streamlit</li> <li>How to write a data science blog</li> <li>Tailor CV for job description</li> <li>Jupyter Book</li> <li>Private documentation</li> <li>Example personal website</li> <li>Come scrivere una newsletter di successo</li> <li>AWS Community</li> </ul>"},{"location":"resources/career/portfolio/#resume","title":"Resume","text":"<ul> <li>JSON Resume: a walkthrough and some themes</li> </ul>"},{"location":"resources/career/preparation/","title":"Preparation","text":"<ul> <li>How to survive a layoff during challenging times</li> <li>Data science interview blueprint</li> <li>Hiring process for programmers</li> <li>Guide for hiring managers to hire better data scientists</li> <li>Amazon interview guide</li> <li>Interview checklist</li> <li>The Data Science Interview Project</li> </ul>"},{"location":"resources/career/technical-skills/","title":"Technical skills","text":"<ul> <li>DS and ML interview questions</li> <li>How to ace the in person DS interview</li> <li>DS interview questions</li> <li>How to land a DS job</li> <li>Comprehensive DS and ML interview guide</li> <li>Google interview brain teasers</li> <li>DS interview questions and answers</li> <li>Python interview questions and answers</li> <li>DS interview questions</li> <li>DS interview questions and answers 2</li> <li>Amazon questions for 2021</li> <li>Probability and statistics cheatsheet</li> </ul>"},{"location":"resources/data-engineering/","title":"Data Engineering","text":""},{"location":"resources/data-engineering/#data-architecture","title":"Data Architecture","text":"<ul> <li>10 characteristics of a modern data architecture</li> <li>Modern data architecture schema</li> <li>Data pipelines</li> <li>Data Engineering blog posts by Robin Linacre</li> <li>Databases and Data Modelling: a quick crash course</li> <li>System Design: ElasticSearch</li> <li>Architecture based on feedback loops</li> </ul>"},{"location":"resources/data-engineering/#basics","title":"Basics","text":"<ul> <li>Python for Data Engineers</li> <li>JSON Lines</li> <li>Modern Data Engineering</li> <li>Introduction to Streaming Frameworks</li> <li>Data Engineering Design Patterns</li> <li>Airbyte Data Glossary</li> <li>Modern Data Engineering</li> </ul>"},{"location":"resources/data-engineering/#database","title":"Database","text":"<ul> <li>TimescaleDB</li> <li>DuckDB and Motherduck serverless analytics platform</li> </ul>"},{"location":"resources/data-engineering/#data-format","title":"Data format","text":"<ul> <li>Apache Iceberg O'Reilly Training</li> </ul>"},{"location":"resources/data-engineering/#monitoring","title":"Monitoring","text":"<ul> <li>SLA, SLO and SLI for data teams</li> </ul>"},{"location":"resources/data-engineering/#os","title":"OS","text":"<ul> <li>Tech info about operating systems</li> </ul>"},{"location":"resources/data-engineering/#rest-api","title":"Rest API","text":"<ul> <li>Intro</li> </ul>"},{"location":"resources/data-engineering/#tools","title":"Tools","text":"<ul> <li>Luigi</li> <li>d6t</li> <li>Metaflow</li> <li>Airflow</li> <li>Dagster</li> <li>GPU</li> <li>Observer pattern vs Pub Sub pattern</li> <li>Prefect</li> <li>Ray</li> <li>Splink: probabilistic data linkage at scale</li> <li>Haystack: an end-to-end framework for production-ready search pipelines</li> </ul>"},{"location":"resources/data-engineering/#search-engines","title":"Search engines","text":"<ul> <li>Approaching Relevance Challenges in Elasticsearch Query Construction</li> </ul>"},{"location":"resources/data-engineering/#unit-testing","title":"Unit testing","text":"<ul> <li>Test driven development and triangulation</li> </ul>"},{"location":"resources/data-engineering/architecture/","title":"Data Architecture","text":"<ul> <li>10 characteristics of a modern data architecture</li> <li>Modern data architecture schema</li> <li>Data pipelines</li> <li>Data Engineering blog posts by Robin Linacre</li> <li>Databases and Data Modelling: a quick crash course</li> <li>System Design: ElasticSearch</li> <li>Architecture based on feedback loops</li> </ul>"},{"location":"resources/data-engineering/basics/","title":"Basics","text":"<ul> <li>Python for Data Engineers</li> <li>JSON Lines</li> <li>Modern Data Engineering</li> <li>Introduction to Streaming Frameworks</li> <li>Data Engineering Design Patterns</li> <li>Airbyte Data Glossary</li> <li>Modern Data Engineering</li> </ul>"},{"location":"resources/data-engineering/database/","title":"Database","text":"<ul> <li>TimescaleDB</li> <li>DuckDB and Motherduck serverless analytics platform</li> </ul>"},{"location":"resources/data-engineering/format/","title":"Data format","text":"<ul> <li>Apache Iceberg O'Reilly Training</li> </ul>"},{"location":"resources/data-engineering/monitoring/","title":"Monitoring","text":"<ul> <li>SLA, SLO and SLI for data teams</li> </ul>"},{"location":"resources/data-engineering/os/","title":"OS","text":"<ul> <li>Tech info about operating systems</li> </ul>"},{"location":"resources/data-engineering/rest-api/","title":"Rest API","text":"<ul> <li>Intro</li> </ul>"},{"location":"resources/data-engineering/tools/","title":"Tools","text":"<ul> <li>Luigi</li> <li>d6t</li> <li>Metaflow</li> <li>Airflow</li> <li>Dagster</li> <li>GPU</li> <li>Observer pattern vs Pub Sub pattern</li> <li>Prefect</li> <li>Ray</li> <li>Splink: probabilistic data linkage at scale</li> <li>Haystack: an end-to-end framework for production-ready search pipelines</li> </ul>"},{"location":"resources/data-engineering/tools/#search-engines","title":"Search engines","text":"<ul> <li>Approaching Relevance Challenges in Elasticsearch Query Construction</li> </ul>"},{"location":"resources/data-engineering/unit-testing/","title":"Unit testing","text":"<ul> <li>Test driven development and triangulation</li> </ul>"},{"location":"resources/data-science/","title":"Data Science","text":""},{"location":"resources/data-science/#ab-testing","title":"A/B Testing","text":"<ul> <li>Art of A/B testing</li> <li>When and when not to A/B test</li> <li>Fundamentals of A/B testing</li> <li>Netflix: interpreting A/B testing results part 1</li> <li>Netflix: interpreting A/B testing results part 2</li> <li>How to Accurately Test Significance with Difference in Difference Models</li> </ul>"},{"location":"resources/data-science/#anomaly-detection","title":"Anomaly detection","text":"<ul> <li>Time series anomaly detection</li> <li>Isolation forest</li> <li>Anomaly detection with <code>pycaret</code></li> <li>Equipment effectiveness with python</li> <li>Real-time time series anomaly detection</li> <li>Anomaly detection with copulas</li> <li>PyOD: Python outlier detection library</li> <li>5 anomaly detection algorithms with sklearn implementation</li> <li>Auto anomaly detection with isolation forest</li> <li>Probabilistic forecasting of binary events using regression</li> <li>Luminol: a light weight Python library for time series anomaly detection and correlation</li> <li>Alibi Detect: an open source Python library focused on outlier, adversarial and drift detection</li> </ul>"},{"location":"resources/data-science/#automl","title":"AutoML","text":"<ul> <li>AutoML python libraries</li> <li>TPOT pipelines optimization with genetic algorithms</li> <li>MLBox</li> </ul>"},{"location":"resources/data-science/#bayesian-methods","title":"Bayesian methods","text":"<ul> <li>Bayesian revenue estimation</li> <li>Estimating probabilities with bayesian modeling</li> <li>Probabilistic programming and Bayesian methods for hackers</li> <li>Bayesian neural network with <code>pyro</code> and <code>pytorch</code></li> <li>Bayesian modeling with <code>pymc3</code></li> <li>Richard Gott Princeton</li> <li>How to be less wrong</li> <li>Bayesian logistic regression with <code>pymc3</code></li> <li>Naive Bayes</li> <li>Math behind Bayes methods</li> <li>Mathematical explanation of Naive Bayes</li> <li>Bayesian inference with <code>pymc3</code></li> <li>Bayesian Time Series linear regression</li> <li>Bayesian optimization</li> <li>Bayesian inference</li> <li>Gelman book Columbia university</li> <li>Bayesian state space model with <code>pymc3</code></li> <li>Bayesian inference and MCMC variational inference</li> <li><code>bambi</code> for Bayesian Model Building Interface</li> <li>How to be less wrong: a Bayesian's guide to predicting the future with limited data</li> <li>bnlearn: a library for Bayesian network learning and inference</li> </ul>"},{"location":"resources/data-science/#bin-packing","title":"Bin Packing","text":"<ul> <li>BPP scipbook</li> <li>PuLP</li> <li>GitHub PuLP</li> <li>PuLP examples</li> <li>Wedding PuLP example</li> <li>PuLP paper</li> <li>Binpacking library</li> <li>Binpacking PuLP</li> </ul>"},{"location":"resources/data-science/#binsize","title":"Binsize","text":"<ul> <li>Histogram</li> <li>Model risk</li> <li>Optimal number of bins Freedman Diaconis rule</li> <li>Understanding Freedman Diaconis rule</li> <li>Freedman Diaconis rule paper</li> </ul>"},{"location":"resources/data-science/#causal-inference","title":"Causal Inference","text":"<ul> <li>Causal Inference handbook</li> <li>The Effect: An Introduction to Research Design and Causality</li> <li>Intro to Causal Inference course</li> <li>What is Causal Inference?</li> <li>PyWhy: ML based causal inference by Microsoft DoWhy</li> <li>CausalPy hands-on</li> </ul>"},{"location":"resources/data-science/#churn-analysis","title":"Churn analysis","text":"<ul> <li>Modeling customer churn when churns are not observed</li> <li>EDA empirical cumulative distribution</li> <li>Customer churn management</li> <li>Predicting customer churn for telcom</li> <li>Churn analysis via PyCaret</li> </ul>"},{"location":"resources/data-science/#classification","title":"Classification","text":"<ul> <li>Reliability diagrams for probability calibration</li> <li>Composite classification metrics</li> <li>SMOTE for synthetic data augmentation and unbalanced datasets</li> <li>Calculating business value of binary classification</li> <li><code>predict_proba</code> probabilities calibration</li> <li>Why class balancing can be avoided</li> <li>Matthews Correlation Coefficient (MCC) and Brier score</li> <li>Precision and Recall visually explained</li> <li>The Effect of Class Imbalance on Precision-Recall Curves</li> <li>Classification metrics calibration</li> <li><code>binclass-tools</code> for binary classification inspection</li> </ul>"},{"location":"resources/data-science/#clustering","title":"Clustering","text":"<ul> <li>Tomato clustering</li> <li>Alternatives to k-means</li> <li>Clustering metrics</li> <li>Find optimal k in KNN</li> <li>K-Means</li> <li>Anatomy of K-Means</li> <li>Clustering algorithms comparison</li> <li>Intro to hierarchical clustering</li> <li>How to determine optimal clusters number</li> <li>Clustering algorithms comparison</li> <li>Hierarchical Agglomerative Clustering</li> <li>Hierarchical clustering 101</li> <li>Regional Online Learnable Fields (ROLF)</li> <li>Interpretable KMeans via Classification feature importance</li> <li>How to select optimal k for K-Means</li> <li>How many clusters? Methods comparison</li> <li>Expectation Maximization soft clustering</li> <li>Markov clustering</li> <li>Unsupervised Learning Series: exploring DBScan</li> <li>Recursive Embedding and Clustering by Spotify</li> </ul>"},{"location":"resources/data-science/#code-differentiation","title":"Code differentiation","text":"<ul> <li>Differentiation from scratch</li> <li>Differentiable programming</li> <li>Taichi</li> </ul>"},{"location":"resources/data-science/#community-detection","title":"Community detection","text":"<ul> <li>Louvain algorithm for community detection</li> <li>Decoding the Manhattan Project's Network</li> </ul>"},{"location":"resources/data-science/#computer-vision","title":"Computer Vision","text":"<ul> <li>Lane detection</li> <li>Modern computer vision with <code>caer</code></li> <li><code>scikit-image</code> for image processing</li> <li>FiftyOne app</li> <li>Augmentor for image augmentation</li> <li>Concept: a technique that leverages CLIP and BERTopic-based techniques to perform Concept Modeling on images</li> </ul>"},{"location":"resources/data-science/#correlation","title":"Correlation","text":"<ul> <li>Non-linear correlation matrix</li> <li>Predictive power score (PPS)</li> </ul>"},{"location":"resources/data-science/#curse-of-dimensionality","title":"Curse Of Dimensionality","text":"<ul> <li>Curse of dimensionality explained</li> </ul>"},{"location":"resources/data-science/#customer-value","title":"Customer value","text":"<ul> <li>Customer segmentation</li> <li>Seasonal customers via time series analysis</li> <li>Identify seasonal customers with Python</li> <li>Customer lifetime value prediction</li> <li>Business DS</li> <li>Quantiles from ML model</li> <li>DS guide to subscription businesses</li> <li>Clustering for customer segmentation</li> </ul>"},{"location":"resources/data-science/#dataset","title":"Dataset","text":"<ul> <li>Dataset search</li> <li>Hand drawn data</li> <li>Faker</li> <li>Mimesis</li> <li>SDV</li> <li>Diffbot</li> <li>Datasette</li> <li>Hand drawn data in Jupyter with <code>drawdata</code></li> <li>World Bank data API</li> <li>Footprint Network</li> <li>Sondaggi politico elettorali ITA</li> <li>Microsoft's Bing road detections</li> <li>Kontur population dataset</li> <li>ISPRA: Open Data sul dissesto idrogeologico</li> <li>Folktables</li> <li>The official portal for European data</li> <li>Awesome datasets</li> </ul>"},{"location":"resources/data-science/#deep-learning","title":"Deep Learning","text":"<ul> <li>D2L</li> <li>Implementing DL from scratch in Python</li> </ul>"},{"location":"resources/data-science/#dimensionality-reduction","title":"Dimensionality Reduction","text":"<ul> <li>Locally linear embedding (LLE)</li> </ul>"},{"location":"resources/data-science/#dynamic-pricing","title":"Dynamic pricing","text":"<ul> <li>Dynamic pricing for theatre</li> <li>Regression for price optimization</li> <li>Dynamic Pricing with Reinforcement Learning from Scratch: Q-Learning</li> </ul>"},{"location":"resources/data-science/#embeddings","title":"Embeddings","text":"<ul> <li>Embetter: scikit-learn compatible embeddings for computer vision and text</li> <li>An intuitive introduction to text embeddings</li> <li>The Hidden World of (Vector) Indexes</li> <li>Why cosine similarity between sentence embeddings is always positive</li> </ul>"},{"location":"resources/data-science/#energy-and-power-systems","title":"Energy and Power Systems","text":"<ul> <li>PyPSA: Python for Power System Analysis</li> </ul>"},{"location":"resources/data-science/#ensemble-models","title":"Ensemble models","text":"<ul> <li><code>vectstack</code> for models stacking</li> <li>One general model vs many specialized ones</li> </ul>"},{"location":"resources/data-science/#features-engineering-and-selection","title":"Features engineering and selection","text":"<ul> <li>Boruta</li> <li>Guide to feature extraction</li> <li>Feature selection don'ts</li> <li>Features normally distributed</li> <li>How and Why</li> <li>Feast: an open source feature store for machine learning</li> <li>Shapicant: a feature selection package based on SHAP and target permutation, for pandas and Spark</li> </ul>"},{"location":"resources/data-science/#football-analytics","title":"Football analytics","text":"<ul> <li>Paper</li> <li>Predict Euro 2020 winner</li> <li>Poisson regression for football match results prediction</li> <li>Predicting FIFA World Cup 2022 winner</li> </ul>"},{"location":"resources/data-science/#function-learning","title":"Function learning","text":"<ul> <li>Adaptive: Parallel Active Learning of Mathematical Functions</li> </ul>"},{"location":"resources/data-science/#game-theory","title":"Game Theory","text":"<ul> <li>Game Theory intro with Python</li> </ul>"},{"location":"resources/data-science/#gaussian-mixture-models","title":"Gaussian Mixture Models","text":"<ul> <li>EM algorithm for GMM</li> <li>GMM explained</li> </ul>"},{"location":"resources/data-science/#gaussian-processes","title":"Gaussian Processes","text":"<ul> <li>Intuitive guide to Gaussian processes</li> <li>Gaussian process regression</li> <li>Other uses of Gaussian processes</li> </ul>"},{"location":"resources/data-science/#genetic-algorithm","title":"Genetic algorithm","text":"<ul> <li>Intro to GA for optimization</li> </ul>"},{"location":"resources/data-science/#geo-science","title":"Geo science","text":"<ul> <li>Transportation DS</li> <li>Spatial autocorrelation</li> <li>Geospatial data declustering</li> <li>EDA of spatial data and spatial autocorrelation</li> <li>GPS trajectory clustering</li> <li>Geospatial indexing with quadkeys</li> <li>Travel time estimatione using quadkeys</li> <li>Geographic Data Science with Python</li> <li>Geocoding via Geoapify</li> <li>Geospatial Data Engineering: Spatial Indexing</li> <li>Proximity Analysis: a few words about spatial data processing</li> <li>Deep Dive into ESA's Sentinel API</li> <li>Geospatial Analysis and Representation for Data Science course for the master in Data Science University of Trento</li> <li>Overture Maps Data Repo</li> <li>3D Geospatial Data Integration with Python: The Ultimate Guide</li> <li><code>srai</code>: Spatial Representations for Artificial Intelligence</li> <li>Earth Isn't Flat, and Neither Should Your Voronoi Diagrams Be</li> <li>Voronoi diagram in Manhattan metric</li> <li>Geospatial Indexing Explained: A Comparison of Geohash, S2, and H3</li> </ul>"},{"location":"resources/data-science/#gradient-methods","title":"Gradient methods","text":"<ul> <li>ML and particle motion in liquid</li> <li>Gradient descent deep dive</li> </ul>"},{"location":"resources/data-science/#hyperparameters-tuning","title":"Hyperparameters Tuning","text":"<ul> <li><code>optuna</code> library for hyperparameter tuning in logistic regression</li> <li>Gaussian processes for ML models tuning</li> <li>Optuna and sklearn integration</li> <li>Hyperparameters tuning with Optuna and human-in-the-loop</li> <li>Evolutionary and genetic algorithms for parameters tuning</li> <li>Bayesian hyperparameters optimization</li> <li><code>mango</code>: a parallel hyperparameter tuning library</li> <li>Mango tutorial</li> </ul>"},{"location":"resources/data-science/#information-theory","title":"Information Theory","text":"<ul> <li>Intro to Shannon Information Theory</li> </ul>"},{"location":"resources/data-science/#kernel-methods","title":"Kernel Methods","text":"<ul> <li>Kernel trick</li> <li>Kernel regression</li> </ul>"},{"location":"resources/data-science/#large-language-models-llm","title":"Large Language Models (LLM)","text":"<ul> <li>ChatGPT Is An Extra-Ordinary Python Programmer</li> <li>StartChat Playground by Hugging Face</li> <li>What is ChatGPT doing and why does it work</li> <li>GPT in 60 Lines of NumPy</li> <li>privateGPT</li> <li>Pushing Prompt Engineering to the Limit</li> <li>How Foundation Model Providers Comply with the Draft EU AI Act</li> <li>A Gentle Introduction to LLM APIs</li> <li>All You Need to Know to Build Your First LLM App</li> <li>Mastering Prompt Engineering</li> <li>How to Run LLMs Locally</li> <li>LangChain: Building applications with LLMs through composability</li> <li>DeclarAI: turning Python code into production-ready LLM tasks</li> <li>Open Source LLMs To Power A LLM Application</li> <li>Large language models, explained with a minimum of math and jargon</li> <li>Inside GPT: Understanding the text generation</li> <li>Llama 2: Open Foundation and Fine-Tuned Chat Models</li> <li>Understand how BERT constructs state-of-the-art embeddings</li> <li>codellama</li> <li>NLP tasks via LLM</li> <li>From encoding to embeddings</li> <li>Large Language Models: Sentence-BERT</li> <li>Methods For Improving Your Large Language Model</li> <li>Vector Databases and How to Use Them to Augment LLM</li> <li>Large Language Models: RoBERTa, a Robustly Optimized BERT Approach</li> <li>DeepEval: Unit Testing for LLMs</li> <li>Attention Sinks in LLMs for endless fluency</li> <li>Generative AI exists because of the transformer: this is how it works</li> <li>OpenLLM Leaderboard</li> <li>All you need to know to Develop using Large Language Models</li> <li>LMQL: a programming language for large language models</li> <li>GPT-Engineer</li> <li>Chatbot Arena: Benchmarking LLMs in the Wild</li> <li>magentic: easily integrate Large Language Models into your Python code</li> <li>Hard Truths About Generative AI for Technology Leaders</li> <li>AlphaCodium: From Prompt Engineering to Flow Engineering</li> <li>Cheshire-Cat: Production ready AI assistant framework</li> </ul>"},{"location":"resources/data-science/#machine-learning","title":"Machine Learning","text":"<p>Machine Learning Tooling GitHub space with ranked lists of awesome Python libraries for, updated weekly.</p> <ul> <li>GUI for ML workflow and pipeline discovery</li> <li>ML prototypes</li> <li>Designing intelligence</li> <li>AI, ML and DL</li> <li>Game theory for ML interpretation</li> <li><code>pycaret</code></li> <li>Hybrid rule based ML</li> <li><code>pycaret-2.0</code></li> <li>QLattice</li> <li>Applied ML use cases</li> <li>Google ML glossary</li> <li>130 ML Tricks And Resources Carefully Curated</li> </ul>"},{"location":"resources/data-science/#model-evaluation","title":"Model evaluation","text":"<ul> <li>Plot learning curve</li> <li>Validation sets</li> <li>ML Tool</li> <li>Validate and ML model</li> <li>Overfitting and underfitting</li> <li>Cross validation</li> <li>Validation curve</li> <li>MAPIE for confidence prediction intervals estimation</li> </ul>"},{"location":"resources/data-science/#model-monitoring","title":"Model monitoring","text":"<ul> <li>Static threshold vs anomalies and changepoints detection</li> <li>Different retrain strategies for ML models</li> <li>An end-to-end implementation of a prediction flow for kids who can't MLOps good</li> <li>Giskard: scan AI models to detect risks of biases, performance issues and errors</li> <li>MLflow</li> <li>Model drift</li> <li>Evidently for model monitoring</li> <li>Weights and Biases</li> <li>Sacred</li> <li>Omniboard as a Sacred frontend</li> <li>MLflow 101</li> <li>deepchecks</li> <li>MLNotify for training completion notification</li> <li>NannyML for post-deployment model performance monitoring</li> </ul>"},{"location":"resources/data-science/#mlops","title":"MLOps","text":"<ul> <li>What is MLOps</li> <li>MLOps maturity checklist</li> <li>Why data makes MLOps different</li> <li>ML model deployment strategies</li> <li>MLOps lifecycles</li> <li>A curated (awesome!) list of open source libraries to deploy, monitor, version, scale and secure production machine learning</li> <li>The Full Stack 7-steps MLOps framework</li> <li>CD for ML</li> <li>Our MLOps story: Production-Grade Machine Learning for Twelve Brands</li> <li>No, You Don't Need MLOps</li> </ul>"},{"location":"resources/data-science/#marketing-analytics","title":"Marketing Analytics","text":"<ul> <li>Beginner guide to Marketing Analytics</li> <li>Discrete-Time Markov Chains: Identifying Winning Customer Journeys in a Cashback Campaign</li> <li>Methods for Modelling Customer Lifetime Value: The Good Stuff and the Gotchas</li> </ul>"},{"location":"resources/data-science/#markov-chains","title":"Markov Chains","text":"<ul> <li>Attribution model</li> <li>Progressions</li> <li>Market simulator with Mark chains</li> <li>Markov chains</li> <li>Hidden Markov models</li> <li>Markov chain process and HMM</li> <li>Markov chain as text generation model</li> <li>Beatles lyrics generation via Markov Chains</li> <li>Markov chains for time series forecasting</li> </ul>"},{"location":"resources/data-science/#mcmc","title":"MCMC","text":"<ul> <li>Animations with MCMC</li> <li>Monte Carlo tree search</li> <li>Monte Carlo in PBP</li> <li>MCMC for cryptography and optimization</li> <li><code>pyro</code></li> <li>Metropolis-Hastings from scratch in Python</li> <li>Monte Carlo methods</li> <li>Random sampling via Python decorator</li> <li>Intro to Monte Carlo methods</li> <li>Simulating data with PyMC</li> <li>Mastering Monte Carlo: How to Simulate Your Way to Better Machine Learning Models</li> <li>Chaospy: a numerical toolbox for performing uncertainty quantification using polynomial chaos expansions and advanced Monte Carlo methods</li> <li>PyMC-Marketing: Bayesian Marketing Mix Modeling (MMM) &amp; Customer Lifetime Value (CLV)</li> </ul>"},{"location":"resources/data-science/#nearest-neighbors","title":"Nearest Neighbors","text":"<ul> <li>Voyager: a library for performing fast approximate nearest-neighbor searches on an in-memory collection of vectors</li> </ul>"},{"location":"resources/data-science/#neural-networks","title":"Neural Networks","text":"<ul> <li>Neural networks and deep learning</li> <li>Make NN paint to understand how they work</li> <li>Intro to neural networks</li> <li>NN manifolds topology</li> <li>Visualizing optimization trajectory in neural networks</li> <li>Deep dream convolutional networks full code</li> <li>Neural networks as ensembles of simpler models</li> <li>Neural networks as functions composition</li> <li>N-Students learning framework</li> <li>A short history of Neural Networks</li> <li>Drag Your GAN: Interactive Point-based Manipulation on the Generative Image Manifold</li> <li>AI Canon</li> </ul>"},{"location":"resources/data-science/#natural-language-processing-nlp","title":"Natural Language Processing (NLP)","text":"<ul> <li>EDA and visualization of text data</li> <li><code>text2emotion</code> to detect emotions from textual data</li> <li>Quantify information in statements with entropy from Information Theory</li> <li>NLTK</li> <li>Chatbot using <code>rasa</code></li> <li><code>rasa</code>: open source ML framework to automate text-and voice-based conversations</li> <li>WordNet for a lexical taxonomy of English words</li> <li>Clean text</li> <li>Gramformer for text correction</li> <li>Styleformer for text styling</li> <li>Data jobs description analyzed with scattertext</li> <li>Scattertext</li> <li><code>texthero</code></li> <li><code>yarl</code> for URL processing</li> <li><code>Ecco</code> for pattern visualization in text data</li> <li>Data QA to label data</li> <li>Text summarization</li> <li>Text similarity with Levenshtein distance</li> <li>Autocorrect for multilanguage spelling correction</li> <li>Neattext for cleaning textual data and text preprocessing</li> <li>Texthero tutorial</li> <li>Microsoft <code>presidio</code> for NER (Named Entity Recognition) and data anonymization</li> <li>SEER model for information extraction based on user-specified examples</li> <li>Textnets: text analysis with networks</li> <li>Universal romanizer tool</li> <li>Text summarization</li> <li>Sentence embedding</li> <li>Semantic search with <code>txtai</code></li> <li>Arabica and Cappuccino for text EDA</li> <li>Simple spelling check in Python</li> <li>A guide to computational linguistics and conversational AI</li> <li>diff-match-patch: robust algorithms to perform the operations required for synchronizing plain text</li> <li>PolyFuzz: fuzzy string matching and string grouping</li> <li>Outlines: a library for neural text generation</li> <li><code>sense2vec</code>: query vectors for multi-word phrases based on part-of-speech tags and entity labels</li> </ul>"},{"location":"resources/data-science/#topic-modeling","title":"Topic modeling","text":"<ul> <li>Concept modeling to link text and images</li> <li>Topic coherence measures</li> <li>Intro to topic modeling with Latent Dirichlet Allocation (LDA)</li> <li>Topic modeling strategies comparison</li> <li>Hands-on topic modeling via LDA</li> <li>Advanced Topic Modeling with BERTopic</li> <li>Topic Modeling with Llama 2</li> <li>cluestar: visualisation tools to get started with text classification tasks</li> <li>Practical Guide to Topic Modeling with Latent Dirichlet Allocation (LDA)</li> </ul>"},{"location":"resources/data-science/#objects-tracking","title":"Objects tracking","text":"<ul> <li><code>py-motmetrics</code></li> <li>Intro to multiple objects tracking metrics</li> </ul>"},{"location":"resources/data-science/#ocr","title":"OCR","text":"<ul> <li>Open source OCR tools</li> <li>Extract text written in different languages with <code>easyocr</code></li> </ul>"},{"location":"resources/data-science/#optimization","title":"Optimization","text":"<ul> <li>Lagrange multipliers</li> <li>Openopt</li> <li>OR-Tools</li> <li>Solving Sudoku via AI</li> <li>Arbitrage strategy with linear programming</li> <li>Lagrange multiplier demystified</li> <li>Python constraint</li> <li>Surrogate optimization</li> <li>Particle Swarm Optimization (PSO)</li> <li>Traveling Salesman Problem (TSP) heuristic</li> <li>Guide to dynamic programming</li> <li>Goal programming</li> <li>Artificial Bee Colony algorithm</li> <li>Animate particle swarm optimization</li> <li>ErlangC queue optimization with <code>pyworkforce</code></li> <li>Optimization heuristics</li> <li>How Amazon learned to cut its cardboard waste with pioneering web-based PackOpt tool</li> <li>Route optimization with Python</li> <li>The Vehicle Routing Problem: Exact and Heuristic Solutions</li> <li>List of optimization packages in Python</li> </ul>"},{"location":"resources/data-science/#scholarpedia","title":"Scholarpedia","text":"<ul> <li>Artificial Bee Colony</li> <li>Particle Swarm Optimization</li> <li>Ant Colony Optimization</li> </ul>"},{"location":"resources/data-science/#pattern-mining","title":"Pattern mining","text":"<ul> <li>Data mining techniques</li> </ul>"},{"location":"resources/data-science/#physics","title":"Physics","text":"<ul> <li>From physics to optimization</li> </ul>"},{"location":"resources/data-science/#predictive-maintenance","title":"Predictive Maintenance","text":"<ul> <li>Understanding Predictive Maintenance: Data Acquisition and Signal Denoising</li> <li>Understanding Predictive Maintenance: Unit Roots and Stationarity</li> <li>Understanding Predictive Maintenance: Wave Data and Feature Engineering (Part 1)</li> </ul>"},{"location":"resources/data-science/#probability-statistics","title":"Probability &amp; Statistics","text":"credits to: XKCD <ul> <li>Chi-square test</li> <li>Probability and statistics for DS</li> <li>Statistical significance</li> <li>Hypothesis test</li> <li>How to determine significance for hypothesis testing</li> <li>Visualize hypothesis testing</li> <li>Causal vs statistical inference</li> <li>Phi_k correlation coefficient</li> <li>PP score</li> <li>Generate random variables</li> <li><code>pingouin</code> better than <code>statsmodels</code></li> <li><code>pingouin</code> library for statistical tests</li> <li>Guide to confidence intervals</li> <li>Stop using p = 0.05</li> <li>What p-value stands for</li> <li>Optimal sample size</li> <li>Experiment design</li> <li>Rule of three: calculating probability of events not yet occurred</li> <li>Hypotheses testing with <code>scipy</code></li> <li>Adaptive p-value</li> <li>Probability distributions Q&amp;A - part 1</li> <li>Probability distributions Q&amp;A - part 2</li> <li>Correlation visually explained</li> <li>3 t-tests for data scientists</li> <li>Stats gist list: guide to jargon by Cassie Kozyrkov</li> <li>Algorithmic approach to statistical testing</li> <li>Kolmogorov-Smirnov test to check how data are distributed</li> <li>Empirical cumulative distribution: advantages over histogram for EDA</li> </ul>"},{"location":"resources/data-science/#regression","title":"Regression","text":"<ul> <li>Generalized linear models</li> <li>Generalized linear regression with <code>scikit-learn</code></li> <li>Ordinary least squared regression</li> <li>Adaptive LASSO</li> <li>What happens when you break the assumptions of linear regression</li> <li>Statistics supporting linear models</li> <li>Geodesic regression</li> <li>Symbolic regression</li> <li>Ridge regression from scratch</li> <li>Regularization in regression</li> <li>Deming regression</li> <li>Interpreting linear regression sum-up from statsmodels</li> <li>Logistic regression 101</li> <li>Complete guide to regression analysis</li> <li>Constrained logistic regression</li> <li>Robust regression</li> <li>Polynomial regression with scikit-learn</li> </ul>"},{"location":"resources/data-science/#reinforcement-learning","title":"Reinforcement Learning","text":"<ul> <li>Playing Blackjack with RL</li> <li>Math behind reinforcement learning</li> <li>How RL works</li> <li>Create a custom RL enviroment</li> <li>Start learning RL</li> <li>Dive into RL</li> <li>Policy gradient algorithms</li> <li>RL fundamentals</li> <li>Markov decision process</li> <li>Bellman equation and dynamic programming</li> <li>Reinforcement Learning series</li> <li>Multi-agent particle swarm</li> <li>The K-armed bandit problem</li> <li>Python packages to experiment with Reinforcement Learning</li> <li>Reinforcement Learning algorithms explained</li> <li>Training an Agent to Master a Simple Game Through Self-Play</li> <li>Training an Agent to Master Tic-Tac-Toe Through Self-Play</li> <li>Stablebaseline3: the Swiss Army Knife of Applied RL</li> </ul>"},{"location":"resources/data-science/#resampling","title":"Resampling","text":"<ul> <li>Weighted resampling in Matlab</li> </ul>"},{"location":"resources/data-science/#revenue-science","title":"Revenue science","text":"<ul> <li>Money tree for revenue prioritization</li> </ul>"},{"location":"resources/data-science/#scada-data-analysis","title":"Scada data analysis","text":"<ul> <li>Wind energy analytics toolbox</li> </ul>"},{"location":"resources/data-science/#similarity-measures","title":"Similarity measures","text":"<ul> <li>Similarity measures for data science</li> </ul>"},{"location":"resources/data-science/#simulated-annealing","title":"Simulated Annealing","text":"<ul> <li>Simulated annealing for optimization</li> </ul>"},{"location":"resources/data-science/#sql","title":"SQL","text":"<ul> <li>PugSQL</li> <li>Window functions in SparkSQL</li> <li>Advanced SQL queries in pandas</li> <li>SQL window functions</li> <li>5 SQL common queries</li> <li>SQL window functions</li> <li>Intermediate SQL queries</li> <li>6 lesser known queries</li> <li>10 SQL tips</li> <li>Settings for NLS in SQL Developer</li> <li>Advanced SQL concepts</li> <li>SQL advanced functions: qualify, arrays and more</li> <li>SQL CASE</li> <li>Python built-in database: SQLite</li> <li>Advanced SQL for Data Scientists: cube, array, window and math functions</li> <li>DuckDB: open source OLAP database</li> <li>Lost at SQL: the SQL learning game</li> <li>Window Functions: A Must Know for Data Engineers and Data Scientists</li> <li>How to Low-Pass Filter in Google BigQuery</li> </ul>"},{"location":"resources/data-science/#streamingonline-learning","title":"Streaming/Online Learning","text":"<ul> <li><code>river</code></li> <li>Intro to River</li> </ul>"},{"location":"resources/data-science/#structural-equation-modeling-sem","title":"Structural Equation Modeling (SEM)","text":"<ul> <li>Structural equation modeling with <code>semopy</code></li> </ul>"},{"location":"resources/data-science/#svm","title":"SVM","text":"<ul> <li>Support vector machines</li> <li>SVM theory and practice</li> </ul>"},{"location":"resources/data-science/#synthetic-data","title":"Synthetic data","text":"<ul> <li>Synthetic mobility data generation</li> </ul>"},{"location":"resources/data-science/#time-series","title":"Time Series","text":"<ul> <li>Nested cross validation</li> <li>TS and feature selection</li> <li>Out-of-time validation</li> <li>scikit-learn prediction intervals</li> <li>Forecast visualization</li> <li>TS transfer learning</li> <li>Detecting stationarity</li> <li>End to end project</li> <li>Analysis and forecasting</li> <li>Seasonal ARIMA</li> <li>Forecasting models overview</li> <li>Causality inference</li> <li>Giotto time</li> <li>Time Series Analysis</li> <li>Time series in Python</li> <li>Matrix profile</li> <li>Brownian motion in Python</li> <li>Forecast energy consumption with neural networks and xgboost</li> <li>TS forecasting</li> <li>Statistical tests and ARIMA</li> <li>Dynamic time warping</li> <li>Whale identification TS processing</li> <li>Pattern mining with <code>stumpy</code></li> <li>Statistical tests for trend</li> <li>How to synchronize time series</li> <li>Time series libraries</li> <li>Kats by Facebook</li> <li>Merlion by Salesforce</li> <li>Darts</li> <li>Avoid data leakage in time series</li> <li>Orbit by Uber for Bayesian time series forecasting</li> <li>Time Series terminology</li> <li>Time Series forecasting cheatsheet</li> <li>Poisson Hidden Markov Model for Time Series regression</li> <li>PyCaret AutoML for Time Series</li> <li>Seasonal adjustment of daily time series</li> <li>TSA basics</li> <li>Univariate time series forecasting with Neural Networks</li> <li><code>sktime</code> as sklearn TSA interface</li> <li>Changepoints detection with e-divisive</li> <li>Time series data visualization</li> <li><code>statsforecast</code> for lightning fast forecasting</li> <li>Time features encoding: cyclic vs dummy vs numeric</li> <li>Scalecast</li> <li>Hierarchical forecast reconciliation</li> <li>Deep Learning for time series forecasting</li> <li>Interpreting ACF and PACF plots for time series</li> <li>Python Automatic Forecasting</li> <li>Forecasting with tree-based algorithms</li> <li>FEDOT: an AutoML approach to time series forecasting</li> <li>Time series forecasting with Transformers</li> <li>Conformal prediction interval with scikit-learn, MAPIE and TSPIRAL</li> <li><code>mlforecast</code>: scalable machine learning based time series forecasting</li> <li>Time Series Forecasting with Scikit-learn</li> <li>Time Series for Climate Change: Forecasting Energy Demand</li> <li>Skforecast: a Python library that eases using scikit-learn regressors as single and multi-step forecasters</li> <li>Time series complexity analysis using entropy</li> <li><code>functime</code> is a powerful Python library for production-ready global forecasting and time-series feature extraction on large panel datasets</li> <li>Feature Engineering for Time Series Regression</li> <li>TimeGPT: The First Foundation Model for Time Series Forecasting</li> <li>Group time-series split</li> <li>Feature Engineering for Time Series</li> <li>TSMixer: The Latest Forecasting Model by Google</li> <li><code>tsfresh</code>: Time Series Feature extraction based on scalable hypothesis tests</li> <li><code>pytimetk</code>: time series easier, faster, more fun</li> <li><code>autogluon</code>: AutoML for Image, Text, Time Series, and Tabular Data</li> <li>AutoGluon-TimeSeries: Every Time Series Forecasting Model In One Library</li> <li>Time Series Forecasting with TiDE</li> </ul>"},{"location":"resources/data-science/#prophet","title":"Prophet","text":"<ul> <li>Is Facebook's \"Prophet\" the Time-Series Messiah, or Just a Very Naughty Boy?</li> <li>LSTM and Prophet</li> <li>Prophet forecasting</li> <li>AutoArima Prophet adapter in statsforecast</li> <li>Fixing Prophet forecasting issue</li> </ul>"},{"location":"resources/data-science/#greykite","title":"Greykite","text":"<ul> <li>Greykite by Linkedin</li> <li>Intro to Greykite</li> <li>Tuning a model in Greykite</li> </ul>"},{"location":"resources/data-science/#tree-based-methods","title":"Tree-based methods","text":"<ul> <li>Entropy in decision trees</li> <li>Intuition behind Shannon entropy</li> <li>Explaining feature importance</li> <li><code>catboost</code> for gradient boosting decision trees</li> <li><code>catboost</code> docs</li> <li>Understanding decision trees</li> <li>Random Forest interpretability</li> <li><code>catboost</code> for model interpretation</li> <li>Visualize bagging effect on bias and variance</li> <li>How to draw decision trees</li> <li>Decision trees code</li> <li>Why you should learn <code>catboost</code></li> <li>Intuition behind <code>xgboost</code></li> <li>Tree boosted mixed models</li> <li>Random Forest in ML</li> <li>Multiple imputation with Random Forest</li> <li>Ensemble learning</li> <li>Decision tree and overfitting</li> <li>From boosting to gradient boosting</li> <li>Decision trees and lookahead strategy</li> <li>AdaBoost mathematical approach</li> <li>How to visualize Decision trees</li> <li>Random Forest vs Gradient Boosting</li> <li>Why bagging works</li> <li>Gradient boosted trees explained</li> <li>Maths and viz of Gradient Boosting</li> <li>Intuitive explanation of entropy</li> </ul>"},{"location":"resources/data-science/#weather-data","title":"Weather data","text":"<ul> <li>Prediction of severe thunderstorm events with ensemble deep learning and radar data</li> <li>Pirate weather API</li> <li>Meteostat Python library</li> <li>GraphCast: AI model for faster and more accurate global weather forecasting</li> <li>GraphCast: Learning skillful medium-range global weather forecasting</li> </ul>"},{"location":"resources/data-science/#xai","title":"XAI","text":"<ul> <li>Interpretable ML</li> <li>Interpretable ML with Python</li> <li>SHAP decision plot</li> <li>Making sense of Shapley values</li> <li>SHAP values and kernelexplainer</li> <li>Additive feature importances</li> <li>SHAP overview</li> <li>Explainer dashboard</li> <li>Shapash model explaining webapp</li> <li>Black box vs glass box models</li> <li>Interpretable Machine Learning book</li> <li>InterpretML</li> <li>Permutation feature importance</li> <li>Interpretation of Isolation Forest with <code>shap</code></li> <li>Eli5</li> <li>SHAP vs ACV</li> <li>FastTreeSHAP: speed up SHAP values computation for tree-based models</li> <li>Grad-CAM: Visual Explanations from Deep Networks via Gradient-based Localization</li> </ul>"},{"location":"resources/data-science/a-b-testing/","title":"A/B Testing","text":"<ul> <li>Art of A/B testing</li> <li>When and when not to A/B test</li> <li>Fundamentals of A/B testing</li> <li>Netflix: interpreting A/B testing results part 1</li> <li>Netflix: interpreting A/B testing results part 2</li> <li>How to Accurately Test Significance with Difference in Difference Models</li> </ul>"},{"location":"resources/data-science/anomaly-detection/","title":"Anomaly detection","text":"<ul> <li>Time series anomaly detection</li> <li>Isolation forest</li> <li>Anomaly detection with <code>pycaret</code></li> <li>Equipment effectiveness with python</li> <li>Real-time time series anomaly detection</li> <li>Anomaly detection with copulas</li> <li>PyOD: Python outlier detection library</li> <li>5 anomaly detection algorithms with sklearn implementation</li> <li>Auto anomaly detection with isolation forest</li> <li>Probabilistic forecasting of binary events using regression</li> <li>Luminol: a light weight Python library for time series anomaly detection and correlation</li> <li>Alibi Detect: an open source Python library focused on outlier, adversarial and drift detection</li> </ul>"},{"location":"resources/data-science/automl/","title":"AutoML","text":"<ul> <li>AutoML python libraries</li> <li>TPOT pipelines optimization with genetic algorithms</li> <li>MLBox</li> </ul>"},{"location":"resources/data-science/bayesian-methods/","title":"Bayesian methods","text":"<ul> <li>Bayesian revenue estimation</li> <li>Estimating probabilities with bayesian modeling</li> <li>Probabilistic programming and Bayesian methods for hackers</li> <li>Bayesian neural network with <code>pyro</code> and <code>pytorch</code></li> <li>Bayesian modeling with <code>pymc3</code></li> <li>Richard Gott Princeton</li> <li>How to be less wrong</li> <li>Bayesian logistic regression with <code>pymc3</code></li> <li>Naive Bayes</li> <li>Math behind Bayes methods</li> <li>Mathematical explanation of Naive Bayes</li> <li>Bayesian inference with <code>pymc3</code></li> <li>Bayesian Time Series linear regression</li> <li>Bayesian optimization</li> <li>Bayesian inference</li> <li>Gelman book Columbia university</li> <li>Bayesian state space model with <code>pymc3</code></li> <li>Bayesian inference and MCMC variational inference</li> <li><code>bambi</code> for Bayesian Model Building Interface</li> <li>How to be less wrong: a Bayesian's guide to predicting the future with limited data</li> <li>bnlearn: a library for Bayesian network learning and inference</li> </ul>"},{"location":"resources/data-science/bin-packing/","title":"Bin Packing","text":"<ul> <li>BPP scipbook</li> <li>PuLP</li> <li>GitHub PuLP</li> <li>PuLP examples</li> <li>Wedding PuLP example</li> <li>PuLP paper</li> <li>Binpacking library</li> <li>Binpacking PuLP</li> </ul>"},{"location":"resources/data-science/binsize/","title":"Binsize","text":"<ul> <li>Histogram</li> <li>Model risk</li> <li>Optimal number of bins Freedman Diaconis rule</li> <li>Understanding Freedman Diaconis rule</li> <li>Freedman Diaconis rule paper</li> </ul>"},{"location":"resources/data-science/causal-inference/","title":"Causal Inference","text":"<ul> <li>Causal Inference handbook</li> <li>The Effect: An Introduction to Research Design and Causality</li> <li>Intro to Causal Inference course</li> <li>What is Causal Inference?</li> <li>PyWhy: ML based causal inference by Microsoft DoWhy</li> <li>CausalPy hands-on</li> </ul>"},{"location":"resources/data-science/churn-analysis/","title":"Churn analysis","text":"<ul> <li>Modeling customer churn when churns are not observed</li> <li>EDA empirical cumulative distribution</li> <li>Customer churn management</li> <li>Predicting customer churn for telcom</li> <li>Churn analysis via PyCaret</li> </ul>"},{"location":"resources/data-science/classification/","title":"Classification","text":"<ul> <li>Reliability diagrams for probability calibration</li> <li>Composite classification metrics</li> <li>SMOTE for synthetic data augmentation and unbalanced datasets</li> <li>Calculating business value of binary classification</li> <li><code>predict_proba</code> probabilities calibration</li> <li>Why class balancing can be avoided</li> <li>Matthews Correlation Coefficient (MCC) and Brier score</li> <li>Precision and Recall visually explained</li> <li>The Effect of Class Imbalance on Precision-Recall Curves</li> <li>Classification metrics calibration</li> <li><code>binclass-tools</code> for binary classification inspection</li> </ul>"},{"location":"resources/data-science/clustering/","title":"Clustering","text":"<ul> <li>Tomato clustering</li> <li>Alternatives to k-means</li> <li>Clustering metrics</li> <li>Find optimal k in KNN</li> <li>K-Means</li> <li>Anatomy of K-Means</li> <li>Clustering algorithms comparison</li> <li>Intro to hierarchical clustering</li> <li>How to determine optimal clusters number</li> <li>Clustering algorithms comparison</li> <li>Hierarchical Agglomerative Clustering</li> <li>Hierarchical clustering 101</li> <li>Regional Online Learnable Fields (ROLF)</li> <li>Interpretable KMeans via Classification feature importance</li> <li>How to select optimal k for K-Means</li> <li>How many clusters? Methods comparison</li> <li>Expectation Maximization soft clustering</li> <li>Markov clustering</li> <li>Unsupervised Learning Series: exploring DBScan</li> <li>Recursive Embedding and Clustering by Spotify</li> </ul>"},{"location":"resources/data-science/code-differentiation/","title":"Code differentiation","text":"<ul> <li>Differentiation from scratch</li> <li>Differentiable programming</li> <li>Taichi</li> </ul>"},{"location":"resources/data-science/community-detection/","title":"Community detection","text":"<ul> <li>Louvain algorithm for community detection</li> <li>Decoding the Manhattan Project's Network</li> </ul>"},{"location":"resources/data-science/computer-vision/","title":"Computer Vision","text":"<ul> <li>Lane detection</li> <li>Modern computer vision with <code>caer</code></li> <li><code>scikit-image</code> for image processing</li> <li>FiftyOne app</li> <li>Augmentor for image augmentation</li> <li>Concept: a technique that leverages CLIP and BERTopic-based techniques to perform Concept Modeling on images</li> </ul>"},{"location":"resources/data-science/correlation/","title":"Correlation","text":"<ul> <li>Non-linear correlation matrix</li> <li>Predictive power score (PPS)</li> </ul>"},{"location":"resources/data-science/curse-of-dimensionality/","title":"Curse Of Dimensionality","text":"<ul> <li>Curse of dimensionality explained</li> </ul>"},{"location":"resources/data-science/customer-value/","title":"Customer value","text":"<ul> <li>Customer segmentation</li> <li>Seasonal customers via time series analysis</li> <li>Identify seasonal customers with Python</li> <li>Customer lifetime value prediction</li> <li>Business DS</li> <li>Quantiles from ML model</li> <li>DS guide to subscription businesses</li> <li>Clustering for customer segmentation</li> </ul>"},{"location":"resources/data-science/datasets/","title":"Dataset","text":"<ul> <li>Dataset search</li> <li>Hand drawn data</li> <li>Faker</li> <li>Mimesis</li> <li>SDV</li> <li>Diffbot</li> <li>Datasette</li> <li>Hand drawn data in Jupyter with <code>drawdata</code></li> <li>World Bank data API</li> <li>Footprint Network</li> <li>Sondaggi politico elettorali ITA</li> <li>Microsoft's Bing road detections</li> <li>Kontur population dataset</li> <li>ISPRA: Open Data sul dissesto idrogeologico</li> <li>Folktables</li> <li>The official portal for European data</li> <li>Awesome datasets</li> </ul>"},{"location":"resources/data-science/deep-learning/","title":"Deep Learning","text":"<ul> <li>D2L</li> <li>Implementing DL from scratch in Python</li> </ul>"},{"location":"resources/data-science/dimensionality-reduction/","title":"Dimensionality Reduction","text":"<ul> <li>Locally linear embedding (LLE)</li> </ul>"},{"location":"resources/data-science/dynamic-pricing/","title":"Dynamic pricing","text":"<ul> <li>Dynamic pricing for theatre</li> <li>Regression for price optimization</li> <li>Dynamic Pricing with Reinforcement Learning from Scratch: Q-Learning</li> </ul>"},{"location":"resources/data-science/embeddings/","title":"Embeddings","text":"<ul> <li>Embetter: scikit-learn compatible embeddings for computer vision and text</li> <li>An intuitive introduction to text embeddings</li> <li>The Hidden World of (Vector) Indexes</li> <li>Why cosine similarity between sentence embeddings is always positive</li> </ul>"},{"location":"resources/data-science/energy/","title":"Energy and Power Systems","text":"<ul> <li>PyPSA: Python for Power System Analysis</li> </ul>"},{"location":"resources/data-science/ensemble-models/","title":"Ensemble models","text":"<ul> <li><code>vectstack</code> for models stacking</li> <li>One general model vs many specialized ones</li> </ul>"},{"location":"resources/data-science/features-engineering-selection/","title":"Features engineering and selection","text":"<ul> <li>Boruta</li> <li>Guide to feature extraction</li> <li>Feature selection don'ts</li> <li>Features normally distributed</li> <li>How and Why</li> <li>Feast: an open source feature store for machine learning</li> <li>Shapicant: a feature selection package based on SHAP and target permutation, for pandas and Spark</li> </ul>"},{"location":"resources/data-science/football-analytics/","title":"Football analytics","text":"<ul> <li>Paper</li> <li>Predict Euro 2020 winner</li> <li>Poisson regression for football match results prediction</li> <li>Predicting FIFA World Cup 2022 winner</li> </ul>"},{"location":"resources/data-science/function-learning/","title":"Function learning","text":"<ul> <li>Adaptive: Parallel Active Learning of Mathematical Functions</li> </ul>"},{"location":"resources/data-science/game-theory/","title":"Game Theory","text":"<ul> <li>Game Theory intro with Python</li> </ul>"},{"location":"resources/data-science/gaussian-mixture-models/","title":"Gaussian Mixture Models","text":"<ul> <li>EM algorithm for GMM</li> <li>GMM explained</li> </ul>"},{"location":"resources/data-science/gaussian-processes/","title":"Gaussian Processes","text":"<ul> <li>Intuitive guide to Gaussian processes</li> <li>Gaussian process regression</li> <li>Other uses of Gaussian processes</li> </ul>"},{"location":"resources/data-science/genetic-algorithm/","title":"Genetic algorithm","text":"<ul> <li>Intro to GA for optimization</li> </ul>"},{"location":"resources/data-science/geo/","title":"Geo science","text":"<ul> <li>Transportation DS</li> <li>Spatial autocorrelation</li> <li>Geospatial data declustering</li> <li>EDA of spatial data and spatial autocorrelation</li> <li>GPS trajectory clustering</li> <li>Geospatial indexing with quadkeys</li> <li>Travel time estimatione using quadkeys</li> <li>Geographic Data Science with Python</li> <li>Geocoding via Geoapify</li> <li>Geospatial Data Engineering: Spatial Indexing</li> <li>Proximity Analysis: a few words about spatial data processing</li> <li>Deep Dive into ESA's Sentinel API</li> <li>Geospatial Analysis and Representation for Data Science course for the master in Data Science University of Trento</li> <li>Overture Maps Data Repo</li> <li>3D Geospatial Data Integration with Python: The Ultimate Guide</li> <li><code>srai</code>: Spatial Representations for Artificial Intelligence</li> <li>Earth Isn't Flat, and Neither Should Your Voronoi Diagrams Be</li> <li>Voronoi diagram in Manhattan metric</li> <li>Geospatial Indexing Explained: A Comparison of Geohash, S2, and H3</li> </ul>"},{"location":"resources/data-science/gradient-methods/","title":"Gradient methods","text":"<ul> <li>ML and particle motion in liquid</li> <li>Gradient descent deep dive</li> </ul>"},{"location":"resources/data-science/hyperparameters-tuning/","title":"Hyperparameters Tuning","text":"<ul> <li><code>optuna</code> library for hyperparameter tuning in logistic regression</li> <li>Gaussian processes for ML models tuning</li> <li>Optuna and sklearn integration</li> <li>Hyperparameters tuning with Optuna and human-in-the-loop</li> <li>Evolutionary and genetic algorithms for parameters tuning</li> <li>Bayesian hyperparameters optimization</li> <li><code>mango</code>: a parallel hyperparameter tuning library</li> <li>Mango tutorial</li> </ul>"},{"location":"resources/data-science/information-theory/","title":"Information Theory","text":"<ul> <li>Intro to Shannon Information Theory</li> </ul>"},{"location":"resources/data-science/kernel-methods/","title":"Kernel Methods","text":"<ul> <li>Kernel trick</li> <li>Kernel regression</li> </ul>"},{"location":"resources/data-science/llm/","title":"Large Language Models (LLM)","text":"<ul> <li>ChatGPT Is An Extra-Ordinary Python Programmer</li> <li>StartChat Playground by Hugging Face</li> <li>What is ChatGPT doing and why does it work</li> <li>GPT in 60 Lines of NumPy</li> <li>privateGPT</li> <li>Pushing Prompt Engineering to the Limit</li> <li>How Foundation Model Providers Comply with the Draft EU AI Act</li> <li>A Gentle Introduction to LLM APIs</li> <li>All You Need to Know to Build Your First LLM App</li> <li>Mastering Prompt Engineering</li> <li>How to Run LLMs Locally</li> <li>LangChain: Building applications with LLMs through composability</li> <li>DeclarAI: turning Python code into production-ready LLM tasks</li> <li>Open Source LLMs To Power A LLM Application</li> <li>Large language models, explained with a minimum of math and jargon</li> <li>Inside GPT: Understanding the text generation</li> <li>Llama 2: Open Foundation and Fine-Tuned Chat Models</li> <li>Understand how BERT constructs state-of-the-art embeddings</li> <li>codellama</li> <li>NLP tasks via LLM</li> <li>From encoding to embeddings</li> <li>Large Language Models: Sentence-BERT</li> <li>Methods For Improving Your Large Language Model</li> <li>Vector Databases and How to Use Them to Augment LLM</li> <li>Large Language Models: RoBERTa, a Robustly Optimized BERT Approach</li> <li>DeepEval: Unit Testing for LLMs</li> <li>Attention Sinks in LLMs for endless fluency</li> <li>Generative AI exists because of the transformer: this is how it works</li> <li>OpenLLM Leaderboard</li> <li>All you need to know to Develop using Large Language Models</li> <li>LMQL: a programming language for large language models</li> <li>GPT-Engineer</li> <li>Chatbot Arena: Benchmarking LLMs in the Wild</li> <li>magentic: easily integrate Large Language Models into your Python code</li> <li>Hard Truths About Generative AI for Technology Leaders</li> <li>AlphaCodium: From Prompt Engineering to Flow Engineering</li> <li>Cheshire-Cat: Production ready AI assistant framework</li> </ul>"},{"location":"resources/data-science/machine-learning/","title":"Machine Learning","text":"<p>Machine Learning Tooling GitHub space with ranked lists of awesome Python libraries for, updated weekly.</p> <ul> <li>GUI for ML workflow and pipeline discovery</li> <li>ML prototypes</li> <li>Designing intelligence</li> <li>AI, ML and DL</li> <li>Game theory for ML interpretation</li> <li><code>pycaret</code></li> <li>Hybrid rule based ML</li> <li><code>pycaret-2.0</code></li> <li>QLattice</li> <li>Applied ML use cases</li> <li>Google ML glossary</li> <li>130 ML Tricks And Resources Carefully Curated</li> </ul>"},{"location":"resources/data-science/machine-learning/#model-evaluation","title":"Model evaluation","text":"<ul> <li>Plot learning curve</li> <li>Validation sets</li> <li>ML Tool</li> <li>Validate and ML model</li> <li>Overfitting and underfitting</li> <li>Cross validation</li> <li>Validation curve</li> <li>MAPIE for confidence prediction intervals estimation</li> </ul>"},{"location":"resources/data-science/machine-learning/#model-monitoring","title":"Model monitoring","text":"<ul> <li>Static threshold vs anomalies and changepoints detection</li> <li>Different retrain strategies for ML models</li> <li>An end-to-end implementation of a prediction flow for kids who can't MLOps good</li> <li>Giskard: scan AI models to detect risks of biases, performance issues and errors</li> <li>MLflow</li> <li>Model drift</li> <li>Evidently for model monitoring</li> <li>Weights and Biases</li> <li>Sacred</li> <li>Omniboard as a Sacred frontend</li> <li>MLflow 101</li> <li>deepchecks</li> <li>MLNotify for training completion notification</li> <li>NannyML for post-deployment model performance monitoring</li> </ul>"},{"location":"resources/data-science/machine-learning/#mlops","title":"MLOps","text":"<ul> <li>What is MLOps</li> <li>MLOps maturity checklist</li> <li>Why data makes MLOps different</li> <li>ML model deployment strategies</li> <li>MLOps lifecycles</li> <li>A curated (awesome!) list of open source libraries to deploy, monitor, version, scale and secure production machine learning</li> <li>The Full Stack 7-steps MLOps framework</li> <li>CD for ML</li> <li>Our MLOps story: Production-Grade Machine Learning for Twelve Brands</li> <li>No, You Don't Need MLOps</li> </ul>"},{"location":"resources/data-science/marketing-analytics/","title":"Marketing Analytics","text":"<ul> <li>Beginner guide to Marketing Analytics</li> <li>Discrete-Time Markov Chains: Identifying Winning Customer Journeys in a Cashback Campaign</li> <li>Methods for Modelling Customer Lifetime Value: The Good Stuff and the Gotchas</li> </ul>"},{"location":"resources/data-science/markov-chains/","title":"Markov Chains","text":"<ul> <li>Attribution model</li> <li>Progressions</li> <li>Market simulator with Mark chains</li> <li>Markov chains</li> <li>Hidden Markov models</li> <li>Markov chain process and HMM</li> <li>Markov chain as text generation model</li> <li>Beatles lyrics generation via Markov Chains</li> <li>Markov chains for time series forecasting</li> </ul>"},{"location":"resources/data-science/mcmc/","title":"MCMC","text":"<ul> <li>Animations with MCMC</li> <li>Monte Carlo tree search</li> <li>Monte Carlo in PBP</li> <li>MCMC for cryptography and optimization</li> <li><code>pyro</code></li> <li>Metropolis-Hastings from scratch in Python</li> <li>Monte Carlo methods</li> <li>Random sampling via Python decorator</li> <li>Intro to Monte Carlo methods</li> <li>Simulating data with PyMC</li> <li>Mastering Monte Carlo: How to Simulate Your Way to Better Machine Learning Models</li> <li>Chaospy: a numerical toolbox for performing uncertainty quantification using polynomial chaos expansions and advanced Monte Carlo methods</li> <li>PyMC-Marketing: Bayesian Marketing Mix Modeling (MMM) &amp; Customer Lifetime Value (CLV)</li> </ul>"},{"location":"resources/data-science/nearest-neighbors/","title":"Nearest Neighbors","text":"<ul> <li>Voyager: a library for performing fast approximate nearest-neighbor searches on an in-memory collection of vectors</li> </ul>"},{"location":"resources/data-science/neural-networks/","title":"Neural Networks","text":"<ul> <li>Neural networks and deep learning</li> <li>Make NN paint to understand how they work</li> <li>Intro to neural networks</li> <li>NN manifolds topology</li> <li>Visualizing optimization trajectory in neural networks</li> <li>Deep dream convolutional networks full code</li> <li>Neural networks as ensembles of simpler models</li> <li>Neural networks as functions composition</li> <li>N-Students learning framework</li> <li>A short history of Neural Networks</li> <li>Drag Your GAN: Interactive Point-based Manipulation on the Generative Image Manifold</li> <li>AI Canon</li> </ul>"},{"location":"resources/data-science/nlp/","title":"Natural Language Processing (NLP)","text":"<ul> <li>EDA and visualization of text data</li> <li><code>text2emotion</code> to detect emotions from textual data</li> <li>Quantify information in statements with entropy from Information Theory</li> <li>NLTK</li> <li>Chatbot using <code>rasa</code></li> <li><code>rasa</code>: open source ML framework to automate text-and voice-based conversations</li> <li>WordNet for a lexical taxonomy of English words</li> <li>Clean text</li> <li>Gramformer for text correction</li> <li>Styleformer for text styling</li> <li>Data jobs description analyzed with scattertext</li> <li>Scattertext</li> <li><code>texthero</code></li> <li><code>yarl</code> for URL processing</li> <li><code>Ecco</code> for pattern visualization in text data</li> <li>Data QA to label data</li> <li>Text summarization</li> <li>Text similarity with Levenshtein distance</li> <li>Autocorrect for multilanguage spelling correction</li> <li>Neattext for cleaning textual data and text preprocessing</li> <li>Texthero tutorial</li> <li>Microsoft <code>presidio</code> for NER (Named Entity Recognition) and data anonymization</li> <li>SEER model for information extraction based on user-specified examples</li> <li>Textnets: text analysis with networks</li> <li>Universal romanizer tool</li> <li>Text summarization</li> <li>Sentence embedding</li> <li>Semantic search with <code>txtai</code></li> <li>Arabica and Cappuccino for text EDA</li> <li>Simple spelling check in Python</li> <li>A guide to computational linguistics and conversational AI</li> <li>diff-match-patch: robust algorithms to perform the operations required for synchronizing plain text</li> <li>PolyFuzz: fuzzy string matching and string grouping</li> <li>Outlines: a library for neural text generation</li> <li><code>sense2vec</code>: query vectors for multi-word phrases based on part-of-speech tags and entity labels</li> </ul>"},{"location":"resources/data-science/nlp/#topic-modeling","title":"Topic modeling","text":"<ul> <li>Concept modeling to link text and images</li> <li>Topic coherence measures</li> <li>Intro to topic modeling with Latent Dirichlet Allocation (LDA)</li> <li>Topic modeling strategies comparison</li> <li>Hands-on topic modeling via LDA</li> <li>Advanced Topic Modeling with BERTopic</li> <li>Topic Modeling with Llama 2</li> <li>cluestar: visualisation tools to get started with text classification tasks</li> <li>Practical Guide to Topic Modeling with Latent Dirichlet Allocation (LDA)</li> </ul>"},{"location":"resources/data-science/objects-tracking/","title":"Objects tracking","text":"<ul> <li><code>py-motmetrics</code></li> <li>Intro to multiple objects tracking metrics</li> </ul>"},{"location":"resources/data-science/ocr/","title":"OCR","text":"<ul> <li>Open source OCR tools</li> <li>Extract text written in different languages with <code>easyocr</code></li> </ul>"},{"location":"resources/data-science/optimization/","title":"Optimization","text":"<ul> <li>Lagrange multipliers</li> <li>Openopt</li> <li>OR-Tools</li> <li>Solving Sudoku via AI</li> <li>Arbitrage strategy with linear programming</li> <li>Lagrange multiplier demystified</li> <li>Python constraint</li> <li>Surrogate optimization</li> <li>Particle Swarm Optimization (PSO)</li> <li>Traveling Salesman Problem (TSP) heuristic</li> <li>Guide to dynamic programming</li> <li>Goal programming</li> <li>Artificial Bee Colony algorithm</li> <li>Animate particle swarm optimization</li> <li>ErlangC queue optimization with <code>pyworkforce</code></li> <li>Optimization heuristics</li> <li>How Amazon learned to cut its cardboard waste with pioneering web-based PackOpt tool</li> <li>Route optimization with Python</li> <li>The Vehicle Routing Problem: Exact and Heuristic Solutions</li> <li>List of optimization packages in Python</li> </ul>"},{"location":"resources/data-science/optimization/#scholarpedia","title":"Scholarpedia","text":"<ul> <li>Artificial Bee Colony</li> <li>Particle Swarm Optimization</li> <li>Ant Colony Optimization</li> </ul>"},{"location":"resources/data-science/pattern-mining/","title":"Pattern mining","text":"<ul> <li>Data mining techniques</li> </ul>"},{"location":"resources/data-science/physics/","title":"Physics","text":"<ul> <li>From physics to optimization</li> </ul>"},{"location":"resources/data-science/predictive-maintenance/","title":"Predictive Maintenance","text":"<ul> <li>Understanding Predictive Maintenance: Data Acquisition and Signal Denoising</li> <li>Understanding Predictive Maintenance: Unit Roots and Stationarity</li> <li>Understanding Predictive Maintenance: Wave Data and Feature Engineering (Part 1)</li> </ul>"},{"location":"resources/data-science/probability-statistics/","title":"Probability &amp; Statistics","text":"credits to: XKCD <ul> <li>Chi-square test</li> <li>Probability and statistics for DS</li> <li>Statistical significance</li> <li>Hypothesis test</li> <li>How to determine significance for hypothesis testing</li> <li>Visualize hypothesis testing</li> <li>Causal vs statistical inference</li> <li>Phi_k correlation coefficient</li> <li>PP score</li> <li>Generate random variables</li> <li><code>pingouin</code> better than <code>statsmodels</code></li> <li><code>pingouin</code> library for statistical tests</li> <li>Guide to confidence intervals</li> <li>Stop using p = 0.05</li> <li>What p-value stands for</li> <li>Optimal sample size</li> <li>Experiment design</li> <li>Rule of three: calculating probability of events not yet occurred</li> <li>Hypotheses testing with <code>scipy</code></li> <li>Adaptive p-value</li> <li>Probability distributions Q&amp;A - part 1</li> <li>Probability distributions Q&amp;A - part 2</li> <li>Correlation visually explained</li> <li>3 t-tests for data scientists</li> <li>Stats gist list: guide to jargon by Cassie Kozyrkov</li> <li>Algorithmic approach to statistical testing</li> <li>Kolmogorov-Smirnov test to check how data are distributed</li> <li>Empirical cumulative distribution: advantages over histogram for EDA</li> </ul>"},{"location":"resources/data-science/regression/","title":"Regression","text":"<ul> <li>Generalized linear models</li> <li>Generalized linear regression with <code>scikit-learn</code></li> <li>Ordinary least squared regression</li> <li>Adaptive LASSO</li> <li>What happens when you break the assumptions of linear regression</li> <li>Statistics supporting linear models</li> <li>Geodesic regression</li> <li>Symbolic regression</li> <li>Ridge regression from scratch</li> <li>Regularization in regression</li> <li>Deming regression</li> <li>Interpreting linear regression sum-up from statsmodels</li> <li>Logistic regression 101</li> <li>Complete guide to regression analysis</li> <li>Constrained logistic regression</li> <li>Robust regression</li> <li>Polynomial regression with scikit-learn</li> </ul>"},{"location":"resources/data-science/reinforcement-learning/","title":"Reinforcement Learning","text":"<ul> <li>Playing Blackjack with RL</li> <li>Math behind reinforcement learning</li> <li>How RL works</li> <li>Create a custom RL enviroment</li> <li>Start learning RL</li> <li>Dive into RL</li> <li>Policy gradient algorithms</li> <li>RL fundamentals</li> <li>Markov decision process</li> <li>Bellman equation and dynamic programming</li> <li>Reinforcement Learning series</li> <li>Multi-agent particle swarm</li> <li>The K-armed bandit problem</li> <li>Python packages to experiment with Reinforcement Learning</li> <li>Reinforcement Learning algorithms explained</li> <li>Training an Agent to Master a Simple Game Through Self-Play</li> <li>Training an Agent to Master Tic-Tac-Toe Through Self-Play</li> <li>Stablebaseline3: the Swiss Army Knife of Applied RL</li> </ul>"},{"location":"resources/data-science/resampling/","title":"Resampling","text":"<ul> <li>Weighted resampling in Matlab</li> </ul>"},{"location":"resources/data-science/revenue-science/","title":"Revenue science","text":"<ul> <li>Money tree for revenue prioritization</li> </ul>"},{"location":"resources/data-science/scada/","title":"Scada data analysis","text":"<ul> <li>Wind energy analytics toolbox</li> </ul>"},{"location":"resources/data-science/similarity-measures/","title":"Similarity measures","text":"<ul> <li>Similarity measures for data science</li> </ul>"},{"location":"resources/data-science/simulated-annealing/","title":"Simulated Annealing","text":"<ul> <li>Simulated annealing for optimization</li> </ul>"},{"location":"resources/data-science/sql/","title":"SQL","text":"<ul> <li>PugSQL</li> <li>Window functions in SparkSQL</li> <li>Advanced SQL queries in pandas</li> <li>SQL window functions</li> <li>5 SQL common queries</li> <li>SQL window functions</li> <li>Intermediate SQL queries</li> <li>6 lesser known queries</li> <li>10 SQL tips</li> <li>Settings for NLS in SQL Developer</li> <li>Advanced SQL concepts</li> <li>SQL advanced functions: qualify, arrays and more</li> <li>SQL CASE</li> <li>Python built-in database: SQLite</li> <li>Advanced SQL for Data Scientists: cube, array, window and math functions</li> <li>DuckDB: open source OLAP database</li> <li>Lost at SQL: the SQL learning game</li> <li>Window Functions: A Must Know for Data Engineers and Data Scientists</li> <li>How to Low-Pass Filter in Google BigQuery</li> </ul>"},{"location":"resources/data-science/streaming-ml/","title":"Streaming/Online Learning","text":"<ul> <li><code>river</code></li> <li>Intro to River</li> </ul>"},{"location":"resources/data-science/structural-equation-modeling/","title":"Structural Equation Modeling (SEM)","text":"<ul> <li>Structural equation modeling with <code>semopy</code></li> </ul>"},{"location":"resources/data-science/svm/","title":"SVM","text":"<ul> <li>Support vector machines</li> <li>SVM theory and practice</li> </ul>"},{"location":"resources/data-science/synthetic-data/","title":"Synthetic data","text":"<ul> <li>Synthetic mobility data generation</li> </ul>"},{"location":"resources/data-science/time-series/","title":"Time Series","text":"<ul> <li>Nested cross validation</li> <li>TS and feature selection</li> <li>Out-of-time validation</li> <li>scikit-learn prediction intervals</li> <li>Forecast visualization</li> <li>TS transfer learning</li> <li>Detecting stationarity</li> <li>End to end project</li> <li>Analysis and forecasting</li> <li>Seasonal ARIMA</li> <li>Forecasting models overview</li> <li>Causality inference</li> <li>Giotto time</li> <li>Time Series Analysis</li> <li>Time series in Python</li> <li>Matrix profile</li> <li>Brownian motion in Python</li> <li>Forecast energy consumption with neural networks and xgboost</li> <li>TS forecasting</li> <li>Statistical tests and ARIMA</li> <li>Dynamic time warping</li> <li>Whale identification TS processing</li> <li>Pattern mining with <code>stumpy</code></li> <li>Statistical tests for trend</li> <li>How to synchronize time series</li> <li>Time series libraries</li> <li>Kats by Facebook</li> <li>Merlion by Salesforce</li> <li>Darts</li> <li>Avoid data leakage in time series</li> <li>Orbit by Uber for Bayesian time series forecasting</li> <li>Time Series terminology</li> <li>Time Series forecasting cheatsheet</li> <li>Poisson Hidden Markov Model for Time Series regression</li> <li>PyCaret AutoML for Time Series</li> <li>Seasonal adjustment of daily time series</li> <li>TSA basics</li> <li>Univariate time series forecasting with Neural Networks</li> <li><code>sktime</code> as sklearn TSA interface</li> <li>Changepoints detection with e-divisive</li> <li>Time series data visualization</li> <li><code>statsforecast</code> for lightning fast forecasting</li> <li>Time features encoding: cyclic vs dummy vs numeric</li> <li>Scalecast</li> <li>Hierarchical forecast reconciliation</li> <li>Deep Learning for time series forecasting</li> <li>Interpreting ACF and PACF plots for time series</li> <li>Python Automatic Forecasting</li> <li>Forecasting with tree-based algorithms</li> <li>FEDOT: an AutoML approach to time series forecasting</li> <li>Time series forecasting with Transformers</li> <li>Conformal prediction interval with scikit-learn, MAPIE and TSPIRAL</li> <li><code>mlforecast</code>: scalable machine learning based time series forecasting</li> <li>Time Series Forecasting with Scikit-learn</li> <li>Time Series for Climate Change: Forecasting Energy Demand</li> <li>Skforecast: a Python library that eases using scikit-learn regressors as single and multi-step forecasters</li> <li>Time series complexity analysis using entropy</li> <li><code>functime</code> is a powerful Python library for production-ready global forecasting and time-series feature extraction on large panel datasets</li> <li>Feature Engineering for Time Series Regression</li> <li>TimeGPT: The First Foundation Model for Time Series Forecasting</li> <li>Group time-series split</li> <li>Feature Engineering for Time Series</li> <li>TSMixer: The Latest Forecasting Model by Google</li> <li><code>tsfresh</code>: Time Series Feature extraction based on scalable hypothesis tests</li> <li><code>pytimetk</code>: time series easier, faster, more fun</li> <li><code>autogluon</code>: AutoML for Image, Text, Time Series, and Tabular Data</li> <li>AutoGluon-TimeSeries: Every Time Series Forecasting Model In One Library</li> <li>Time Series Forecasting with TiDE</li> </ul>"},{"location":"resources/data-science/time-series/#prophet","title":"Prophet","text":"<ul> <li>Is Facebook's \"Prophet\" the Time-Series Messiah, or Just a Very Naughty Boy?</li> <li>LSTM and Prophet</li> <li>Prophet forecasting</li> <li>AutoArima Prophet adapter in statsforecast</li> <li>Fixing Prophet forecasting issue</li> </ul>"},{"location":"resources/data-science/time-series/#greykite","title":"Greykite","text":"<ul> <li>Greykite by Linkedin</li> <li>Intro to Greykite</li> <li>Tuning a model in Greykite</li> </ul>"},{"location":"resources/data-science/trees/","title":"Tree-based methods","text":"<ul> <li>Entropy in decision trees</li> <li>Intuition behind Shannon entropy</li> <li>Explaining feature importance</li> <li><code>catboost</code> for gradient boosting decision trees</li> <li><code>catboost</code> docs</li> <li>Understanding decision trees</li> <li>Random Forest interpretability</li> <li><code>catboost</code> for model interpretation</li> <li>Visualize bagging effect on bias and variance</li> <li>How to draw decision trees</li> <li>Decision trees code</li> <li>Why you should learn <code>catboost</code></li> <li>Intuition behind <code>xgboost</code></li> <li>Tree boosted mixed models</li> <li>Random Forest in ML</li> <li>Multiple imputation with Random Forest</li> <li>Ensemble learning</li> <li>Decision tree and overfitting</li> <li>From boosting to gradient boosting</li> <li>Decision trees and lookahead strategy</li> <li>AdaBoost mathematical approach</li> <li>How to visualize Decision trees</li> <li>Random Forest vs Gradient Boosting</li> <li>Why bagging works</li> <li>Gradient boosted trees explained</li> <li>Maths and viz of Gradient Boosting</li> <li>Intuitive explanation of entropy</li> </ul>"},{"location":"resources/data-science/weather/","title":"Weather data","text":"<ul> <li>Prediction of severe thunderstorm events with ensemble deep learning and radar data</li> <li>Pirate weather API</li> <li>Meteostat Python library</li> <li>GraphCast: AI model for faster and more accurate global weather forecasting</li> <li>GraphCast: Learning skillful medium-range global weather forecasting</li> </ul>"},{"location":"resources/data-science/xai/","title":"XAI","text":"<ul> <li>Interpretable ML</li> <li>Interpretable ML with Python</li> <li>SHAP decision plot</li> <li>Making sense of Shapley values</li> <li>SHAP values and kernelexplainer</li> <li>Additive feature importances</li> <li>SHAP overview</li> <li>Explainer dashboard</li> <li>Shapash model explaining webapp</li> <li>Black box vs glass box models</li> <li>Interpretable Machine Learning book</li> <li>InterpretML</li> <li>Permutation feature importance</li> <li>Interpretation of Isolation Forest with <code>shap</code></li> <li>Eli5</li> <li>SHAP vs ACV</li> <li>FastTreeSHAP: speed up SHAP values computation for tree-based models</li> <li>Grad-CAM: Visual Explanations from Deep Networks via Gradient-based Localization</li> </ul>"},{"location":"resources/data-visualization/","title":"Data Visualization","text":""},{"location":"resources/data-visualization/#3d","title":"3D","text":"<ul> <li>Guide to real-time visualization of massive 3D point clouds in Python</li> </ul>"},{"location":"resources/data-visualization/#altair","title":"Altair","text":"<ul> <li>Multiple plots bindings with <code>altair</code></li> </ul>"},{"location":"resources/data-visualization/#animations","title":"Animations","text":"<ul> <li>Creating animated graphs</li> <li>Animations with matplotlib</li> <li>A day in the life of Americans</li> <li>3b1b and <code>manim</code></li> <li>Animating with <code>manim</code></li> <li>Coronavirus pandemic with choropleth maps</li> <li>Population models in Python</li> <li>GIF and math videos in Python</li> <li>GIF in Python</li> <li><code>manim</code> 101</li> <li><code>ipyvizzu</code></li> <li>Manim step by step intro</li> <li>Visualizing the shockwave propagation of Tonga vulcano eruption</li> <li>ManimML: animations and visualizations of common machine learning concepts</li> </ul>"},{"location":"resources/data-visualization/#books","title":"Books","text":"<ul> <li>Serialmentor data-viz</li> <li>Data visualization tools and books index by Keshif</li> </ul>"},{"location":"resources/data-visualization/#chord-diagram","title":"Chord diagram","text":"<ul> <li>Interactive chord diagram</li> </ul>"},{"location":"resources/data-visualization/#clustering","title":"Clustering","text":"<ul> <li>Clustergram 101</li> </ul>"},{"location":"resources/data-visualization/#colors","title":"Colors","text":"<ul> <li>Colorbrewer</li> <li>How to use color in data visualization</li> <li>Coolors</li> <li>Canva color combinations</li> <li>The power of color palette</li> <li>What to consider when choosing colors</li> <li>Palette transfer via KMeans</li> <li>How the right colormap helps revealing hidden information</li> <li>Pantone colors</li> </ul>"},{"location":"resources/data-visualization/#confusion-matrix","title":"Confusion matrix","text":"<ul> <li>Confusion matrix visualized</li> <li>Visual guide to the confusion matrix</li> </ul>"},{"location":"resources/data-visualization/#dashboard-design","title":"Dashboard design","text":"<ul> <li>Dashboard design patterns</li> </ul>"},{"location":"resources/data-visualization/#data-journalism","title":"Data Journalism","text":"<ul> <li>Data Journalism spatial projection for story decomposition</li> <li>vis4.net: random thoughts on visualization and data journalism by Gregor Aisch</li> </ul>"},{"location":"resources/data-visualization/#scrolling-visualisation-with-d3js","title":"Scrolling Visualisation with <code>D3.js</code>","text":"<ul> <li>How to build a scroller</li> <li>How to create an interactive scrolling visualization with D3.js</li> <li>Storytelling with maps and scrolling</li> </ul>"},{"location":"resources/data-visualization/#data-mapping","title":"Data Mapping","text":"<ul> <li>from Data to Viz</li> <li>Word embedding visualization</li> <li>Visual vocabulary</li> </ul>"},{"location":"resources/data-visualization/#data-storytelling","title":"Data Storytelling","text":"<ul> <li>Tips for creating persuasive charts</li> <li>Make your data talk</li> <li>Prevent misinformation in data visualization</li> <li>The power of visualization in DS</li> <li>Information visualization</li> <li>Art and science of data visualization</li> <li>DS concepts visually explained</li> <li>Time doesn't exist</li> <li>Color in data visualization</li> <li>Stakeholders friendly dot plots</li> <li>The limits of knowledge</li> <li>Visual vocabulary</li> <li>Why this chart is bad</li> <li>ML concepts interactively</li> <li>The 10-20-30 rule</li> <li>365 days in data-viz</li> <li>Visual and interactive explorables data-stories</li> </ul>"},{"location":"resources/data-visualization/#datamapplot","title":"Datamapplot","text":"<ul> <li>Topic Modeling with Quantized LLMs</li> <li>DataMapPlot: Creating beautiful plot of data maps</li> </ul>"},{"location":"resources/data-visualization/#datashader","title":"Datashader","text":"<ul> <li>Networks</li> </ul>"},{"location":"resources/data-visualization/#decision-trees","title":"Decision Trees","text":"<ul> <li><code>pybaobabdt</code> BaobabView</li> </ul>"},{"location":"resources/data-visualization/#design-systems","title":"Design Systems","text":"<ul> <li>Design Systems Database</li> </ul>"},{"location":"resources/data-visualization/#dumbbell-charts","title":"Dumbbell charts","text":"<ul> <li>Dumbbell charts vs bar charts</li> </ul>"},{"location":"resources/data-visualization/#eda","title":"EDA","text":"<ul> <li>Exploratory design in data visualization</li> <li>Speed up data analysis in Python</li> <li>Improve data analysis in Python</li> <li><code>dataprep</code> for EDA</li> <li><code>pandas-profiling</code> vs <code>dataprep</code></li> <li><code>hiplot</code> for parallel coordinate plots</li> <li>Pandas EDA libraries</li> <li>Lux for Python pandas</li> <li>SweetViz for EDA</li> <li><code>datapane</code> to automate HTML report</li> <li>RAWGraphs to explore spreadsheets data</li> <li><code>arviz</code> for Bayesian EDA</li> <li>Kangas: exploring, analyzing, and visualizing large-scale multimedia data</li> <li>PyGWalker: A Python Library for Exploratory Data Analysis with Visualization</li> </ul>"},{"location":"resources/data-visualization/#energy-data","title":"Energy data","text":"<ul> <li>Modo Energy Plotter</li> </ul>"},{"location":"resources/data-visualization/#geodata","title":"Geodata","text":"<ul> <li>How to build a non geographical map</li> <li>Feature extraction with <code>selenium</code> and google maps</li> <li>Python interface for GMT (Generic Mapping Tools)</li> <li>Ridge geomap</li> <li>Shuttle Radar Topography Mission parser</li> <li>Geemap for Google Earth maps interaction</li> <li>KeplerGL</li> <li>How to add Google Maps layer to Folium map</li> <li>Leafmap</li> <li>eefolium: Folium meets Google Earth Engine</li> <li>ipyleaflet</li> <li>Embed Plotly chart into Folium popups</li> <li>Greppo for geospatial dashboarding</li> <li>Electricity Maps</li> <li>Planning the perfect hike with OSMnx</li> <li>Prettymaps</li> <li>Visualizing routes with VeRoViz</li> </ul>"},{"location":"resources/data-visualization/#gui","title":"GUI","text":"<ul> <li>Jupyter <code>pivottable_js</code></li> <li>Build real world applications</li> </ul>"},{"location":"resources/data-visualization/#hierarchical","title":"Hierarchical","text":"<ul> <li>Technology tree visualization with <code>skillmap</code></li> <li>treevis: a Visual Bibliography of Tree Visualization</li> </ul>"},{"location":"resources/data-visualization/#high-dimensional-data","title":"High-dimensional data","text":"<ul> <li>HyperTools</li> <li>Cosmos: large networks visualization</li> </ul>"},{"location":"resources/data-visualization/#andrews-curves","title":"Andrews curves","text":"<ul> <li>Andrews plot Wikipedia page</li> <li><code>pandas.plotting.andrews_curves</code></li> </ul>"},{"location":"resources/data-visualization/#javascript-libraries","title":"Javascript libraries","text":"<ul> <li>Javascript charts</li> <li><code>d3blocks</code>: Python porting of D3js<sup>1</sup></li> <li>Carbon charts: a reusable framework-agnostic D3 charting library</li> <li>D3js scatterplots in Python</li> </ul>"},{"location":"resources/data-visualization/#line-plot","title":"Line Plot","text":"<ul> <li>How to Create a Heat-Line Plot: a multi-dimensional segmented line graph</li> </ul>"},{"location":"resources/data-visualization/#model-accuracy","title":"Model accuracy","text":"<ul> <li>Model lift</li> <li>Yellowbrick</li> </ul>"},{"location":"resources/data-visualization/#networks-and-graphs","title":"Networks and graphs","text":"<ul> <li>Ipysigma</li> </ul>"},{"location":"resources/data-visualization/#pie-charts","title":"Pie Charts","text":"<ul> <li>A case against pie charts</li> </ul>"},{"location":"resources/data-visualization/#plotly","title":"Plotly","text":"<ul> <li>Animations Hans Rosling style</li> <li>Plotly graphics</li> <li>Data visualization for data-storytelling</li> <li>Professional scatter plots</li> </ul>"},{"location":"resources/data-visualization/#publications-plot","title":"Publications plot","text":"<ul> <li>Reproducible scientific figures with <code>pylustrator</code></li> </ul>"},{"location":"resources/data-visualization/#reports","title":"Reports","text":"<ul> <li>Creating pdf reports with <code>pdfkit</code> and <code>jinja2</code> templates</li> </ul>"},{"location":"resources/data-visualization/#ridgeline-plots","title":"Ridgeline plots","text":"<ul> <li><code>joypy</code> for drawing ridgeline plots</li> </ul>"},{"location":"resources/data-visualization/#roc-curve","title":"ROC Curve","text":"<ul> <li>Classification model evaluation</li> <li>ROC curve</li> <li>Understanding ROC and AUC</li> <li>ROC and precision-recall curves</li> <li>Classification models and ROC curve</li> <li>Mechanics of the ROC curve</li> <li>ROC and AUC explained</li> </ul>"},{"location":"resources/data-visualization/#scatterplot","title":"Scatterplot","text":""},{"location":"resources/data-visualization/#binned","title":"Binned","text":"<ul> <li>Binsreg</li> <li>Binned scatterplot blog post</li> </ul>"},{"location":"resources/data-visualization/#connected","title":"Connected","text":"<ul> <li>Connected Scatterplots Make Me Feel Dumb</li> </ul>"},{"location":"resources/data-visualization/#seaborn","title":"Seaborn","text":"<ul> <li>Advanced data visualization with <code>seaborn</code></li> <li>How to merge seaborn plots</li> </ul>"},{"location":"resources/data-visualization/#social-science","title":"Social science","text":"<ul> <li>Visualization of elections with python</li> <li>How visualizing social inequality can make it worse</li> <li>Beyond Numbers: How Ethical Data Visualization Tells the Human Story</li> </ul>"},{"location":"resources/data-visualization/#strip-charts-for-time-series","title":"Strip charts for time-series","text":"<ul> <li>Visualize many time-series at once</li> </ul>"},{"location":"resources/data-visualization/#theory","title":"Theory","text":"<ul> <li>Rules for using colors</li> <li>Human-Computer Interaction principles</li> <li>Design informative visualizations</li> <li>The importance of scale and scaling data</li> <li>Applied theory to improve line charts</li> <li>Psychology behind data visualization</li> <li>Does data visualization have rules?</li> <li>Introduction to data visualization theory</li> <li>Data Visualization guidelines from <code>data.europa.eu</code></li> <li>Declarative vs. Imperative Plotting</li> </ul>"},{"location":"resources/data-visualization/#datawrapper-blog","title":"Datawrapper Blog","text":"<ul> <li>Emphasize what you want readers to see with color</li> <li>What to consider when using text in data visualizations</li> <li>Which fonts to use for your charts and tables</li> <li>How to choose an interpolation for your color scale</li> </ul>"},{"location":"resources/data-visualization/#time-series-visualization","title":"Time Series visualization","text":"<ul> <li>Time series plot with GitHub contributions style</li> <li>July for calendar plot</li> <li>Stop aggregating: context and rearrangement for time series visualization with Observable plot</li> <li>Radial visualization of time series</li> <li>Visualization tips for long time series</li> </ul>"},{"location":"resources/data-visualization/#tools","title":"Tools","text":"<ul> <li>Causal</li> <li>10 tools for data visualization</li> <li>Other 5 tools for data visualization</li> <li>Datawrapper</li> <li>RAWGraphs</li> </ul>"},{"location":"resources/data-visualization/#upset-plot","title":"Upset plot","text":"<ul> <li>UpSet</li> <li>Visualizing intersections and overlaps with Venn diagrams and Upset plots</li> <li>UpSetPlot library</li> <li>matplotlib-venn library</li> </ul>"},{"location":"resources/data-visualization/#widgets","title":"Widgets","text":"<ul> <li><code>ipywidgets</code></li> </ul> <ol> <li> <p>A day in the life of Americans is finally available in Python!\u00a0\u21a9</p> </li> </ol>"},{"location":"resources/data-visualization/3d/","title":"3D","text":"<ul> <li>Guide to real-time visualization of massive 3D point clouds in Python</li> </ul>"},{"location":"resources/data-visualization/altair/","title":"Altair","text":"<ul> <li>Multiple plots bindings with <code>altair</code></li> </ul>"},{"location":"resources/data-visualization/animations/","title":"Animations","text":"<ul> <li>Creating animated graphs</li> <li>Animations with matplotlib</li> <li>A day in the life of Americans</li> <li>3b1b and <code>manim</code></li> <li>Animating with <code>manim</code></li> <li>Coronavirus pandemic with choropleth maps</li> <li>Population models in Python</li> <li>GIF and math videos in Python</li> <li>GIF in Python</li> <li><code>manim</code> 101</li> <li><code>ipyvizzu</code></li> <li>Manim step by step intro</li> <li>Visualizing the shockwave propagation of Tonga vulcano eruption</li> <li>ManimML: animations and visualizations of common machine learning concepts</li> </ul>"},{"location":"resources/data-visualization/books/","title":"Books","text":"<ul> <li>Serialmentor data-viz</li> <li>Data visualization tools and books index by Keshif</li> </ul>"},{"location":"resources/data-visualization/chord-diagram/","title":"Chord diagram","text":"<ul> <li>Interactive chord diagram</li> </ul>"},{"location":"resources/data-visualization/clustering/","title":"Clustering","text":"<ul> <li>Clustergram 101</li> </ul>"},{"location":"resources/data-visualization/colors/","title":"Colors","text":"<ul> <li>Colorbrewer</li> <li>How to use color in data visualization</li> <li>Coolors</li> <li>Canva color combinations</li> <li>The power of color palette</li> <li>What to consider when choosing colors</li> <li>Palette transfer via KMeans</li> <li>How the right colormap helps revealing hidden information</li> <li>Pantone colors</li> </ul>"},{"location":"resources/data-visualization/confusion-matrix/","title":"Confusion matrix","text":"<ul> <li>Confusion matrix visualized</li> <li>Visual guide to the confusion matrix</li> </ul>"},{"location":"resources/data-visualization/dashboard/","title":"Dashboard design","text":"<ul> <li>Dashboard design patterns</li> </ul>"},{"location":"resources/data-visualization/data-journalism/","title":"Data Journalism","text":"<ul> <li>Data Journalism spatial projection for story decomposition</li> <li>vis4.net: random thoughts on visualization and data journalism by Gregor Aisch</li> </ul>"},{"location":"resources/data-visualization/data-journalism/#scrolling-visualisation-with-d3js","title":"Scrolling Visualisation with <code>D3.js</code>","text":"<ul> <li>How to build a scroller</li> <li>How to create an interactive scrolling visualization with D3.js</li> <li>Storytelling with maps and scrolling</li> </ul>"},{"location":"resources/data-visualization/data-mapping/","title":"Data Mapping","text":"<ul> <li>from Data to Viz</li> <li>Word embedding visualization</li> <li>Visual vocabulary</li> </ul>"},{"location":"resources/data-visualization/data-storytelling/","title":"Data Storytelling","text":"<ul> <li>Tips for creating persuasive charts</li> <li>Make your data talk</li> <li>Prevent misinformation in data visualization</li> <li>The power of visualization in DS</li> <li>Information visualization</li> <li>Art and science of data visualization</li> <li>DS concepts visually explained</li> <li>Time doesn't exist</li> <li>Color in data visualization</li> <li>Stakeholders friendly dot plots</li> <li>The limits of knowledge</li> <li>Visual vocabulary</li> <li>Why this chart is bad</li> <li>ML concepts interactively</li> <li>The 10-20-30 rule</li> <li>365 days in data-viz</li> <li>Visual and interactive explorables data-stories</li> </ul>"},{"location":"resources/data-visualization/datamapplot/","title":"Datamapplot","text":"<ul> <li>Topic Modeling with Quantized LLMs</li> <li>DataMapPlot: Creating beautiful plot of data maps</li> </ul>"},{"location":"resources/data-visualization/datashader/","title":"Datashader","text":"<ul> <li>Networks</li> </ul>"},{"location":"resources/data-visualization/decision-trees/","title":"Decision Trees","text":"<ul> <li><code>pybaobabdt</code> BaobabView</li> </ul>"},{"location":"resources/data-visualization/design/","title":"Design Systems","text":"<ul> <li>Design Systems Database</li> </ul>"},{"location":"resources/data-visualization/dumbbell-charts/","title":"Dumbbell charts","text":"<ul> <li>Dumbbell charts vs bar charts</li> </ul>"},{"location":"resources/data-visualization/eda/","title":"EDA","text":"<ul> <li>Exploratory design in data visualization</li> <li>Speed up data analysis in Python</li> <li>Improve data analysis in Python</li> <li><code>dataprep</code> for EDA</li> <li><code>pandas-profiling</code> vs <code>dataprep</code></li> <li><code>hiplot</code> for parallel coordinate plots</li> <li>Pandas EDA libraries</li> <li>Lux for Python pandas</li> <li>SweetViz for EDA</li> <li><code>datapane</code> to automate HTML report</li> <li>RAWGraphs to explore spreadsheets data</li> <li><code>arviz</code> for Bayesian EDA</li> <li>Kangas: exploring, analyzing, and visualizing large-scale multimedia data</li> <li>PyGWalker: A Python Library for Exploratory Data Analysis with Visualization</li> </ul>"},{"location":"resources/data-visualization/energy/","title":"Energy data","text":"<ul> <li>Modo Energy Plotter</li> </ul>"},{"location":"resources/data-visualization/geodata/","title":"Geodata","text":"<ul> <li>How to build a non geographical map</li> <li>Feature extraction with <code>selenium</code> and google maps</li> <li>Python interface for GMT (Generic Mapping Tools)</li> <li>Ridge geomap</li> <li>Shuttle Radar Topography Mission parser</li> <li>Geemap for Google Earth maps interaction</li> <li>KeplerGL</li> <li>How to add Google Maps layer to Folium map</li> <li>Leafmap</li> <li>eefolium: Folium meets Google Earth Engine</li> <li>ipyleaflet</li> <li>Embed Plotly chart into Folium popups</li> <li>Greppo for geospatial dashboarding</li> <li>Electricity Maps</li> <li>Planning the perfect hike with OSMnx</li> <li>Prettymaps</li> <li>Visualizing routes with VeRoViz</li> </ul>"},{"location":"resources/data-visualization/gui/","title":"GUI","text":"<ul> <li>Jupyter <code>pivottable_js</code></li> <li>Build real world applications</li> </ul>"},{"location":"resources/data-visualization/hierarchical/","title":"Hierarchical","text":"<ul> <li>Technology tree visualization with <code>skillmap</code></li> <li>treevis: a Visual Bibliography of Tree Visualization</li> </ul>"},{"location":"resources/data-visualization/high-dimensional-data/","title":"High-dimensional data","text":"<ul> <li>HyperTools</li> <li>Cosmos: large networks visualization</li> </ul>"},{"location":"resources/data-visualization/high-dimensional-data/#andrews-curves","title":"Andrews curves","text":"<ul> <li>Andrews plot Wikipedia page</li> <li><code>pandas.plotting.andrews_curves</code></li> </ul>"},{"location":"resources/data-visualization/js-libraries/","title":"Javascript libraries","text":"<ul> <li>Javascript charts</li> <li><code>d3blocks</code>: Python porting of D3js<sup>1</sup></li> <li>Carbon charts: a reusable framework-agnostic D3 charting library</li> <li>D3js scatterplots in Python</li> </ul> <ol> <li> <p>A day in the life of Americans is finally available in Python!\u00a0\u21a9</p> </li> </ol>"},{"location":"resources/data-visualization/line/","title":"Line Plot","text":"<ul> <li>How to Create a Heat-Line Plot: a multi-dimensional segmented line graph</li> </ul>"},{"location":"resources/data-visualization/model-accuracy/","title":"Model accuracy","text":"<ul> <li>Model lift</li> <li>Yellowbrick</li> </ul>"},{"location":"resources/data-visualization/network/","title":"Networks and graphs","text":"<ul> <li>Ipysigma</li> </ul>"},{"location":"resources/data-visualization/pie-chart/","title":"Pie Charts","text":"<ul> <li>A case against pie charts</li> </ul>"},{"location":"resources/data-visualization/plotly/","title":"Plotly","text":"<ul> <li>Animations Hans Rosling style</li> <li>Plotly graphics</li> <li>Data visualization for data-storytelling</li> <li>Professional scatter plots</li> </ul>"},{"location":"resources/data-visualization/publications-plot/","title":"Publications plot","text":"<ul> <li>Reproducible scientific figures with <code>pylustrator</code></li> </ul>"},{"location":"resources/data-visualization/reports/","title":"Reports","text":"<ul> <li>Creating pdf reports with <code>pdfkit</code> and <code>jinja2</code> templates</li> </ul>"},{"location":"resources/data-visualization/ridgeline/","title":"Ridgeline plots","text":"<ul> <li><code>joypy</code> for drawing ridgeline plots</li> </ul>"},{"location":"resources/data-visualization/roc-curve/","title":"ROC Curve","text":"<ul> <li>Classification model evaluation</li> <li>ROC curve</li> <li>Understanding ROC and AUC</li> <li>ROC and precision-recall curves</li> <li>Classification models and ROC curve</li> <li>Mechanics of the ROC curve</li> <li>ROC and AUC explained</li> </ul>"},{"location":"resources/data-visualization/scatterplot/","title":"Scatterplot","text":""},{"location":"resources/data-visualization/scatterplot/#binned","title":"Binned","text":"<ul> <li>Binsreg</li> <li>Binned scatterplot blog post</li> </ul>"},{"location":"resources/data-visualization/scatterplot/#connected","title":"Connected","text":"<ul> <li>Connected Scatterplots Make Me Feel Dumb</li> </ul>"},{"location":"resources/data-visualization/seaborn/","title":"Seaborn","text":"<ul> <li>Advanced data visualization with <code>seaborn</code></li> <li>How to merge seaborn plots</li> </ul>"},{"location":"resources/data-visualization/social-science/","title":"Social science","text":"<ul> <li>Visualization of elections with python</li> <li>How visualizing social inequality can make it worse</li> <li>Beyond Numbers: How Ethical Data Visualization Tells the Human Story</li> </ul>"},{"location":"resources/data-visualization/strip-charts/","title":"Strip charts for time-series","text":"<ul> <li>Visualize many time-series at once</li> </ul>"},{"location":"resources/data-visualization/theory/","title":"Theory","text":"<ul> <li>Rules for using colors</li> <li>Human-Computer Interaction principles</li> <li>Design informative visualizations</li> <li>The importance of scale and scaling data</li> <li>Applied theory to improve line charts</li> <li>Psychology behind data visualization</li> <li>Does data visualization have rules?</li> <li>Introduction to data visualization theory</li> <li>Data Visualization guidelines from <code>data.europa.eu</code></li> <li>Declarative vs. Imperative Plotting</li> </ul>"},{"location":"resources/data-visualization/theory/#datawrapper-blog","title":"Datawrapper Blog","text":"<ul> <li>Emphasize what you want readers to see with color</li> <li>What to consider when using text in data visualizations</li> <li>Which fonts to use for your charts and tables</li> <li>How to choose an interpolation for your color scale</li> </ul>"},{"location":"resources/data-visualization/time-series/","title":"Time Series visualization","text":"<ul> <li>Time series plot with GitHub contributions style</li> <li>July for calendar plot</li> <li>Stop aggregating: context and rearrangement for time series visualization with Observable plot</li> <li>Radial visualization of time series</li> <li>Visualization tips for long time series</li> </ul>"},{"location":"resources/data-visualization/tools/","title":"Tools","text":"<ul> <li>Causal</li> <li>10 tools for data visualization</li> <li>Other 5 tools for data visualization</li> <li>Datawrapper</li> <li>RAWGraphs</li> </ul>"},{"location":"resources/data-visualization/upset-plot/","title":"Upset plot","text":"<ul> <li>UpSet</li> <li>Visualizing intersections and overlaps with Venn diagrams and Upset plots</li> <li>UpSetPlot library</li> <li>matplotlib-venn library</li> </ul>"},{"location":"resources/data-visualization/widgets/","title":"Widgets","text":"<ul> <li><code>ipywidgets</code></li> </ul>"},{"location":"resources/education/","title":"Education","text":""},{"location":"resources/education/#collaborative-coding","title":"Collaborative coding","text":"<ul> <li>Replit</li> <li>DagsHub</li> </ul>"},{"location":"resources/education/#competition","title":"Competition","text":"<ul> <li>DS competition design</li> </ul>"},{"location":"resources/education/#cons","title":"Cons","text":"<ul> <li>Why so many data scientists are leaving their jobs</li> <li>AI hierarchy of needs</li> <li>How not to hire your first data scientist</li> <li>If your company isn't good at analytics, it's not ready for AI</li> <li>Why you're not a job-ready data scientist</li> <li>Reasons not to hire a data scientist</li> <li>If you think your company needs a data scientist, you're probably wrong</li> <li>The sexiest job of 22<sup>nd</sup> century</li> <li>The sexiest job of 21<sup>st</sup> century</li> <li>Data graveyard and the valley of death and despair</li> <li>Pros and cons: truth about working as a Data Scientist</li> <li>Data Scientists will be extinct before 2030</li> <li>Things you are not told about data science</li> <li>Reasons to quit being a data scientist</li> <li>What we talk about when we talk about imposter syndrome</li> </ul>"},{"location":"resources/education/#data-art-science","title":"Data, Art &amp; Science","text":"<ul> <li>Fireworks</li> <li>Synthwave with matplotlib</li> <li>A date with yourself</li> <li>Cyberpunk style in matplotlib</li> <li>Color palette extraction</li> <li>Visualize emotional arcs of movie scripts with rule-based sentiment analysis</li> <li>Processing</li> <li>Human brain and backpropagation</li> <li>175 years of words in Scientific American</li> <li>Discovering the shape of fractions</li> <li>Google PaLM (Pathways Language Model)</li> <li>DALL-E 2: from text to images</li> <li>WebGL Fluid Simulation</li> <li>Stable Diffusion by Hugging Face</li> </ul>"},{"location":"resources/education/#data-sonification","title":"Data sonification","text":"<ul> <li>Turn music into data</li> <li>Playing cryptocurrency time series</li> <li>Turn time series to music with <code>miditime</code></li> <li>Data sonification tutorials</li> <li>Sonic Pi: turn live coding into a musical instrument</li> </ul>"},{"location":"resources/education/#social-sciences","title":"Social sciences","text":"<ul> <li>Automating NYC: and (en)coding inequality?</li> <li>All The Names: Algorithmic Design and the 9/11 Memorial</li> </ul>"},{"location":"resources/education/#gamification","title":"Gamification","text":"<ul> <li>Habitica</li> <li>RPG to do list</li> </ul>"},{"location":"resources/education/#methodology","title":"Methodology","text":"<ul> <li>Strategies for learning data science</li> <li>Path for learning analytics and data skills</li> <li>From business question to data task</li> <li>Why you shouldn't be a generalist data scientist</li> <li>Build a trust infrastructure</li> <li>Data scientific method</li> <li>Yet another ML article</li> <li>What DS learners do wrong</li> <li>What is a full stack developer</li> <li>How to learn DS</li> <li>Great developers never stop learning</li> <li>The key DS question: so what?</li> <li>Being a DS does not make you a software engineer</li> <li>How to become a data scientist</li> <li>Data science conversation starters</li> <li>Generalist vs specialist data scientists</li> <li>Question to ask before starting a data science project</li> <li>What is data engineering</li> <li>Data science landscape</li> <li>Programming languages associated with highest salaries</li> <li>Data science and the age of acceleration</li> <li>Mistakes to avoid being a data scientist</li> <li>How to build AI for Twitter, Pinterest and Amazon</li> <li>The data island of truth: advices from Facebook and AirBnB</li> <li>Statistics and probability for expert data scientists</li> <li>What makes an excellent DS</li> <li>How to become a data scientist</li> <li>Metaflow motivation diagram</li> <li>How to resist the temptation to solve every problem</li> <li>Data science methodology</li> <li>Key requirements for an MLOps foundation</li> <li>Building ML models is like cooking</li> <li>Data Science curriculum for professionals</li> <li>Data documentation with 5W1H framework</li> <li>First rule of ML: start without ML</li> <li>Teach Yourself Programming in Ten Years</li> <li>Hidden aspects about being a Data Scientist</li> <li>4 rules for better data science</li> <li>Critical insights about Data Scientist profession</li> <li>How to interrogate unfamiliar code</li> <li>Coding learning path</li> <li>Developers second brain</li> <li>What is Data Engineering?</li> <li>Why tech writing is important</li> <li>The Data Cards Playbook: a toolkit for transparency in AI dataset documentation</li> <li>The Privileged Have Entered Their Escape Pods</li> <li>Complessita crescente vs. management e consulenza old-style: cosa non funziona e perch\u00e8</li> <li>The Paradigm Shift to Cloudless Computing</li> <li>The Real Problem with Software Development: It's not writing code, it's managing complexity</li> <li>Il curioso caso Orosz vs. McKinsey: Come misurare gli sviluppatori e una riflessione sull'autorevolezza</li> <li>hacker-laws: laws, theories, principles and patterns that developers will find useful</li> </ul>"},{"location":"resources/education/#python","title":"Python","text":"<ul> <li>Coding problems</li> <li>Advent of Code</li> <li>Learn python</li> <li>Online compiler</li> <li>The Hitchhiker's Guide to Python</li> <li>Python for Data Science</li> <li>Python learning paths</li> <li>Thonny: the beginner-friendly Python editor</li> <li>Learn Python with Jupyter</li> <li>pytudes</li> <li>Advanced Python Mastery: an exercise-driven course</li> </ul>"},{"location":"resources/education/#quantum-computing","title":"Quantum Computing","text":"<ul> <li>Quantum computing per ottimizzazione delle reti mobili</li> <li>Quantum computing as a field is obvious bullshit</li> </ul>"},{"location":"resources/education/#regulation","title":"Regulation","text":"<ul> <li>EU Artificial Intelligence Act</li> <li>Legge sull'Intelligenza Artificiale</li> <li>Understanding the EU AI Act as a Data Scientist</li> <li>Do Foundation Model Providers Comply with the Draft EU AI Act?</li> </ul>"},{"location":"resources/education/#teaching","title":"Teaching","text":"<ul> <li><code>handcalcs</code> for hand calculations</li> <li>Google LaTeXify</li> </ul>"},{"location":"resources/education/#technical-skills","title":"Technical skills","text":"<ul> <li>ML projects example</li> <li>Learn data science</li> <li>ML resources</li> <li>Research computing meetup</li> <li>Notebooks resources</li> <li>ISLR python</li> <li>Assessment and guide for statistics education</li> <li>UCLA Technology Innovations in Statistics Education</li> <li>Machine Learning University (MLU) by Amazon</li> <li>Illustrated Machine Learning</li> <li>Data Science Trivia</li> </ul>"},{"location":"resources/education/#tools","title":"Tools","text":"<ul> <li>Periodic table of DevOps</li> <li>Plotly vs Dash vs Streamlit</li> <li>AI developer tools and IKEA effect</li> <li>Google train ML teachable machine</li> </ul>"},{"location":"resources/education/#videos","title":"Videos","text":"<ul> <li>DS playlist 1</li> <li>DS playlist 2</li> </ul>"},{"location":"resources/education/collaborative-coding/","title":"Collaborative coding","text":"<ul> <li>Replit</li> <li>DagsHub</li> </ul>"},{"location":"resources/education/competition/","title":"Competition","text":"<ul> <li>DS competition design</li> </ul>"},{"location":"resources/education/cons/","title":"Cons","text":"<ul> <li>Why so many data scientists are leaving their jobs</li> <li>AI hierarchy of needs</li> <li>How not to hire your first data scientist</li> <li>If your company isn't good at analytics, it's not ready for AI</li> <li>Why you're not a job-ready data scientist</li> <li>Reasons not to hire a data scientist</li> <li>If you think your company needs a data scientist, you're probably wrong</li> <li>The sexiest job of 22<sup>nd</sup> century</li> <li>The sexiest job of 21<sup>st</sup> century</li> <li>Data graveyard and the valley of death and despair</li> <li>Pros and cons: truth about working as a Data Scientist</li> <li>Data Scientists will be extinct before 2030</li> <li>Things you are not told about data science</li> <li>Reasons to quit being a data scientist</li> <li>What we talk about when we talk about imposter syndrome</li> </ul>"},{"location":"resources/education/data-art-science/","title":"Data, Art &amp; Science","text":"<ul> <li>Fireworks</li> <li>Synthwave with matplotlib</li> <li>A date with yourself</li> <li>Cyberpunk style in matplotlib</li> <li>Color palette extraction</li> <li>Visualize emotional arcs of movie scripts with rule-based sentiment analysis</li> <li>Processing</li> <li>Human brain and backpropagation</li> <li>175 years of words in Scientific American</li> <li>Discovering the shape of fractions</li> <li>Google PaLM (Pathways Language Model)</li> <li>DALL-E 2: from text to images</li> <li>WebGL Fluid Simulation</li> <li>Stable Diffusion by Hugging Face</li> </ul>"},{"location":"resources/education/data-art-science/#data-sonification","title":"Data sonification","text":"<ul> <li>Turn music into data</li> <li>Playing cryptocurrency time series</li> <li>Turn time series to music with <code>miditime</code></li> <li>Data sonification tutorials</li> <li>Sonic Pi: turn live coding into a musical instrument</li> </ul>"},{"location":"resources/education/data-art-science/#social-sciences","title":"Social sciences","text":"<ul> <li>Automating NYC: and (en)coding inequality?</li> <li>All The Names: Algorithmic Design and the 9/11 Memorial</li> </ul>"},{"location":"resources/education/gamification/","title":"Gamification","text":"<ul> <li>Habitica</li> <li>RPG to do list</li> </ul>"},{"location":"resources/education/methodology/","title":"Methodology","text":"<ul> <li>Strategies for learning data science</li> <li>Path for learning analytics and data skills</li> <li>From business question to data task</li> <li>Why you shouldn't be a generalist data scientist</li> <li>Build a trust infrastructure</li> <li>Data scientific method</li> <li>Yet another ML article</li> <li>What DS learners do wrong</li> <li>What is a full stack developer</li> <li>How to learn DS</li> <li>Great developers never stop learning</li> <li>The key DS question: so what?</li> <li>Being a DS does not make you a software engineer</li> <li>How to become a data scientist</li> <li>Data science conversation starters</li> <li>Generalist vs specialist data scientists</li> <li>Question to ask before starting a data science project</li> <li>What is data engineering</li> <li>Data science landscape</li> <li>Programming languages associated with highest salaries</li> <li>Data science and the age of acceleration</li> <li>Mistakes to avoid being a data scientist</li> <li>How to build AI for Twitter, Pinterest and Amazon</li> <li>The data island of truth: advices from Facebook and AirBnB</li> <li>Statistics and probability for expert data scientists</li> <li>What makes an excellent DS</li> <li>How to become a data scientist</li> <li>Metaflow motivation diagram</li> <li>How to resist the temptation to solve every problem</li> <li>Data science methodology</li> <li>Key requirements for an MLOps foundation</li> <li>Building ML models is like cooking</li> <li>Data Science curriculum for professionals</li> <li>Data documentation with 5W1H framework</li> <li>First rule of ML: start without ML</li> <li>Teach Yourself Programming in Ten Years</li> <li>Hidden aspects about being a Data Scientist</li> <li>4 rules for better data science</li> <li>Critical insights about Data Scientist profession</li> <li>How to interrogate unfamiliar code</li> <li>Coding learning path</li> <li>Developers second brain</li> <li>What is Data Engineering?</li> <li>Why tech writing is important</li> <li>The Data Cards Playbook: a toolkit for transparency in AI dataset documentation</li> <li>The Privileged Have Entered Their Escape Pods</li> <li>Complessita crescente vs. management e consulenza old-style: cosa non funziona e perch\u00e8</li> <li>The Paradigm Shift to Cloudless Computing</li> <li>The Real Problem with Software Development: It's not writing code, it's managing complexity</li> <li>Il curioso caso Orosz vs. McKinsey: Come misurare gli sviluppatori e una riflessione sull'autorevolezza</li> <li>hacker-laws: laws, theories, principles and patterns that developers will find useful</li> </ul>"},{"location":"resources/education/python/","title":"Python","text":"<ul> <li>Coding problems</li> <li>Advent of Code</li> <li>Learn python</li> <li>Online compiler</li> <li>The Hitchhiker's Guide to Python</li> <li>Python for Data Science</li> <li>Python learning paths</li> <li>Thonny: the beginner-friendly Python editor</li> <li>Learn Python with Jupyter</li> <li>pytudes</li> <li>Advanced Python Mastery: an exercise-driven course</li> </ul>"},{"location":"resources/education/quantum-computing/","title":"Quantum Computing","text":"<ul> <li>Quantum computing per ottimizzazione delle reti mobili</li> <li>Quantum computing as a field is obvious bullshit</li> </ul>"},{"location":"resources/education/regulation/","title":"Regulation","text":"<ul> <li>EU Artificial Intelligence Act</li> <li>Legge sull'Intelligenza Artificiale</li> <li>Understanding the EU AI Act as a Data Scientist</li> <li>Do Foundation Model Providers Comply with the Draft EU AI Act?</li> </ul>"},{"location":"resources/education/teaching/","title":"Teaching","text":"<ul> <li><code>handcalcs</code> for hand calculations</li> <li>Google LaTeXify</li> </ul>"},{"location":"resources/education/technical-skills/","title":"Technical skills","text":"<ul> <li>ML projects example</li> <li>Learn data science</li> <li>ML resources</li> <li>Research computing meetup</li> <li>Notebooks resources</li> <li>ISLR python</li> <li>Assessment and guide for statistics education</li> <li>UCLA Technology Innovations in Statistics Education</li> <li>Machine Learning University (MLU) by Amazon</li> <li>Illustrated Machine Learning</li> <li>Data Science Trivia</li> </ul>"},{"location":"resources/education/tools/","title":"Tools","text":"<ul> <li>Periodic table of DevOps</li> <li>Plotly vs Dash vs Streamlit</li> <li>AI developer tools and IKEA effect</li> <li>Google train ML teachable machine</li> </ul>"},{"location":"resources/education/videos/","title":"Videos","text":"<ul> <li>DS playlist 1</li> <li>DS playlist 2</li> </ul>"},{"location":"resources/misc/","title":"Misc","text":""},{"location":"resources/misc/#games-development","title":"Games development","text":"<ul> <li>Game Boy Development community</li> </ul>"},{"location":"resources/misc/#hardware","title":"Hardware","text":"<ul> <li>Differences between software and hardware projects</li> </ul>"},{"location":"resources/misc/#knowledge-management","title":"Knowledge Management","text":"<ul> <li>Simon Sp\u00e4ti public second brain</li> <li>The PARA Method: The Simple System for Organizing Your Digital Life in Seconds</li> <li>Quartz: a set of tools that helps you publish a digital garden and notes as a website for free</li> <li>Obsidian tools: a Python package for analysing an Obsidian vault</li> <li>A no-brainer solution to turning your Obsidian PKM into a Zola site</li> <li>Mkdocs Obsidian is a combination of an Obsidian plugin and a Material mkdocs</li> <li>Lyz digital garden</li> <li>A curated list of awesome digital gardens and second brains</li> </ul>"},{"location":"resources/misc/#mathematics","title":"Mathematics","text":"<p>by XKCD</p>"},{"location":"resources/misc/#fourier-transform","title":"Fourier transform","text":"<ul> <li>Teach and learn Fourier transform geometrically</li> <li>K-space explorer for MRI image reconstruction</li> <li>The Fourier Transform and its applications in Machine Learning</li> </ul>"},{"location":"resources/misc/#topology","title":"Topology","text":"<ul> <li>Topology 101</li> <li>Ricci curvature</li> <li>Community network detection with Ricci flow and surgery on graphs</li> </ul>"},{"location":"resources/misc/#linear-algebra","title":"Linear Algebra","text":"<ul> <li>Matrix determinant</li> </ul>"},{"location":"resources/misc/#symbolic-calculations","title":"Symbolic calculations","text":"<ul> <li>Latex sympy calculator VSC extension</li> </ul>"},{"location":"resources/misc/#algorithms","title":"Algorithms","text":"<ul> <li>Discovering novel algorithms with AlphaTensor</li> <li>Beyond automatic differentiation</li> <li>Exposing the Power of the Kalman Filter</li> </ul>"},{"location":"resources/misc/#physics","title":"Physics","text":"<ul> <li>Sound: a visual explanation</li> <li>International Geomagnetic Reference Field</li> </ul>"},{"location":"resources/misc/games/","title":"Games development","text":"<ul> <li>Game Boy Development community</li> </ul>"},{"location":"resources/misc/hardware/","title":"Hardware","text":"<ul> <li>Differences between software and hardware projects</li> </ul>"},{"location":"resources/misc/km/","title":"Knowledge Management","text":"<ul> <li>Simon Sp\u00e4ti public second brain</li> <li>The PARA Method: The Simple System for Organizing Your Digital Life in Seconds</li> <li>Quartz: a set of tools that helps you publish a digital garden and notes as a website for free</li> <li>Obsidian tools: a Python package for analysing an Obsidian vault</li> <li>A no-brainer solution to turning your Obsidian PKM into a Zola site</li> <li>Mkdocs Obsidian is a combination of an Obsidian plugin and a Material mkdocs</li> <li>Lyz digital garden</li> <li>A curated list of awesome digital gardens and second brains</li> </ul>"},{"location":"resources/misc/math/","title":"Mathematics","text":"<p>by XKCD</p>"},{"location":"resources/misc/math/#fourier-transform","title":"Fourier transform","text":"<ul> <li>Teach and learn Fourier transform geometrically</li> <li>K-space explorer for MRI image reconstruction</li> <li>The Fourier Transform and its applications in Machine Learning</li> </ul>"},{"location":"resources/misc/math/#topology","title":"Topology","text":"<ul> <li>Topology 101</li> <li>Ricci curvature</li> <li>Community network detection with Ricci flow and surgery on graphs</li> </ul>"},{"location":"resources/misc/math/#linear-algebra","title":"Linear Algebra","text":"<ul> <li>Matrix determinant</li> </ul>"},{"location":"resources/misc/math/#symbolic-calculations","title":"Symbolic calculations","text":"<ul> <li>Latex sympy calculator VSC extension</li> </ul>"},{"location":"resources/misc/math/#algorithms","title":"Algorithms","text":"<ul> <li>Discovering novel algorithms with AlphaTensor</li> <li>Beyond automatic differentiation</li> <li>Exposing the Power of the Kalman Filter</li> </ul>"},{"location":"resources/misc/physics/","title":"Physics","text":"<ul> <li>Sound: a visual explanation</li> <li>International Geomagnetic Reference Field</li> </ul>"},{"location":"resources/python/","title":"Python","text":""},{"location":"resources/python/#api","title":"API","text":"<ul> <li>List of API wrappers</li> <li>Layman guide to create APIs for DS</li> <li>How to build an API in Python</li> <li>Datamodel code generator: create pydantic model from an openapi file and others</li> <li>FastAPI code generator: create a FastAPI app from an openapi file</li> </ul>"},{"location":"resources/python/#asynchronous-programming","title":"Asynchronous Programming","text":"<ul> <li>Intro to asynchronous programming in Python</li> <li>Understanding async, await and asyncio</li> </ul>"},{"location":"resources/python/#audio-recognition","title":"Audio recognition","text":"<ul> <li>Kaldi and speech recognition</li> <li>FastAI for audio classification and frequency transforms</li> <li>Sound data analysis with <code>librosa</code></li> <li>Whisper: OpenAI model for audio transcriptions</li> <li>Pedalboard: a Python library for working with audio: reading, writing, rendering, adding effects, and more</li> </ul>"},{"location":"resources/python/#automate-boring-stuff","title":"Automate boring stuff","text":"<ul> <li>Automate boring stuff</li> <li>Scheduling recurring jobs with Python</li> <li>Numerizer</li> <li>Calendar</li> <li>Mail with HTML template and charts</li> <li>Robotic Process Automation (RPA) with Python</li> <li><code>schedule</code> as Python scheduling library</li> <li>PyAutoGUI</li> <li>Convert docx to HTML with <code>mammoth</code></li> <li>How to build a serverless automation to cross-post blog articles</li> <li>Rocketry: a modern statement-based scheduling framework for Python</li> </ul>"},{"location":"resources/python/#caching","title":"Caching","text":"<ul> <li>Disk caching using joblib</li> </ul>"},{"location":"resources/python/#carbon-footprint","title":"Carbon footprint","text":"<ul> <li>Track carbon footprint with co2 emissions tracker</li> </ul>"},{"location":"resources/python/#cheatsheets","title":"Cheatsheets","text":"<ul> <li>Python data structures</li> <li>Numpy</li> <li>Python from zero to hero</li> <li>Python cheatsheet</li> </ul>"},{"location":"resources/python/#cli","title":"CLI","text":"<ul> <li>How to create a Python CLI app</li> <li>Colorama</li> <li>Python Fire</li> <li>Typer</li> <li>CLI comparison</li> </ul>"},{"location":"resources/python/#code-freezing","title":"Code freezing","text":"<ul> <li>Code freezing with Python</li> <li>Nativefier</li> </ul>"},{"location":"resources/python/#code-maintenance","title":"Code maintenance","text":"<ul> <li>Why your code is probably bad</li> <li>Coding mistakes made by DS</li> <li>How to make Python run faster</li> <li>Tools for production quality code</li> <li>Time complexity for DS</li> <li>Clean code Python</li> <li>Down with technical debt for Python DS</li> <li><code>py-spy</code> code profiler</li> <li><code>line_profiler</code> code profiler</li> <li>Mypy type checker</li> <li>Logging in python with <code>logzero</code></li> <li>Memory profiler for DS</li> <li>Python speedup skills</li> <li>Python coding mistakes</li> <li>Python best practices for DS</li> <li>Improving Python code efficiency</li> <li>How to write better Python code</li> <li>Reduce in Python</li> <li>Static code analysis</li> <li>Log, don't print</li> <li>Python type annotations</li> <li><code>pydantic</code> type checking</li> <li>Joblib to speed up Python pipelines</li> <li>Avoid recursion in favour of closure</li> <li>Custom context managers</li> <li>Complexity theory and Big O notation</li> <li>Parallelization with Python</li> <li>Python functions to interact with JSON</li> <li><code>icecream</code> for code debugging</li> <li><code>debugpy</code> for code debug</li> <li>Python features from 3.7 to 3.9</li> <li>How to avoid nested if-else statements</li> <li>Codetags for code comments</li> <li><code>kedro</code> for code modularization and pipeline visualization</li> <li><code>retry</code> decorator</li> <li>Monitoring Python code execution</li> <li><code>scalene</code> for ML code memory consumption</li> <li><code>birdseye</code> for visual code debugging</li> <li>Best practices for writing code comments</li> <li>Maintain and visualize Python dependencies</li> <li><code>pretty errors</code></li> <li><code>memray</code> code memory profiler</li> <li>Custom classes supporting <code>with</code> statement and context management</li> <li>PySnooper: a poor man's debugger</li> <li>Improve performance with caching via <code>@lru_cache</code></li> <li>The art of naming things</li> <li>Scalene: a Python CPU+GPU+memory profiler with AI-powered optimization proposals</li> <li>Generates call graphs for dynamic programming language</li> <li>Google Python Style Guide</li> </ul>"},{"location":"resources/python/#dash","title":"Dash","text":"<ul> <li><code>dash</code> regression</li> <li>Capturing mouse events position</li> <li><code>dash</code> SVM</li> <li>Reactive dashboard with <code>dash</code></li> <li>Introducing <code>dash</code></li> <li><code>dash</code> in PBP</li> <li><code>awesome-dash</code></li> <li>Metrics in <code>dash</code></li> <li>Long callbacks in Dash</li> </ul>"},{"location":"resources/python/#data-augmentation","title":"Data Augmentation","text":"<ul> <li>AugLy</li> <li><code>snorkel</code> for training data labeling</li> <li>Cleanlab: automatically find and fix label issues in ML datasets</li> </ul>"},{"location":"resources/python/#data-processing","title":"Data Processing","text":"<ul> <li><code>flowpy</code></li> <li>Data anonymization tutorial</li> </ul>"},{"location":"resources/python/#data-structures","title":"Data Structures","text":"<ul> <li>Container data types</li> <li>Python dictionaries on steroids with <code>munch</code></li> <li>Format comparison for large datasets</li> </ul>"},{"location":"resources/python/#data-validation","title":"Data validation","text":"<ul> <li><code>schema</code> library for data validation</li> <li><code>pandera</code></li> <li>Joint usage of <code>hypothesis</code> and <code>pandera</code> to automatically create validation test examples</li> </ul>"},{"location":"resources/python/#datatable","title":"Datatable","text":"<ul> <li><code>datatable</code></li> <li><code>datatable</code> library to speed up data analysis</li> </ul>"},{"location":"resources/python/#dates-and-times","title":"Dates and times","text":"<ul> <li>Pendulum as a drop-in replacement for datetime</li> </ul>"},{"location":"resources/python/#dependencies-management","title":"Dependencies management","text":"<ul> <li>Dependencies management</li> </ul>"},{"location":"resources/python/#digital-clock","title":"Digital clock","text":"<ul> <li>Digital clock with Python</li> </ul>"},{"location":"resources/python/#documentation","title":"Documentation","text":"<ul> <li>Autodocs with Python</li> <li>How to write an awesome readme</li> <li><code>diagrams</code> as code</li> <li><code>pycco</code> for source files inline docs</li> </ul>"},{"location":"resources/python/#mkdocs","title":"mkdocs","text":"<ul> <li>mktestdocs: run pytest against markdown files/docstrings</li> <li>mkdocs-jupyter: use Jupyter Notebooks in mkdocs</li> <li>Python markdown terminal built for mkdocs</li> <li>Mkdocs Newsletter: show the changes of documentation repositories in a user friendly format</li> </ul>"},{"location":"resources/python/#dtale","title":"DTale","text":"<ul> <li><code>dtale</code></li> </ul>"},{"location":"resources/python/#file-system","title":"File system","text":"<ul> <li>IO streams and ZIP archives</li> </ul>"},{"location":"resources/python/#functional-programming","title":"Functional programming","text":"<ul> <li>Functions attributes</li> <li>Python operators module</li> <li><code>funcy</code></li> <li>Lazy Evaluation Using Recursive Python Generators</li> <li>Writing Python like it's Rust</li> </ul>"},{"location":"resources/python/#game-development","title":"Game development","text":"<ul> <li>Pygame</li> <li>Traffic intersection simulation</li> <li>A primer on game programming</li> <li>Build Tic-Tac-Toe with Python</li> <li>Build a Tic-Tac-Toe Game Engine With an AI Player in Python</li> </ul>"},{"location":"resources/python/#gui","title":"GUI","text":"<ul> <li>Toga: a Python native, OS native GUI toolkit</li> <li>Textual: a Rapid Application Development framework for Python</li> </ul>"},{"location":"resources/python/#holidays","title":"Holidays","text":"<ul> <li>holidays</li> <li>workalendar</li> </ul>"},{"location":"resources/python/#hypothesis-testing","title":"Hypothesis testing","text":"<ul> <li>ht-python package</li> </ul>"},{"location":"resources/python/#jupyter","title":"Jupyter","text":"<ul> <li>Jupyter tools to increase productivity</li> <li>Nbconvert</li> <li>Jupyter notebooks for data science</li> <li>Jupyter themes</li> <li>Jupyter lab</li> <li>Interactive dashboards in Jupyter</li> <li>Tips for writing in Jupyter notebooks</li> <li>Magic Python commands to boost productivity</li> <li>Jupyter notebook from cmd raises <code>module not found</code> error</li> <li>Jupyter notebook installation issue using <code>pip</code></li> <li>Jupyter notebooks in Excel</li> <li>JupyterLab cells execution time</li> <li>Deploy Jupyter notebook with Binder</li> <li>Jupyter magic commands</li> <li>Tools for notebook reproducibility</li> <li>JupyterLite: Jupyter in web browser</li> <li>Jupyter Desktop App</li> <li>Enable notification for jupyter cells execution</li> <li><code>atoti</code> for BI dashboard in jupyter</li> <li>StickyLand for sticky notes in Jupyter</li> <li>Convert notebook to web app with Mercury</li> <li>Notebook cells output strip out with <code>nbstripout</code></li> <li>In and Out variables and %store magic command</li> <li>Jupyter Book</li> <li>Quarto: an open-source scientific and technical publishing system</li> </ul>"},{"location":"resources/python/#logging","title":"Logging","text":"<ul> <li>Structured logging</li> <li>Whylogs for data logging</li> </ul>"},{"location":"resources/python/#missing-values","title":"Missing values","text":"<ul> <li>Custom imputer for missing data in scikit-learn</li> </ul>"},{"location":"resources/python/#numpy","title":"Numpy","text":"<ul> <li>Reshaping numpy arrays</li> <li>Random number generator and random seed</li> <li>Numpy functions</li> </ul>"},{"location":"resources/python/#oo-programming","title":"OO Programming","text":"<ul> <li>Python classes and objects</li> <li>Dunder methods</li> <li>Special methods</li> <li>Class decorators</li> <li>Python function tools</li> <li>Managing instance attributes in Python</li> <li>Methods in Python for DS</li> <li>Function overloading</li> <li>Easy tutorial with Cat vs Dog</li> <li>Practical intro to object oriented programming</li> <li>Tricks for Python classes</li> <li>Design patterns</li> <li>RealPython best practices collection</li> <li>Python class <code>__slots__</code></li> <li>Strict constants in Python</li> <li>Python decorator patterns</li> <li><code>__init__</code> is not a constructor: a deep dive in Python object creation</li> </ul>"},{"location":"resources/python/#object-relational-mapper-orm","title":"Object Relational Mapper (ORM)","text":"<ul> <li>Peewee</li> <li>Tortoise</li> </ul>"},{"location":"resources/python/#or-tools","title":"OR-Tools","text":"<ul> <li>Google OR-Tools recipes</li> </ul>"},{"location":"resources/python/#pandas","title":"Pandas","text":"<ul> <li>Drop all rows after first occurrence of column value</li> <li>Drop all rows after first occurrence of column value 2</li> <li>Vectorize data aggregation</li> <li>Selecting rows based on value counts of a column</li> <li>Filter rows of dataframe with operator chaining</li> <li>Python dictionaries get nested value</li> <li>Styling <code>pandas</code></li> <li><code>bamboolib</code></li> <li><code>sidetable</code> with an introductive blog post</li> <li>HTML table in PBP</li> <li><code>cut</code> to transform numerical data into cateorical</li> <li><code>swifter</code> for parallel apply</li> <li><code>ConnectorX</code> to fast SQL data load into DataFrame</li> <li>Movingpandas for trajectory data</li> <li>Dataframe manipulations explained</li> <li><code>pandas-log</code></li> <li>Pandas illustrated: a visual guide</li> </ul>"},{"location":"resources/python/#numpy_1","title":"Numpy","text":"<ul> <li>Numpy illustrated: a visual guide</li> </ul>"},{"location":"resources/python/#polars","title":"Polars","text":"<ul> <li>Polars</li> <li>Polars intro by Practical Business Python</li> </ul>"},{"location":"resources/python/#password-management","title":"Password Management","text":"<ul> <li>Secure password handling</li> <li>Secrets management</li> </ul>"},{"location":"resources/python/#os-and-pathlib","title":"OS and Pathlib","text":"<ul> <li><code>pathlib</code></li> <li>Examples with Python's pathlib</li> <li>File system operations</li> <li>Pathlib vs os comparison</li> </ul>"},{"location":"resources/python/#polymorphism","title":"Polymorphism","text":"<ul> <li><code>multipledispatch</code> for polymorphism</li> </ul>"},{"location":"resources/python/#privacy","title":"Privacy","text":"<ul> <li>Privacy for class attributes and methods</li> </ul>"},{"location":"resources/python/#process-simulation","title":"Process simulation","text":"<ul> <li><code>simpy</code> for manifacturing simulation</li> <li>Modelling and simulations in data science</li> <li><code>mesa</code> agent-based modeling framework</li> </ul>"},{"location":"resources/python/#project-packaging","title":"Project packaging","text":"<ul> <li>Poetry</li> <li>Publish to PiP via Poetry</li> <li>Publish to PiP via Poetry v2</li> <li>Pooch: a friend to fetch your data files</li> <li>Robust Testing &amp; Packaging with <code>src</code> layout</li> <li>Python Packages: modern and efficient workflows for creating Python packages</li> </ul>"},{"location":"resources/python/#regex","title":"Regex","text":"<ul> <li>Regex made simple</li> <li>How to remember regex</li> <li>AutoRegex: from plain text to regex</li> </ul>"},{"location":"resources/python/#scikit-learn","title":"Scikit-learn","text":"<ul> <li>Pipelines with <code>sklearn</code></li> <li>Pipeline visualization</li> <li>Sklearn Pipelines for the Modern ML Engineer</li> <li>Pipeline for data preparation</li> </ul>"},{"location":"resources/python/#extensions","title":"Extensions","text":"<ul> <li><code>combo</code> for ML models combination</li> <li><code>scikit-multilearn</code> for multi-label learning</li> <li><code>scikit-lego</code></li> <li><code>lazypredict</code></li> <li><code>human-learn</code> to rule-based learning and interactive drawing rules</li> </ul>"},{"location":"resources/python/#probabl","title":"Probabl","text":"<ul> <li>Probabl open source gallery</li> </ul>"},{"location":"resources/python/#standard-library","title":"Standard library","text":"<ul> <li>Math module overview</li> <li>Boltons</li> <li>Priority queues and <code>heapq</code></li> </ul>"},{"location":"resources/python/#streamlit","title":"Streamlit","text":"<ul> <li>Coding ML tools like you code ML models</li> <li>Build and deploy <code>streamlit</code> applications</li> <li>Intermediate <code>streamlit</code></li> <li>Sharing <code>streamlit</code> securely</li> <li>Download file in <code>streamlit</code></li> <li><code>streamlit</code> inside JupyterHub</li> <li><code>streamlit</code> multi page hack</li> <li><code>streamlit</code> app to make apps</li> <li>Session state for multipage apps</li> <li>Drag scatter point with Bokeh events</li> <li><code>streamlit-heroku</code> deployment utils</li> <li>Display live 2D data in Streamlit</li> <li>Real time dashboard update with asyncio</li> <li>How to build a real time live dashboard</li> <li>Sync session state and app url via query params</li> <li>Table of contents in Streamlit</li> <li>Prettymaps Streamlit frontend</li> <li>Stlite: streamlit app running in browser</li> <li>Streamlit book</li> <li>Streamlit-Pydantic: auto-generate Streamlit UI elements from Pydantic models</li> <li>Package Streamlit into an Electron desktop app</li> <li>Prototyping Streamlit app via Figma and figma-to-streamlit plugin</li> <li>Streamlit type checking playground with mypy</li> <li>Creating repeatable elements</li> <li>Data analysis with Mito: a powerful spreadsheet in Streamlit</li> <li>Simplifying generative AI workflows</li> <li>Streamlit Contact Form Template</li> <li>Search grid for a Pandas DataFrame</li> </ul>"},{"location":"resources/python/#components","title":"Components","text":"<ul> <li>Ant Design Menu and Tree</li> <li>Authenticator</li> <li>Barfi: a visual flow-based programming component</li> <li>Bokeh events</li> <li>Calendar</li> <li>Component for chat UI</li> <li>Datalist</li> <li>Drawable canvas</li> <li>Elements for Material UI tools integration</li> <li>Extras</li> <li>Extra components</li> <li>Image comparison</li> <li>Image cropper</li> <li>Image selection component</li> <li>Lottie animations with <code>streamlit-lottie</code></li> <li>Marquee banner</li> <li>Option men\u00f9</li> <li>Pyvista for 3D objects visualization</li> <li>Raw echarts</li> <li>RevealJS slides</li> <li>Shadcn-ui</li> <li>SHAP</li> <li>Sortables</li> <li>Star rating</li> <li>Text labeling and annotation tool</li> <li>Text rating component</li> <li>Timeline</li> <li>Toggle switch</li> <li>Tree-shaped nested selectbox component</li> <li>User feedback</li> <li>Vizzu</li> <li>Vertical slider</li> </ul>"},{"location":"resources/python/#build-components","title":"Build components","text":"<ul> <li>End to end streamlit components tutorial</li> <li>How to create custom Streamlit components</li> <li>Introductive tutorial to Streamlit components</li> <li>Streamlit components tutorials</li> <li>Streamlit components video tutorial</li> <li>Streamlit tutorial app to build components</li> </ul>"},{"location":"resources/python/#strings","title":"Strings","text":"<ul> <li>Fuzzywuzzy</li> <li>Python strings</li> <li>Thefuzz</li> </ul>"},{"location":"resources/python/#structural-pattern-matching","title":"Structural Pattern Matching","text":"<ul> <li>PEP 636</li> </ul>"},{"location":"resources/python/#tensorflow","title":"Tensorflow","text":"<ul> <li>Tensorflow playground</li> <li>ML classifying text with NN and tensorflow</li> <li><code>einsum</code> for compact and efficient Einstein summation</li> </ul>"},{"location":"resources/python/#testing","title":"Testing","text":"<ul> <li><code>PyHamcrest</code>: a framework for writing matcher objects, allowing you to declaratively define match rules</li> <li><code>behave</code>: behavior-driven development based on Gherkin syntax</li> <li><code>hypothesis</code>: generates simple and comprehensible examples that make your tests fail</li> <li><code>mutmut</code>: a mutation testing system for Python, with a strong focus on ease of use</li> </ul>"},{"location":"resources/python/#unit-tests","title":"Unit tests","text":"<ul> <li>Unit testing for DS</li> <li><code>pytest</code></li> <li><code>pytest</code> and travis for github CI</li> <li><code>nox</code></li> <li><code>locust</code> as a test framework in pure Python</li> <li>Assertions vs Exceptions</li> <li>Python Mocking in Production</li> </ul>"},{"location":"resources/python/#misc-utils","title":"Misc utils","text":"<ul> <li>Barcodes, captcha and num2words</li> <li>Barcode generation with Python</li> <li>Modern high-performance serialization utilities for Python</li> <li><code>pysentation</code>: a CLI for displaying Python presentations</li> </ul>"},{"location":"resources/python/#python-versions","title":"Python versions","text":"<ul> <li>New features in Python 3.10</li> </ul>"},{"location":"resources/python/#video-editing","title":"Video editing","text":"<ul> <li>Moviepy</li> </ul>"},{"location":"resources/python/#vocal-reader","title":"Vocal reader","text":"<ul> <li>How to build an audiobook</li> <li>How to make your computer talk</li> </ul>"},{"location":"resources/python/#web-framework","title":"Web Framework","text":"<ul> <li>Deploying ML model as a REST API</li> <li>Denzel</li> <li>Dash development and deployment</li> <li>Deploy ML model with Flask and Heroku</li> <li>FastAPI</li> <li>Website to host Python web app</li> <li>Deploy Dash app to Heroku</li> <li>Build and deploy a ML web app</li> <li>Deploy <code>streamlit</code> on Heroku</li> <li>Anvil</li> <li>Pythonanywhere</li> <li>Deploy Dash app for free</li> <li><code>streamlit</code> deployment on Heroku</li> <li>Deploying <code>streamlit</code> on AWS Lightsail with nginx and docker</li> <li><code>gradio</code> as a lightweight alternative to Streamlit</li> <li>ML model deployment on iPhone</li> <li>Deploy PyCaret model via FastAPI</li> <li><code>PyWebIO</code> for web app development</li> <li>FastDash</li> <li>H2O Wave and its table component</li> <li>MLEM: package and deploy machine learning models</li> <li>10 Python web frameworks</li> <li>Reflex: performant, customizable web apps in pure Python</li> <li>Dara</li> <li>NiceGUI</li> <li>Vizro is a toolkit for creating modular data visualization applications</li> <li>Panel for data apps</li> </ul>"},{"location":"resources/python/#web-scraping","title":"Web scraping","text":"<ul> <li>Comparison between <code>BeatifulSoup</code>, <code>selenium</code> and <code>scrapy</code></li> <li>trafilatura: a Python package and command-line tool to gather text on the Web</li> <li>Helium: lighter web automation for Python</li> </ul>"},{"location":"resources/python/#whatsapp","title":"Whatsapp","text":"<ul> <li>Whatsapp via Python</li> <li>Whatsapp bot via Selenium</li> </ul>"},{"location":"resources/python/#windows-client","title":"Windows client","text":"<ul> <li>Windows toast notifications</li> <li>Gooey GUI</li> <li>Sound alarm when code finishes</li> <li>Desktop notifier app</li> <li>KnockKnock</li> </ul>"},{"location":"resources/python/api/","title":"API","text":"<ul> <li>List of API wrappers</li> <li>Layman guide to create APIs for DS</li> <li>How to build an API in Python</li> <li>Datamodel code generator: create pydantic model from an openapi file and others</li> <li>FastAPI code generator: create a FastAPI app from an openapi file</li> </ul>"},{"location":"resources/python/asynchronous-programming/","title":"Asynchronous Programming","text":"<ul> <li>Intro to asynchronous programming in Python</li> <li>Understanding async, await and asyncio</li> </ul>"},{"location":"resources/python/audio/","title":"Audio recognition","text":"<ul> <li>Kaldi and speech recognition</li> <li>FastAI for audio classification and frequency transforms</li> <li>Sound data analysis with <code>librosa</code></li> <li>Whisper: OpenAI model for audio transcriptions</li> <li>Pedalboard: a Python library for working with audio: reading, writing, rendering, adding effects, and more</li> </ul>"},{"location":"resources/python/automate-boring-stuff/","title":"Automate boring stuff","text":"<ul> <li>Automate boring stuff</li> <li>Scheduling recurring jobs with Python</li> <li>Numerizer</li> <li>Calendar</li> <li>Mail with HTML template and charts</li> <li>Robotic Process Automation (RPA) with Python</li> <li><code>schedule</code> as Python scheduling library</li> <li>PyAutoGUI</li> <li>Convert docx to HTML with <code>mammoth</code></li> <li>How to build a serverless automation to cross-post blog articles</li> <li>Rocketry: a modern statement-based scheduling framework for Python</li> </ul>"},{"location":"resources/python/caching/","title":"Caching","text":"<ul> <li>Disk caching using joblib</li> </ul>"},{"location":"resources/python/carbon-footprint/","title":"Carbon footprint","text":"<ul> <li>Track carbon footprint with co2 emissions tracker</li> </ul>"},{"location":"resources/python/cheatsheets/","title":"Cheatsheets","text":"<ul> <li>Python data structures</li> <li>Numpy</li> <li>Python from zero to hero</li> <li>Python cheatsheet</li> </ul>"},{"location":"resources/python/cli/","title":"CLI","text":"<ul> <li>How to create a Python CLI app</li> <li>Colorama</li> <li>Python Fire</li> <li>Typer</li> <li>CLI comparison</li> </ul>"},{"location":"resources/python/code-freezing/","title":"Code freezing","text":"<ul> <li>Code freezing with Python</li> <li>Nativefier</li> </ul>"},{"location":"resources/python/code-maintenance/","title":"Code maintenance","text":"<ul> <li>Why your code is probably bad</li> <li>Coding mistakes made by DS</li> <li>How to make Python run faster</li> <li>Tools for production quality code</li> <li>Time complexity for DS</li> <li>Clean code Python</li> <li>Down with technical debt for Python DS</li> <li><code>py-spy</code> code profiler</li> <li><code>line_profiler</code> code profiler</li> <li>Mypy type checker</li> <li>Logging in python with <code>logzero</code></li> <li>Memory profiler for DS</li> <li>Python speedup skills</li> <li>Python coding mistakes</li> <li>Python best practices for DS</li> <li>Improving Python code efficiency</li> <li>How to write better Python code</li> <li>Reduce in Python</li> <li>Static code analysis</li> <li>Log, don't print</li> <li>Python type annotations</li> <li><code>pydantic</code> type checking</li> <li>Joblib to speed up Python pipelines</li> <li>Avoid recursion in favour of closure</li> <li>Custom context managers</li> <li>Complexity theory and Big O notation</li> <li>Parallelization with Python</li> <li>Python functions to interact with JSON</li> <li><code>icecream</code> for code debugging</li> <li><code>debugpy</code> for code debug</li> <li>Python features from 3.7 to 3.9</li> <li>How to avoid nested if-else statements</li> <li>Codetags for code comments</li> <li><code>kedro</code> for code modularization and pipeline visualization</li> <li><code>retry</code> decorator</li> <li>Monitoring Python code execution</li> <li><code>scalene</code> for ML code memory consumption</li> <li><code>birdseye</code> for visual code debugging</li> <li>Best practices for writing code comments</li> <li>Maintain and visualize Python dependencies</li> <li><code>pretty errors</code></li> <li><code>memray</code> code memory profiler</li> <li>Custom classes supporting <code>with</code> statement and context management</li> <li>PySnooper: a poor man's debugger</li> <li>Improve performance with caching via <code>@lru_cache</code></li> <li>The art of naming things</li> <li>Scalene: a Python CPU+GPU+memory profiler with AI-powered optimization proposals</li> <li>Generates call graphs for dynamic programming language</li> <li>Google Python Style Guide</li> </ul>"},{"location":"resources/python/dash/","title":"Dash","text":"<ul> <li><code>dash</code> regression</li> <li>Capturing mouse events position</li> <li><code>dash</code> SVM</li> <li>Reactive dashboard with <code>dash</code></li> <li>Introducing <code>dash</code></li> <li><code>dash</code> in PBP</li> <li><code>awesome-dash</code></li> <li>Metrics in <code>dash</code></li> <li>Long callbacks in Dash</li> </ul>"},{"location":"resources/python/data-augmentation/","title":"Data Augmentation","text":"<ul> <li>AugLy</li> <li><code>snorkel</code> for training data labeling</li> <li>Cleanlab: automatically find and fix label issues in ML datasets</li> </ul>"},{"location":"resources/python/data-processing/","title":"Data Processing","text":"<ul> <li><code>flowpy</code></li> <li>Data anonymization tutorial</li> </ul>"},{"location":"resources/python/data-structures/","title":"Data Structures","text":"<ul> <li>Container data types</li> <li>Python dictionaries on steroids with <code>munch</code></li> <li>Format comparison for large datasets</li> </ul>"},{"location":"resources/python/data-validation/","title":"Data validation","text":"<ul> <li><code>schema</code> library for data validation</li> <li><code>pandera</code></li> <li>Joint usage of <code>hypothesis</code> and <code>pandera</code> to automatically create validation test examples</li> </ul>"},{"location":"resources/python/datatable/","title":"Datatable","text":"<ul> <li><code>datatable</code></li> <li><code>datatable</code> library to speed up data analysis</li> </ul>"},{"location":"resources/python/datetime/","title":"Dates and times","text":"<ul> <li>Pendulum as a drop-in replacement for datetime</li> </ul>"},{"location":"resources/python/dependencies/","title":"Dependencies management","text":"<ul> <li>Dependencies management</li> </ul>"},{"location":"resources/python/digital-clock/","title":"Digital clock","text":"<ul> <li>Digital clock with Python</li> </ul>"},{"location":"resources/python/documentation/","title":"Documentation","text":"<ul> <li>Autodocs with Python</li> <li>How to write an awesome readme</li> <li><code>diagrams</code> as code</li> <li><code>pycco</code> for source files inline docs</li> </ul>"},{"location":"resources/python/documentation/#mkdocs","title":"mkdocs","text":"<ul> <li>mktestdocs: run pytest against markdown files/docstrings</li> <li>mkdocs-jupyter: use Jupyter Notebooks in mkdocs</li> <li>Python markdown terminal built for mkdocs</li> <li>Mkdocs Newsletter: show the changes of documentation repositories in a user friendly format</li> </ul>"},{"location":"resources/python/dtale/","title":"DTale","text":"<ul> <li><code>dtale</code></li> </ul>"},{"location":"resources/python/file-system/","title":"File system","text":"<ul> <li>IO streams and ZIP archives</li> </ul>"},{"location":"resources/python/functional-programming/","title":"Functional programming","text":"<ul> <li>Functions attributes</li> <li>Python operators module</li> <li><code>funcy</code></li> <li>Lazy Evaluation Using Recursive Python Generators</li> <li>Writing Python like it's Rust</li> </ul>"},{"location":"resources/python/game-development/","title":"Game development","text":"<ul> <li>Pygame</li> <li>Traffic intersection simulation</li> <li>A primer on game programming</li> <li>Build Tic-Tac-Toe with Python</li> <li>Build a Tic-Tac-Toe Game Engine With an AI Player in Python</li> </ul>"},{"location":"resources/python/gui/","title":"GUI","text":"<ul> <li>Toga: a Python native, OS native GUI toolkit</li> <li>Textual: a Rapid Application Development framework for Python</li> </ul>"},{"location":"resources/python/holidays/","title":"Holidays","text":"<ul> <li>holidays</li> <li>workalendar</li> </ul>"},{"location":"resources/python/hypothesis-testing/","title":"Hypothesis testing","text":"<ul> <li>ht-python package</li> </ul>"},{"location":"resources/python/jupyter/","title":"Jupyter","text":"<ul> <li>Jupyter tools to increase productivity</li> <li>Nbconvert</li> <li>Jupyter notebooks for data science</li> <li>Jupyter themes</li> <li>Jupyter lab</li> <li>Interactive dashboards in Jupyter</li> <li>Tips for writing in Jupyter notebooks</li> <li>Magic Python commands to boost productivity</li> <li>Jupyter notebook from cmd raises <code>module not found</code> error</li> <li>Jupyter notebook installation issue using <code>pip</code></li> <li>Jupyter notebooks in Excel</li> <li>JupyterLab cells execution time</li> <li>Deploy Jupyter notebook with Binder</li> <li>Jupyter magic commands</li> <li>Tools for notebook reproducibility</li> <li>JupyterLite: Jupyter in web browser</li> <li>Jupyter Desktop App</li> <li>Enable notification for jupyter cells execution</li> <li><code>atoti</code> for BI dashboard in jupyter</li> <li>StickyLand for sticky notes in Jupyter</li> <li>Convert notebook to web app with Mercury</li> <li>Notebook cells output strip out with <code>nbstripout</code></li> <li>In and Out variables and %store magic command</li> <li>Jupyter Book</li> <li>Quarto: an open-source scientific and technical publishing system</li> </ul>"},{"location":"resources/python/logging/","title":"Logging","text":"<ul> <li>Structured logging</li> <li>Whylogs for data logging</li> </ul>"},{"location":"resources/python/missing-values/","title":"Missing values","text":"<ul> <li>Custom imputer for missing data in scikit-learn</li> </ul>"},{"location":"resources/python/numpy/","title":"Numpy","text":"<ul> <li>Reshaping numpy arrays</li> <li>Random number generator and random seed</li> <li>Numpy functions</li> </ul>"},{"location":"resources/python/oo-programming/","title":"OO Programming","text":"<ul> <li>Python classes and objects</li> <li>Dunder methods</li> <li>Special methods</li> <li>Class decorators</li> <li>Python function tools</li> <li>Managing instance attributes in Python</li> <li>Methods in Python for DS</li> <li>Function overloading</li> <li>Easy tutorial with Cat vs Dog</li> <li>Practical intro to object oriented programming</li> <li>Tricks for Python classes</li> <li>Design patterns</li> <li>RealPython best practices collection</li> <li>Python class <code>__slots__</code></li> <li>Strict constants in Python</li> <li>Python decorator patterns</li> <li><code>__init__</code> is not a constructor: a deep dive in Python object creation</li> </ul>"},{"location":"resources/python/orm/","title":"Object Relational Mapper (ORM)","text":"<ul> <li>Peewee</li> <li>Tortoise</li> </ul>"},{"location":"resources/python/ortools/","title":"OR-Tools","text":"<ul> <li>Google OR-Tools recipes</li> </ul>"},{"location":"resources/python/pandas/","title":"Pandas","text":"<ul> <li>Drop all rows after first occurrence of column value</li> <li>Drop all rows after first occurrence of column value 2</li> <li>Vectorize data aggregation</li> <li>Selecting rows based on value counts of a column</li> <li>Filter rows of dataframe with operator chaining</li> <li>Python dictionaries get nested value</li> <li>Styling <code>pandas</code></li> <li><code>bamboolib</code></li> <li><code>sidetable</code> with an introductive blog post</li> <li>HTML table in PBP</li> <li><code>cut</code> to transform numerical data into cateorical</li> <li><code>swifter</code> for parallel apply</li> <li><code>ConnectorX</code> to fast SQL data load into DataFrame</li> <li>Movingpandas for trajectory data</li> <li>Dataframe manipulations explained</li> <li><code>pandas-log</code></li> <li>Pandas illustrated: a visual guide</li> </ul>"},{"location":"resources/python/pandas/#numpy","title":"Numpy","text":"<ul> <li>Numpy illustrated: a visual guide</li> </ul>"},{"location":"resources/python/pandas/#polars","title":"Polars","text":"<ul> <li>Polars</li> <li>Polars intro by Practical Business Python</li> </ul>"},{"location":"resources/python/password/","title":"Password Management","text":"<ul> <li>Secure password handling</li> <li>Secrets management</li> </ul>"},{"location":"resources/python/pathlib/","title":"OS and Pathlib","text":"<ul> <li><code>pathlib</code></li> <li>Examples with Python's pathlib</li> <li>File system operations</li> <li>Pathlib vs os comparison</li> </ul>"},{"location":"resources/python/polymorphism/","title":"Polymorphism","text":"<ul> <li><code>multipledispatch</code> for polymorphism</li> </ul>"},{"location":"resources/python/privacy/","title":"Privacy","text":"<ul> <li>Privacy for class attributes and methods</li> </ul>"},{"location":"resources/python/process-simulation/","title":"Process simulation","text":"<ul> <li><code>simpy</code> for manifacturing simulation</li> <li>Modelling and simulations in data science</li> <li><code>mesa</code> agent-based modeling framework</li> </ul>"},{"location":"resources/python/project-packaging/","title":"Project packaging","text":"<ul> <li>Poetry</li> <li>Publish to PiP via Poetry</li> <li>Publish to PiP via Poetry v2</li> <li>Pooch: a friend to fetch your data files</li> <li>Robust Testing &amp; Packaging with <code>src</code> layout</li> <li>Python Packages: modern and efficient workflows for creating Python packages</li> </ul>"},{"location":"resources/python/regex/","title":"Regex","text":"<ul> <li>Regex made simple</li> <li>How to remember regex</li> <li>AutoRegex: from plain text to regex</li> </ul>"},{"location":"resources/python/scikit-learn/","title":"Scikit-learn","text":"<ul> <li>Pipelines with <code>sklearn</code></li> <li>Pipeline visualization</li> <li>Sklearn Pipelines for the Modern ML Engineer</li> <li>Pipeline for data preparation</li> </ul>"},{"location":"resources/python/scikit-learn/#extensions","title":"Extensions","text":"<ul> <li><code>combo</code> for ML models combination</li> <li><code>scikit-multilearn</code> for multi-label learning</li> <li><code>scikit-lego</code></li> <li><code>lazypredict</code></li> <li><code>human-learn</code> to rule-based learning and interactive drawing rules</li> </ul>"},{"location":"resources/python/scikit-learn/#probabl","title":"Probabl","text":"<ul> <li>Probabl open source gallery</li> </ul>"},{"location":"resources/python/stdlib/","title":"Standard library","text":"<ul> <li>Math module overview</li> <li>Boltons</li> <li>Priority queues and <code>heapq</code></li> </ul>"},{"location":"resources/python/streamlit/","title":"Streamlit","text":"<ul> <li>Coding ML tools like you code ML models</li> <li>Build and deploy <code>streamlit</code> applications</li> <li>Intermediate <code>streamlit</code></li> <li>Sharing <code>streamlit</code> securely</li> <li>Download file in <code>streamlit</code></li> <li><code>streamlit</code> inside JupyterHub</li> <li><code>streamlit</code> multi page hack</li> <li><code>streamlit</code> app to make apps</li> <li>Session state for multipage apps</li> <li>Drag scatter point with Bokeh events</li> <li><code>streamlit-heroku</code> deployment utils</li> <li>Display live 2D data in Streamlit</li> <li>Real time dashboard update with asyncio</li> <li>How to build a real time live dashboard</li> <li>Sync session state and app url via query params</li> <li>Table of contents in Streamlit</li> <li>Prettymaps Streamlit frontend</li> <li>Stlite: streamlit app running in browser</li> <li>Streamlit book</li> <li>Streamlit-Pydantic: auto-generate Streamlit UI elements from Pydantic models</li> <li>Package Streamlit into an Electron desktop app</li> <li>Prototyping Streamlit app via Figma and figma-to-streamlit plugin</li> <li>Streamlit type checking playground with mypy</li> <li>Creating repeatable elements</li> <li>Data analysis with Mito: a powerful spreadsheet in Streamlit</li> <li>Simplifying generative AI workflows</li> <li>Streamlit Contact Form Template</li> <li>Search grid for a Pandas DataFrame</li> </ul>"},{"location":"resources/python/streamlit/#components","title":"Components","text":"<ul> <li>Ant Design Menu and Tree</li> <li>Authenticator</li> <li>Barfi: a visual flow-based programming component</li> <li>Bokeh events</li> <li>Calendar</li> <li>Component for chat UI</li> <li>Datalist</li> <li>Drawable canvas</li> <li>Elements for Material UI tools integration</li> <li>Extras</li> <li>Extra components</li> <li>Image comparison</li> <li>Image cropper</li> <li>Image selection component</li> <li>Lottie animations with <code>streamlit-lottie</code></li> <li>Marquee banner</li> <li>Option men\u00f9</li> <li>Pyvista for 3D objects visualization</li> <li>Raw echarts</li> <li>RevealJS slides</li> <li>Shadcn-ui</li> <li>SHAP</li> <li>Sortables</li> <li>Star rating</li> <li>Text labeling and annotation tool</li> <li>Text rating component</li> <li>Timeline</li> <li>Toggle switch</li> <li>Tree-shaped nested selectbox component</li> <li>User feedback</li> <li>Vizzu</li> <li>Vertical slider</li> </ul>"},{"location":"resources/python/streamlit/#build-components","title":"Build components","text":"<ul> <li>End to end streamlit components tutorial</li> <li>How to create custom Streamlit components</li> <li>Introductive tutorial to Streamlit components</li> <li>Streamlit components tutorials</li> <li>Streamlit components video tutorial</li> <li>Streamlit tutorial app to build components</li> </ul>"},{"location":"resources/python/strings/","title":"Strings","text":"<ul> <li>Fuzzywuzzy</li> <li>Python strings</li> <li>Thefuzz</li> </ul>"},{"location":"resources/python/structural-pattern-matching/","title":"Structural Pattern Matching","text":"<ul> <li>PEP 636</li> </ul>"},{"location":"resources/python/tensorflow/","title":"Tensorflow","text":"<ul> <li>Tensorflow playground</li> <li>ML classifying text with NN and tensorflow</li> <li><code>einsum</code> for compact and efficient Einstein summation</li> </ul>"},{"location":"resources/python/testing/","title":"Testing","text":"<ul> <li><code>PyHamcrest</code>: a framework for writing matcher objects, allowing you to declaratively define match rules</li> <li><code>behave</code>: behavior-driven development based on Gherkin syntax</li> <li><code>hypothesis</code>: generates simple and comprehensible examples that make your tests fail</li> <li><code>mutmut</code>: a mutation testing system for Python, with a strong focus on ease of use</li> </ul>"},{"location":"resources/python/testing/#unit-tests","title":"Unit tests","text":"<ul> <li>Unit testing for DS</li> <li><code>pytest</code></li> <li><code>pytest</code> and travis for github CI</li> <li><code>nox</code></li> <li><code>locust</code> as a test framework in pure Python</li> <li>Assertions vs Exceptions</li> <li>Python Mocking in Production</li> </ul>"},{"location":"resources/python/utils/","title":"Misc utils","text":"<ul> <li>Barcodes, captcha and num2words</li> <li>Barcode generation with Python</li> <li>Modern high-performance serialization utilities for Python</li> <li><code>pysentation</code>: a CLI for displaying Python presentations</li> </ul>"},{"location":"resources/python/versions/","title":"Python versions","text":"<ul> <li>New features in Python 3.10</li> </ul>"},{"location":"resources/python/video-editing/","title":"Video editing","text":"<ul> <li>Moviepy</li> </ul>"},{"location":"resources/python/vocal-reader/","title":"Vocal reader","text":"<ul> <li>How to build an audiobook</li> <li>How to make your computer talk</li> </ul>"},{"location":"resources/python/web-framework/","title":"Web Framework","text":"<ul> <li>Deploying ML model as a REST API</li> <li>Denzel</li> <li>Dash development and deployment</li> <li>Deploy ML model with Flask and Heroku</li> <li>FastAPI</li> <li>Website to host Python web app</li> <li>Deploy Dash app to Heroku</li> <li>Build and deploy a ML web app</li> <li>Deploy <code>streamlit</code> on Heroku</li> <li>Anvil</li> <li>Pythonanywhere</li> <li>Deploy Dash app for free</li> <li><code>streamlit</code> deployment on Heroku</li> <li>Deploying <code>streamlit</code> on AWS Lightsail with nginx and docker</li> <li><code>gradio</code> as a lightweight alternative to Streamlit</li> <li>ML model deployment on iPhone</li> <li>Deploy PyCaret model via FastAPI</li> <li><code>PyWebIO</code> for web app development</li> <li>FastDash</li> <li>H2O Wave and its table component</li> <li>MLEM: package and deploy machine learning models</li> <li>10 Python web frameworks</li> <li>Reflex: performant, customizable web apps in pure Python</li> <li>Dara</li> <li>NiceGUI</li> <li>Vizro is a toolkit for creating modular data visualization applications</li> <li>Panel for data apps</li> </ul>"},{"location":"resources/python/web-scraping/","title":"Web scraping","text":"<ul> <li>Comparison between <code>BeatifulSoup</code>, <code>selenium</code> and <code>scrapy</code></li> <li>trafilatura: a Python package and command-line tool to gather text on the Web</li> <li>Helium: lighter web automation for Python</li> </ul>"},{"location":"resources/python/whatsapp/","title":"Whatsapp","text":"<ul> <li>Whatsapp via Python</li> <li>Whatsapp bot via Selenium</li> </ul>"},{"location":"resources/python/windows-client/","title":"Windows client","text":"<ul> <li>Windows toast notifications</li> <li>Gooey GUI</li> <li>Sound alarm when code finishes</li> <li>Desktop notifier app</li> <li>KnockKnock</li> </ul>"},{"location":"resources/snippets/","title":"Snippets","text":""},{"location":"resources/snippets/#jupyter","title":"Jupyter","text":""},{"location":"resources/snippets/#autoreload","title":"autoreload","text":"<pre><code>%load_ext autoreload\n%autoreload 2\n</code></pre>"},{"location":"resources/snippets/#profiling","title":"profiling","text":"<pre><code>%load_ext line_profiler\n\ndef function_to_profile(arg: int):\n    ...\n\n%lprun -f function_to_profile function_to_profile(1)\n</code></pre> <p>For reference see here and here.</p>"},{"location":"resources/snippets/#sklearn","title":"sklearn","text":""},{"location":"resources/snippets/#timeseriessplitmultistep","title":"<code>TimeSeriesSplitMultiStep</code>","text":"<pre><code>import numpy as np\nimport pandas as pd\nfrom sklearn import model_selection\n\n\ndef TimeSeriesSplitMultiStep(series: pd.DataFrame, \n                             n_splits: int = 3, \n                             n_steps: int = 3, \n                             max_train_size: Optional[int] = None) -&gt; tuple:\n    \"\"\"Extend sklearn' TimeSeriesSplit to the multistep case.\n\n    Args:\n        series (pd.DataFrame): input time series.\n        n_splits (optional, int): number of splits. Defaults to 3.\n        n_steps (optional, int): number of steps ahead. Defaults to 3.\n        max_train_size (optional, Optional[int]): maximum training set size. Defaults to None.\n\n    Returns:\n        Indices for splitting.\n    \"\"\"\n    tscv = model_selection.TimeSeriesSplit(n_splits, max_train_size)\n\n    for train_index, test_index in tscv.split(series):\n        last_test_index = test_index[-1]\n        step_to_add = n_steps - len(test_index)\n        if last_test_index &lt; len(series) - step_to_add:\n            if step_to_add &gt; 0:\n                for next_step in range(last_test_index + 1, step_to_add + last_test_index + 1):\n                    test_index = np.append(test_index, next_step)\n            yield train_index, test_index\n</code></pre>"},{"location":"resources/snippets/#stdlib","title":"stdlib","text":""},{"location":"resources/snippets/#clean_text","title":"<code>clean_text</code>","text":"<pre><code>from textwrap import dedent\n\n\ndef clean_text(x: str) -&gt; str:\n    \"\"\"Remove indentation and whitespaces.\n\n    Args:\n        x (str): (possibly multiline) text.\n\n    Returns:\n        Cleaned text.\n    \"\"\"\n    return dedent(x).strip()\n\nx = '''\n    Hi! I am\n    a multiline\n    text.\n    '''\n\nprint(x)\nprint(clean_text(x)) # cleaner\n</code></pre>"},{"location":"resources/snippets/#flatten","title":"<code>flatten</code>","text":"<pre><code>import numpy as np\nimport pandas as pd\n\n\ndef flatten(x: list | pd.Series | np.ndarray | tuple | map) -&gt; list:\n    \"\"\"Flatten nested input list.\n\n    Credits to [Samuele Fiorini](https://github.com/samuelefiorini).\n\n    Args:\n        x (list): nested list\n\n    Returns:\n        Flattened list.\n    \"\"\"\n    return (\n        [xi for l in x for xi in flatten(l)] if isinstance(x, (list, np.ndarray, tuple)) \n        else flatten(list(x)) if isinstance(x, (pd.Series, map))\n        else [x]\n    )\n\nx = [[1, 2, 3], 4, [5], [6, 7]]\nprint(flatten(x)) # [1, 2, 3, 4, 5, 6, 7]\n</code></pre>"},{"location":"resources/snippets/#groupby","title":"<code>groupby</code>","text":"<pre><code>from itertools import groupby\n\ndef _groupby(x: list) -&gt; list:\n    \"\"\"Groupby a list to remove consecutive duplicates while preserving ordering.\n\n    Inspired by https://stackoverflow.com/a/5738933/13790005.\n\n    Args:\n        x (list): input list.\n\n    Returns:\n        List with removed consecutive duplicates.\n    \"\"\"\n    return list(xi for xi, _ in groupby(x))\n\nx = [1, 2, 2, 3, 2]\nprint(_groupby(x)) # [1, 2, 3, 2]\n</code></pre>"},{"location":"resources/snippets/#make_deps_graph","title":"<code>make_deps_graph</code>","text":"<pre><code>import os\nimport subprocess\n\n\ndef make_deps_graph(*args, **kwargs) -&gt; None:\n    \"\"\"Make dependencies graphs via pydeps.\"\"\"\n\n    # Ensure outdir exists\n    outdir = ...\n    if not os.path.exists(outdir):\n        os.makedirs(outdir)\n\n    # Generate pydeps graph for the following paths\n    fnames = [...]\n\n    for fname in fnames:\n        subprocess.run(f\"pydeps {fname} --cluster --noshow -o {outdir}/{fname}.svg\", shell=True)\n</code></pre>"},{"location":"resources/snippets/#make_project_tree","title":"<code>make_project_tree</code>","text":"<pre><code>import sys\nfrom pathlib import Path\nfrom itertools import islice\n\n\ndef make_project_tree(\n    out_path: Path = './project_tree.md',\n    dir_path: Path = '.',\n    level: int = -1,\n    limit_to_directories: bool = False,\n    length_limit: int = 1000,\n    to_output = True,\n    **kwargs\n    ):\n    \"\"\"Save to out_path a visual tree representation of contents of a given Path object.\n\n    SEE: credits to https://stackoverflow.com/a/59109706/13790005 for tree implementation.\n\n    Args:\n        out_path (Path, optional): output path. Defaults to './project_tree.md'.\n        dir_path (Path, optional): path to traverse. Defaults to '.'.\n        level (int, optional): depth level to traverse. Defaults to -1.\n        limit_to_directories (bool, optional): whether to track only directories. Defaults to False.\n        length_limit (int, optional): limit of total elements retrievable. Defaults to 1000.\n        to_output (bool, optional): whether to save tree in a file. Defaults to True.\n    \"\"\"\n    space =  '    '\n    branch = '\u2502   '\n    tee =    '\u251c\u2500\u2500 '\n    last =   '\u2514\u2500\u2500 '\n\n    dir_path = Path(dir_path) # accept string coerceable to Path\n    files = 0\n    directories = 0\n    blacklist = [...] # fill with path to be excluded\n\n    def inner(\n        dir_path: Path,\n        prefix: str='',\n        level=-1\n        ) -&gt; str:\n        \"\"\"Traverse folder.\n\n        Args:\n            dir_path (Path): target folder.\n            prefix (str, optional): folder prefix to be added. Defaults to ''.\n            level (int, optional): maximum reachable depth. Defaults to -1.\n\n        Returns:\n            Folder contents.\n        \"\"\"\n        nonlocal files, directories\n        if not level:\n            return # 0, stop iterating\n        if limit_to_directories:\n            contents = [d for d in dir_path.iterdir() if d.is_dir()]\n        else:\n            contents = list(filter(lambda x: all(y not in str(x) for y in blacklist), dir_path.iterdir()))\n        pointers = [tee] * (len(contents) - 1) + [last]\n        for pointer, path in zip(pointers, contents):\n            if path.is_dir():\n                yield prefix + pointer + path.name\n                directories += 1\n                extension = branch if pointer == tee else space\n                yield from inner(path, prefix=prefix+extension, level=level-1)\n            elif not limit_to_directories:\n                yield prefix + pointer + path.name\n                files += 1\n\n    if to_output:\n        sys.stdout = open(out_path, \"w\", encoding='utf-8')\n        print(\"# Project tree\")\n        print('')\n        print(\"```\")\n    print(dir_path.name)\n    iterator = inner(dir_path, level=level)\n    for line in islice(iterator, length_limit):\n        print(line)\n    if next(iterator, None):\n        print(f'... length_limit, {length_limit}, reached, counted:')\n    print(f'\\n{directories} directories' + (f', {files} files' if files else ''))\n    if to_output:\n        print(\"```\")\n        sys.stdout.close()\n</code></pre>"},{"location":"resources/snippets/#mround","title":"<code>mround</code>","text":"<pre><code>def mround(x: float, m: int = 10) -&gt; int:\n    \"\"\"Round to nearest multiple of m.\n\n    Args:\n        x (float): Value to round\n        m (optional, int): desired multiple target. Defaults to 10.\n\n    Returns:\n        Rounded value.\n    \"\"\"\n    return round(x / m) * m\n\nx = 123.4\nprint(mround(x, m=10)) # 120\n</code></pre>"},{"location":"resources/snippets/#print","title":"<code>print</code>","text":"<p>This solution depends on <code>python-dotenv</code>, <code>loguru</code> and <code>icecream</code>: with the following setup in the root <code>__init__.py</code> of a given (managed) library, the standard <code>print</code> is overridden with a combo between a Loguru sink with DEBUG level and the useful features provided by IceCream.</p> <p>Warning</p> <p>This comes at a price: overriding the standard <code>print</code> actually breaks Jupyter debugging features in VSC, as stated in this issue.</p> init.py .env <pre><code>import os\nimport sys\n\nfrom dotenv import load_dotenv\nfrom loguru import logger\n\n__ = load_dotenv()\nlogger.remove()\nlogger.add(\n    sys.stdout,\n    level=os.environ.get('LOGURU_LEVEL', 'DEBUG')\n)\n\nFROM_LOCAL = os.environ.get('FROM_LOCAL', 'false') == 'true'\n\nif FROM_LOCAL:\n    from icecream import install, ic\n    ic.configureOutput(\n        prefix='',\n        outputFunction=lambda x: logger.debug(x),\n        includeContext=True\n        )\n    # SEE: this will add ic as 'print' between builtins,\n    # making it available everywhere - and purposely overriding \n    # standard print()!\n    install('print')\n</code></pre> <pre><code>FROM_LOCAL=true\n</code></pre> <p>The above setup also prevents from dangling <code>ic()</code> calls accidentally left into production code, without the need of verbose try-except.</p> Example <p>Let's define a test function:</p> <pre><code>def test(x: list) -&gt; str:\n    return ', '.join(map(str, x))\n</code></pre> <p>Before, with the standard <code>print</code>:</p> <pre><code>&gt;&gt;&gt; print(test([1, 2]))\n1, 2\n</code></pre> <p>After, with the new <code>print</code> obtained by importing anything from the library with the above <code>__init__.py</code>:</p> <pre><code>&gt;&gt;&gt; print(test([1, 2]))\n2022-10-19 10:20:28.588 | DEBUG | my_library:&lt;lambda&gt;:50 - my_script.py:1 - test([1, 2]): '1, 2'\n</code></pre>"},{"location":"resources/snippets/#timed","title":"<code>timed</code>","text":"<pre><code>import time\nfrom datetime import timedelta\nfrom functools import wraps\nfrom typing import Callable, Optional\n\nfrom loguru import logger\n\n\ndef timed(_func: Optional[Callable] = None, *, return_time: bool = False) -&gt; Callable:\n    \"\"\"Print the execution time for the decorated function.\n\n    Args:\n        _func (Optional[Callable], optional): function to decorate. Defaults to None.\n        return_time (bool, optional): if True, returns execution time before function. Defaults to False.\n    \"\"\"\n    def _timed(func):\n        @wraps(func)\n        def wrapper(*args, **kwargs):\n            start = time.time()\n            result = func(*args, **kwargs)\n            end = time.time()\n            logger.success(\n                f\"{func.__module__}.{func.__name__} took {str(timedelta(seconds=end - start)).split('.')[0]}.\")\n            if return_time:\n                return end - start, result\n            else:\n                return result\n        return wrapper\n    if _func is None:\n        return _timed\n    else:\n        return _timed(_func)\n</code></pre>"},{"location":"resources/snippets/#validate_type_annotations","title":"<code>validate_type_annotations</code>","text":"<pre><code>from functools import wraps\nfrom typing import Callable\n\nfrom loguru import logger\n\ndef validate_type_annotations(func: Callable) -&gt; Callable:\n    \"\"\"Validate type annotations of given function arguments enriching error messages.\n\n    Args:\n        func (Callable): function to decorate.\n    \"\"\"\n    @wraps(func)\n    def wrapper(*args, **kwargs):\n        func.__annotations__.pop('return', None)\n        func_types = [*func.__annotations__.values()]\n        input_types = list(map(lambda x: type(x), (*args, *kwargs)))\n        if func_types == input_types:\n            return func(*args, **kwargs)\n        else:\n            logger.error(\n                f\"Function `{func.__name__}` input types mismatch.\\n Annotated: {func.__annotations__}\\n Submitted: { dict(zip(func.__annotations__.keys(), input_types))}\\n\")\n            try:\n                return func(*args, **kwargs)\n            except Exception as e:\n                logger.exception(e.__class__.__name__)\n    return wrapper\n</code></pre>"},{"location":"resources/snippets/#streamlit","title":"streamlit","text":""},{"location":"resources/snippets/#aggrid","title":"<code>AgGrid</code>","text":""},{"location":"resources/snippets/#deferred-single-row-deletion","title":"Deferred single row deletion","text":"<p>Originally posted at discuss.streamlit.io.</p> <pre><code>import string\n\nimport numpy as np\nimport pandas as pd\nimport streamlit as st\nfrom st_aggrid import AgGrid, GridOptionsBuilder, GridUpdateMode\n\nst.set_page_config(layout='wide')\n\n\ndef display_table(df: pd.DataFrame) -&gt; AgGrid:\n    # Configure AgGrid options\n    gb = GridOptionsBuilder.from_dataframe(df)\n    gb.configure_selection('single')\n    st.write(f\"Dataframe shape: {df.shape}\")\n    return AgGrid(\n        df,\n        gridOptions=gb.build(),\n        # this override the default VALUE_CHANGED\n        update_mode=GridUpdateMode.MODEL_CHANGED\n    )\n\n\n## Define dummy data\nrng = np.random.default_rng(2021)\nN_SAMPLES = 100\nN_FEATURES = 10\ndf = pd.DataFrame(rng.integers(0, N_SAMPLES, size=(\n    N_SAMPLES, N_FEATURES)), columns=list(string.ascii_uppercase[:N_FEATURES]))\n\ncols = st.columns(2)\n\nwith cols[0]:\n\n    st.markdown('# \ud83e\udc14 Before')\n\n    # Display AgGrid from data and write response\n    st.markdown(\"### 1\ufe0f\u20e3 Let's display dummy data through AgGrid\")\n    response = display_table(df)\n\n    st.markdown(\n        \"### 2\ufe0f\u20e3 AgGrid response contains `data` (original df) and `selected_rows`\")\n    for k, v in response.items():\n        st.write(k, v)\n\nwith cols[1]:\n\n    st.markdown('# \ud83e\udc16 After')\n\n    # Retrieve selected rows indices\n    st.markdown(\n        \"### 3\ufe0f\u20e3 From selected rows we can obtain dataframe indices to drop\")\n    data = response['data'].to_dict(orient='records')\n    indices = [data.index(row) for row in response['selected_rows']]\n    st.write(f\"Selected rows are located at indices: {indices}\")\n\n    # Use retrieved indices to remove corresponding rows from dataframe\n    st.markdown(\n        \"### 4\ufe0f\u20e3 Display the updated dataframe where rows have been removed\")\n    _df = df.drop(indices, axis=0)\n    st.write(f\"Dataframe shape: {_df.shape}\")\n    AgGrid(_df)\n</code></pre>"},{"location":"resources/snippets/#realtime-single-row-deletion","title":"Realtime single row deletion","text":"<p>Originally posted at discuss.streamlit.io.</p> <pre><code>import string\n\nimport numpy as np\nimport pandas as pd\nimport streamlit as st\nfrom st_aggrid import AgGrid, GridOptionsBuilder, GridUpdateMode, JsCode\n\nst.set_page_config(layout='wide')\n\n\ndef display_table(df: pd.DataFrame) -&gt; AgGrid:\n    # Configure AgGrid options\n    gb = GridOptionsBuilder.from_dataframe(df)\n    gb.configure_selection('single', use_checkbox=True)\n\n    # Custom JS code for interactive rows deletion\n    # For credits SEE: \n    # https://github.com/PablocFonseca/streamlit-aggrid/blob/1acb526ba43b5aac9c8eb22cc54eeb05696cd84d/examples/example_highlight_change.py#L21\n    # https://ag-grid.zendesk.com/hc/en-us/articles/360020160932-Removing-selected-rows-or-cells-when-Backspace-or-Delete-is-pressed\n    js = JsCode(\"\"\"\n    function(e) {\n        let api = e.api;        \n        let sel = api.getSelectedRows();\n\n        api.applyTransaction({remove: sel});\n    };\n    \"\"\")\n    gb.configure_grid_options(onRowSelected=js) \n    return AgGrid(\n        df,\n        gridOptions=gb.build(),\n        # this override the default VALUE_CHANGED\n        update_mode=GridUpdateMode.MODEL_CHANGED,\n        # needed for js injection\n        allow_unsafe_jscode=True\n    )\n\n\n## Define dummy data\nrng = np.random.default_rng(2021)\nN_SAMPLES = 100\nN_FEATURES = 10\ndf = pd.DataFrame(rng.integers(0, N_SAMPLES, size=(\n    N_SAMPLES, N_FEATURES)), columns=list(string.ascii_uppercase[:N_FEATURES]))\n\nst.info(\"Select a row to remove it\")\nresponse = display_table(df)\nst.write(f\"Dataframe shape: {response['data'].shape}\")\n</code></pre>"},{"location":"resources/snippets/#deferred-multiple-rows-deletion","title":"Deferred multiple rows deletion","text":"<p>Originally posted at discuss.streamlit.io.</p> <pre><code>import string\n\nimport numpy as np\nimport pandas as pd\nimport streamlit as st\nfrom st_aggrid import AgGrid, GridOptionsBuilder, GridUpdateMode\n\nst.set_page_config(layout='wide')\n\ndef display_table(df: pd.DataFrame) -&gt; AgGrid:\n    # Configure AgGrid options\n    gb = GridOptionsBuilder.from_dataframe(df)\n    gb.configure_selection('multiple', use_checkbox=True) \n    return AgGrid(\n        df,\n        gridOptions=gb.build(),\n        # this override the default VALUE_CHANGED\n        update_mode=GridUpdateMode.MODEL_CHANGED\n    )\n\n\n## Define dummy data\nrng = np.random.default_rng(2021)\nN_SAMPLES = 100\nN_FEATURES = 10\ndf = pd.DataFrame(rng.integers(0, N_SAMPLES, size=(\n    N_SAMPLES, N_FEATURES)), columns=list(string.ascii_uppercase[:N_FEATURES]))\n\n## Display data and selected rows\nleft, right = st.columns(2)\nwith left:\n    st.info(\"Select rows to be deleted\")\n    response = display_table(df)\nwith right:\n    st.warning(\"Rows selected for deletion\")\n    rows_to_delete = pd.DataFrame(response['selected_rows'])\n    st.write(rows_to_delete)\n\n## Delete rows on button press\nif st.button(\"Delete rows\") and not rows_to_delete.empty:\n    # Lookup table is needed because AgGrid does not return rows indices\n    lookup = df.merge(rows_to_delete, on=list(df.columns), how='left', indicator=True)\n    _df = df.drop(lookup[lookup['_merge'] == 'both'].index)\n    st.success('Rows deleted')\n    st.write(_df)\n</code></pre>"},{"location":"resources/snippets/#folium_map","title":"<code>folium_map</code>","text":"<pre><code>import folium\nimport streamlit as st\nfrom streamlit_folium import folium_static\n\n\ndef folium_map(geomap: folium.Map, height: int = 800) -&gt; None:\n    \"\"\"Render a responsive Folium map via streamlit-folium component.\n\n    Args:\n        geomap (folium.Map): Geo map.\n        height (optional, int): map height. Defaults to 800.\n    \"\"\"\n    make_map_responsive = \"\"\"\n    &lt;style&gt;\n    [title~=\"st.iframe\"] { width: 100%}\n    &lt;/style&gt;\n    \"\"\"\n    st.markdown(make_map_responsive, unsafe_allow_html=True)\n    folium_static(geomap, height=height)\n</code></pre>"},{"location":"resources/snippets/#folium_dual_map","title":"<code>folium_dual_map</code>","text":"<pre><code>from folium import plugins\nimport streamlit as st\nimport streamlit.components.v1 as st_components\n\n\ndef folium_dual_map(dualmap: plugins.DualMap, height: int = 800) -&gt; None:\n    \"\"\"Render a responsive Folium DualMap via streamlit-folium component.\n\n    Args:\n        dualmap (plugins.DualMap): dual geo map.\n        height (optional, int): map height. Defaults to 800.\n    \"\"\"\n    make_map_responsive = \"\"\"\n    &lt;style&gt;\n    [title~=\"st.iframe\"] { width: 100%}\n    &lt;/style&gt;\n    \"\"\"\n    st.markdown(make_map_responsive, unsafe_allow_html=True)\n    st_components.html(\n        dualmap._repr_html_(),\n        height=height\n    )\n</code></pre>"},{"location":"resources/snippets/#grid-layout","title":"Grid layout","text":"<pre><code>from typing import Callable, ContextManager\nimport streamlit as st\n\ndef make_grid(n_rows: int, n_cols: int) -&gt; Callable:\n    \"\"\"Build a grid context manager.\n\n    Inspired from https://towardsdatascience.com/how-to-create-a-grid-layout-in-streamlit-7aff16b94508.\n\n    Args:\n        n_rows (int): number of rows.\n        n_cols (int): number of cols.\n\n    Returns:\n        Callable context manager.\n    \"\"\"\n    grid = [st.columns(n_rows) for _ in range(n_cols)]\n    def _grid(i: int, j: int) -&gt; ContextManager:\n        return grid[i][j]\n    return _grid\n\ngrid = make_grid(2, 2)\n\nfor i in range(2):\n    for j in range(2):\n        with grid(i, j):\n            st.markdown(f'# Hello from ({i}, {j})')\n</code></pre>"},{"location":"resources/snippets/#injecting-javascript","title":"Injecting <code>javascript</code>","text":"<pre><code>import streamlit.components.v1 as components\n\n## SEE: \n## - https://github.com/streamlit/streamlit/issues/1291#issuecomment-1022408379\n## - https://discuss.streamlit.io/t/injecting-js/22651\n## - https://www.w3schools.com/jsref/event_onclick.asp\ncomponents.html('''\n    &lt;h3 id=\"demo\" onclick=\"myFunction()\"&gt;Click me to change my color.&lt;/h3&gt;\n\n    &lt;script&gt;\n    function myFunction() {\n        let color = document.getElementById(\"demo\").style.color;\n        if (color != \"red\") {\n            document.getElementById(\"demo\").style.color = \"red\";\n            }\n        else {\n            document.getElementById(\"demo\").style.color = \"black\";\n            }\n    }\n    &lt;/script&gt;\n    '''\n) \n</code></pre>"},{"location":"resources/snippets/#loguru_to_streamlit","title":"<code>loguru_to_streamlit</code>","text":"<pre><code>import streamlit as st\nfrom loguru import logger\n\n\ndef redirect_loguru_to_streamlit() -&gt; None:\n    \"\"\"Redirect Loguru logs to Streamlit.\"\"\"\n    def _filter_warning(record):\n        return record[\"level\"].no == logger.level(\"WARNING\").no    \n    if 'warning_logger' not in st.session_state:\n        st.session_state['warning_logger'] = logger.add(st.warning, \n                                                        filter=_filter_warning, \n                                                        level='INFO')\n    if 'error_logger' not in st.session_state:\n        st.session_state['error_logger'] = logger.add(st.error, level='ERROR')\n</code></pre>"},{"location":"resources/snippets/jupyter/","title":"Jupyter","text":""},{"location":"resources/snippets/jupyter/#autoreload","title":"autoreload","text":"<pre><code>%load_ext autoreload\n%autoreload 2\n</code></pre>"},{"location":"resources/snippets/jupyter/#profiling","title":"profiling","text":"<pre><code>%load_ext line_profiler\n\ndef function_to_profile(arg: int):\n    ...\n\n%lprun -f function_to_profile function_to_profile(1)\n</code></pre> <p>For reference see here and here.</p>"},{"location":"resources/snippets/sklearn/","title":"sklearn","text":""},{"location":"resources/snippets/sklearn/#timeseriessplitmultistep","title":"<code>TimeSeriesSplitMultiStep</code>","text":"<pre><code>import numpy as np\nimport pandas as pd\nfrom sklearn import model_selection\n\n\ndef TimeSeriesSplitMultiStep(series: pd.DataFrame, \n                             n_splits: int = 3, \n                             n_steps: int = 3, \n                             max_train_size: Optional[int] = None) -&gt; tuple:\n    \"\"\"Extend sklearn' TimeSeriesSplit to the multistep case.\n\n    Args:\n        series (pd.DataFrame): input time series.\n        n_splits (optional, int): number of splits. Defaults to 3.\n        n_steps (optional, int): number of steps ahead. Defaults to 3.\n        max_train_size (optional, Optional[int]): maximum training set size. Defaults to None.\n\n    Returns:\n        Indices for splitting.\n    \"\"\"\n    tscv = model_selection.TimeSeriesSplit(n_splits, max_train_size)\n\n    for train_index, test_index in tscv.split(series):\n        last_test_index = test_index[-1]\n        step_to_add = n_steps - len(test_index)\n        if last_test_index &lt; len(series) - step_to_add:\n            if step_to_add &gt; 0:\n                for next_step in range(last_test_index + 1, step_to_add + last_test_index + 1):\n                    test_index = np.append(test_index, next_step)\n            yield train_index, test_index\n</code></pre>"},{"location":"resources/snippets/stdlib/","title":"stdlib","text":""},{"location":"resources/snippets/stdlib/#clean_text","title":"<code>clean_text</code>","text":"<pre><code>from textwrap import dedent\n\n\ndef clean_text(x: str) -&gt; str:\n    \"\"\"Remove indentation and whitespaces.\n\n    Args:\n        x (str): (possibly multiline) text.\n\n    Returns:\n        Cleaned text.\n    \"\"\"\n    return dedent(x).strip()\n\nx = '''\n    Hi! I am\n    a multiline\n    text.\n    '''\n\nprint(x)\nprint(clean_text(x)) # cleaner\n</code></pre>"},{"location":"resources/snippets/stdlib/#flatten","title":"<code>flatten</code>","text":"<pre><code>import numpy as np\nimport pandas as pd\n\n\ndef flatten(x: list | pd.Series | np.ndarray | tuple | map) -&gt; list:\n    \"\"\"Flatten nested input list.\n\n    Credits to [Samuele Fiorini](https://github.com/samuelefiorini).\n\n    Args:\n        x (list): nested list\n\n    Returns:\n        Flattened list.\n    \"\"\"\n    return (\n        [xi for l in x for xi in flatten(l)] if isinstance(x, (list, np.ndarray, tuple)) \n        else flatten(list(x)) if isinstance(x, (pd.Series, map))\n        else [x]\n    )\n\nx = [[1, 2, 3], 4, [5], [6, 7]]\nprint(flatten(x)) # [1, 2, 3, 4, 5, 6, 7]\n</code></pre>"},{"location":"resources/snippets/stdlib/#groupby","title":"<code>groupby</code>","text":"<pre><code>from itertools import groupby\n\ndef _groupby(x: list) -&gt; list:\n    \"\"\"Groupby a list to remove consecutive duplicates while preserving ordering.\n\n    Inspired by https://stackoverflow.com/a/5738933/13790005.\n\n    Args:\n        x (list): input list.\n\n    Returns:\n        List with removed consecutive duplicates.\n    \"\"\"\n    return list(xi for xi, _ in groupby(x))\n\nx = [1, 2, 2, 3, 2]\nprint(_groupby(x)) # [1, 2, 3, 2]\n</code></pre>"},{"location":"resources/snippets/stdlib/#make_deps_graph","title":"<code>make_deps_graph</code>","text":"<pre><code>import os\nimport subprocess\n\n\ndef make_deps_graph(*args, **kwargs) -&gt; None:\n    \"\"\"Make dependencies graphs via pydeps.\"\"\"\n\n    # Ensure outdir exists\n    outdir = ...\n    if not os.path.exists(outdir):\n        os.makedirs(outdir)\n\n    # Generate pydeps graph for the following paths\n    fnames = [...]\n\n    for fname in fnames:\n        subprocess.run(f\"pydeps {fname} --cluster --noshow -o {outdir}/{fname}.svg\", shell=True)\n</code></pre>"},{"location":"resources/snippets/stdlib/#make_project_tree","title":"<code>make_project_tree</code>","text":"<pre><code>import sys\nfrom pathlib import Path\nfrom itertools import islice\n\n\ndef make_project_tree(\n    out_path: Path = './project_tree.md',\n    dir_path: Path = '.',\n    level: int = -1,\n    limit_to_directories: bool = False,\n    length_limit: int = 1000,\n    to_output = True,\n    **kwargs\n    ):\n    \"\"\"Save to out_path a visual tree representation of contents of a given Path object.\n\n    SEE: credits to https://stackoverflow.com/a/59109706/13790005 for tree implementation.\n\n    Args:\n        out_path (Path, optional): output path. Defaults to './project_tree.md'.\n        dir_path (Path, optional): path to traverse. Defaults to '.'.\n        level (int, optional): depth level to traverse. Defaults to -1.\n        limit_to_directories (bool, optional): whether to track only directories. Defaults to False.\n        length_limit (int, optional): limit of total elements retrievable. Defaults to 1000.\n        to_output (bool, optional): whether to save tree in a file. Defaults to True.\n    \"\"\"\n    space =  '    '\n    branch = '\u2502   '\n    tee =    '\u251c\u2500\u2500 '\n    last =   '\u2514\u2500\u2500 '\n\n    dir_path = Path(dir_path) # accept string coerceable to Path\n    files = 0\n    directories = 0\n    blacklist = [...] # fill with path to be excluded\n\n    def inner(\n        dir_path: Path,\n        prefix: str='',\n        level=-1\n        ) -&gt; str:\n        \"\"\"Traverse folder.\n\n        Args:\n            dir_path (Path): target folder.\n            prefix (str, optional): folder prefix to be added. Defaults to ''.\n            level (int, optional): maximum reachable depth. Defaults to -1.\n\n        Returns:\n            Folder contents.\n        \"\"\"\n        nonlocal files, directories\n        if not level:\n            return # 0, stop iterating\n        if limit_to_directories:\n            contents = [d for d in dir_path.iterdir() if d.is_dir()]\n        else:\n            contents = list(filter(lambda x: all(y not in str(x) for y in blacklist), dir_path.iterdir()))\n        pointers = [tee] * (len(contents) - 1) + [last]\n        for pointer, path in zip(pointers, contents):\n            if path.is_dir():\n                yield prefix + pointer + path.name\n                directories += 1\n                extension = branch if pointer == tee else space\n                yield from inner(path, prefix=prefix+extension, level=level-1)\n            elif not limit_to_directories:\n                yield prefix + pointer + path.name\n                files += 1\n\n    if to_output:\n        sys.stdout = open(out_path, \"w\", encoding='utf-8')\n        print(\"# Project tree\")\n        print('')\n        print(\"```\")\n    print(dir_path.name)\n    iterator = inner(dir_path, level=level)\n    for line in islice(iterator, length_limit):\n        print(line)\n    if next(iterator, None):\n        print(f'... length_limit, {length_limit}, reached, counted:')\n    print(f'\\n{directories} directories' + (f', {files} files' if files else ''))\n    if to_output:\n        print(\"```\")\n        sys.stdout.close()\n</code></pre>"},{"location":"resources/snippets/stdlib/#mround","title":"<code>mround</code>","text":"<pre><code>def mround(x: float, m: int = 10) -&gt; int:\n    \"\"\"Round to nearest multiple of m.\n\n    Args:\n        x (float): Value to round\n        m (optional, int): desired multiple target. Defaults to 10.\n\n    Returns:\n        Rounded value.\n    \"\"\"\n    return round(x / m) * m\n\nx = 123.4\nprint(mround(x, m=10)) # 120\n</code></pre>"},{"location":"resources/snippets/stdlib/#print","title":"<code>print</code>","text":"<p>This solution depends on <code>python-dotenv</code>, <code>loguru</code> and <code>icecream</code>: with the following setup in the root <code>__init__.py</code> of a given (managed) library, the standard <code>print</code> is overridden with a combo between a Loguru sink with DEBUG level and the useful features provided by IceCream.</p> <p>Warning</p> <p>This comes at a price: overriding the standard <code>print</code> actually breaks Jupyter debugging features in VSC, as stated in this issue.</p> init.py .env <pre><code>import os\nimport sys\n\nfrom dotenv import load_dotenv\nfrom loguru import logger\n\n__ = load_dotenv()\nlogger.remove()\nlogger.add(\n    sys.stdout,\n    level=os.environ.get('LOGURU_LEVEL', 'DEBUG')\n)\n\nFROM_LOCAL = os.environ.get('FROM_LOCAL', 'false') == 'true'\n\nif FROM_LOCAL:\n    from icecream import install, ic\n    ic.configureOutput(\n        prefix='',\n        outputFunction=lambda x: logger.debug(x),\n        includeContext=True\n        )\n    # SEE: this will add ic as 'print' between builtins,\n    # making it available everywhere - and purposely overriding \n    # standard print()!\n    install('print')\n</code></pre> <pre><code>FROM_LOCAL=true\n</code></pre> <p>The above setup also prevents from dangling <code>ic()</code> calls accidentally left into production code, without the need of verbose try-except.</p> Example <p>Let's define a test function:</p> <pre><code>def test(x: list) -&gt; str:\n    return ', '.join(map(str, x))\n</code></pre> <p>Before, with the standard <code>print</code>:</p> <pre><code>&gt;&gt;&gt; print(test([1, 2]))\n1, 2\n</code></pre> <p>After, with the new <code>print</code> obtained by importing anything from the library with the above <code>__init__.py</code>:</p> <pre><code>&gt;&gt;&gt; print(test([1, 2]))\n2022-10-19 10:20:28.588 | DEBUG | my_library:&lt;lambda&gt;:50 - my_script.py:1 - test([1, 2]): '1, 2'\n</code></pre>"},{"location":"resources/snippets/stdlib/#timed","title":"<code>timed</code>","text":"<pre><code>import time\nfrom datetime import timedelta\nfrom functools import wraps\nfrom typing import Callable, Optional\n\nfrom loguru import logger\n\n\ndef timed(_func: Optional[Callable] = None, *, return_time: bool = False) -&gt; Callable:\n    \"\"\"Print the execution time for the decorated function.\n\n    Args:\n        _func (Optional[Callable], optional): function to decorate. Defaults to None.\n        return_time (bool, optional): if True, returns execution time before function. Defaults to False.\n    \"\"\"\n    def _timed(func):\n        @wraps(func)\n        def wrapper(*args, **kwargs):\n            start = time.time()\n            result = func(*args, **kwargs)\n            end = time.time()\n            logger.success(\n                f\"{func.__module__}.{func.__name__} took {str(timedelta(seconds=end - start)).split('.')[0]}.\")\n            if return_time:\n                return end - start, result\n            else:\n                return result\n        return wrapper\n    if _func is None:\n        return _timed\n    else:\n        return _timed(_func)\n</code></pre>"},{"location":"resources/snippets/stdlib/#validate_type_annotations","title":"<code>validate_type_annotations</code>","text":"<pre><code>from functools import wraps\nfrom typing import Callable\n\nfrom loguru import logger\n\ndef validate_type_annotations(func: Callable) -&gt; Callable:\n    \"\"\"Validate type annotations of given function arguments enriching error messages.\n\n    Args:\n        func (Callable): function to decorate.\n    \"\"\"\n    @wraps(func)\n    def wrapper(*args, **kwargs):\n        func.__annotations__.pop('return', None)\n        func_types = [*func.__annotations__.values()]\n        input_types = list(map(lambda x: type(x), (*args, *kwargs)))\n        if func_types == input_types:\n            return func(*args, **kwargs)\n        else:\n            logger.error(\n                f\"Function `{func.__name__}` input types mismatch.\\n Annotated: {func.__annotations__}\\n Submitted: { dict(zip(func.__annotations__.keys(), input_types))}\\n\")\n            try:\n                return func(*args, **kwargs)\n            except Exception as e:\n                logger.exception(e.__class__.__name__)\n    return wrapper\n</code></pre>"},{"location":"resources/snippets/streamlit/","title":"streamlit","text":""},{"location":"resources/snippets/streamlit/#aggrid","title":"<code>AgGrid</code>","text":""},{"location":"resources/snippets/streamlit/#deferred-single-row-deletion","title":"Deferred single row deletion","text":"<p>Originally posted at discuss.streamlit.io.</p> <pre><code>import string\n\nimport numpy as np\nimport pandas as pd\nimport streamlit as st\nfrom st_aggrid import AgGrid, GridOptionsBuilder, GridUpdateMode\n\nst.set_page_config(layout='wide')\n\n\ndef display_table(df: pd.DataFrame) -&gt; AgGrid:\n    # Configure AgGrid options\n    gb = GridOptionsBuilder.from_dataframe(df)\n    gb.configure_selection('single')\n    st.write(f\"Dataframe shape: {df.shape}\")\n    return AgGrid(\n        df,\n        gridOptions=gb.build(),\n        # this override the default VALUE_CHANGED\n        update_mode=GridUpdateMode.MODEL_CHANGED\n    )\n\n\n# Define dummy data\nrng = np.random.default_rng(2021)\nN_SAMPLES = 100\nN_FEATURES = 10\ndf = pd.DataFrame(rng.integers(0, N_SAMPLES, size=(\n    N_SAMPLES, N_FEATURES)), columns=list(string.ascii_uppercase[:N_FEATURES]))\n\ncols = st.columns(2)\n\nwith cols[0]:\n\n    st.markdown('# \ud83e\udc14 Before')\n\n    # Display AgGrid from data and write response\n    st.markdown(\"### 1\ufe0f\u20e3 Let's display dummy data through AgGrid\")\n    response = display_table(df)\n\n    st.markdown(\n        \"### 2\ufe0f\u20e3 AgGrid response contains `data` (original df) and `selected_rows`\")\n    for k, v in response.items():\n        st.write(k, v)\n\nwith cols[1]:\n\n    st.markdown('# \ud83e\udc16 After')\n\n    # Retrieve selected rows indices\n    st.markdown(\n        \"### 3\ufe0f\u20e3 From selected rows we can obtain dataframe indices to drop\")\n    data = response['data'].to_dict(orient='records')\n    indices = [data.index(row) for row in response['selected_rows']]\n    st.write(f\"Selected rows are located at indices: {indices}\")\n\n    # Use retrieved indices to remove corresponding rows from dataframe\n    st.markdown(\n        \"### 4\ufe0f\u20e3 Display the updated dataframe where rows have been removed\")\n    _df = df.drop(indices, axis=0)\n    st.write(f\"Dataframe shape: {_df.shape}\")\n    AgGrid(_df)\n</code></pre>"},{"location":"resources/snippets/streamlit/#realtime-single-row-deletion","title":"Realtime single row deletion","text":"<p>Originally posted at discuss.streamlit.io.</p> <pre><code>import string\n\nimport numpy as np\nimport pandas as pd\nimport streamlit as st\nfrom st_aggrid import AgGrid, GridOptionsBuilder, GridUpdateMode, JsCode\n\nst.set_page_config(layout='wide')\n\n\ndef display_table(df: pd.DataFrame) -&gt; AgGrid:\n    # Configure AgGrid options\n    gb = GridOptionsBuilder.from_dataframe(df)\n    gb.configure_selection('single', use_checkbox=True)\n\n    # Custom JS code for interactive rows deletion\n    # For credits SEE: \n    # https://github.com/PablocFonseca/streamlit-aggrid/blob/1acb526ba43b5aac9c8eb22cc54eeb05696cd84d/examples/example_highlight_change.py#L21\n    # https://ag-grid.zendesk.com/hc/en-us/articles/360020160932-Removing-selected-rows-or-cells-when-Backspace-or-Delete-is-pressed\n    js = JsCode(\"\"\"\n    function(e) {\n        let api = e.api;        \n        let sel = api.getSelectedRows();\n\n        api.applyTransaction({remove: sel});\n    };\n    \"\"\")\n    gb.configure_grid_options(onRowSelected=js) \n    return AgGrid(\n        df,\n        gridOptions=gb.build(),\n        # this override the default VALUE_CHANGED\n        update_mode=GridUpdateMode.MODEL_CHANGED,\n        # needed for js injection\n        allow_unsafe_jscode=True\n    )\n\n\n# Define dummy data\nrng = np.random.default_rng(2021)\nN_SAMPLES = 100\nN_FEATURES = 10\ndf = pd.DataFrame(rng.integers(0, N_SAMPLES, size=(\n    N_SAMPLES, N_FEATURES)), columns=list(string.ascii_uppercase[:N_FEATURES]))\n\nst.info(\"Select a row to remove it\")\nresponse = display_table(df)\nst.write(f\"Dataframe shape: {response['data'].shape}\")\n</code></pre>"},{"location":"resources/snippets/streamlit/#deferred-multiple-rows-deletion","title":"Deferred multiple rows deletion","text":"<p>Originally posted at discuss.streamlit.io.</p> <pre><code>import string\n\nimport numpy as np\nimport pandas as pd\nimport streamlit as st\nfrom st_aggrid import AgGrid, GridOptionsBuilder, GridUpdateMode\n\nst.set_page_config(layout='wide')\n\ndef display_table(df: pd.DataFrame) -&gt; AgGrid:\n    # Configure AgGrid options\n    gb = GridOptionsBuilder.from_dataframe(df)\n    gb.configure_selection('multiple', use_checkbox=True) \n    return AgGrid(\n        df,\n        gridOptions=gb.build(),\n        # this override the default VALUE_CHANGED\n        update_mode=GridUpdateMode.MODEL_CHANGED\n    )\n\n\n# Define dummy data\nrng = np.random.default_rng(2021)\nN_SAMPLES = 100\nN_FEATURES = 10\ndf = pd.DataFrame(rng.integers(0, N_SAMPLES, size=(\n    N_SAMPLES, N_FEATURES)), columns=list(string.ascii_uppercase[:N_FEATURES]))\n\n# Display data and selected rows\nleft, right = st.columns(2)\nwith left:\n    st.info(\"Select rows to be deleted\")\n    response = display_table(df)\nwith right:\n    st.warning(\"Rows selected for deletion\")\n    rows_to_delete = pd.DataFrame(response['selected_rows'])\n    st.write(rows_to_delete)\n\n# Delete rows on button press\nif st.button(\"Delete rows\") and not rows_to_delete.empty:\n    # Lookup table is needed because AgGrid does not return rows indices\n    lookup = df.merge(rows_to_delete, on=list(df.columns), how='left', indicator=True)\n    _df = df.drop(lookup[lookup['_merge'] == 'both'].index)\n    st.success('Rows deleted')\n    st.write(_df)\n</code></pre>"},{"location":"resources/snippets/streamlit/#folium_map","title":"<code>folium_map</code>","text":"<pre><code>import folium\nimport streamlit as st\nfrom streamlit_folium import folium_static\n\n\ndef folium_map(geomap: folium.Map, height: int = 800) -&gt; None:\n    \"\"\"Render a responsive Folium map via streamlit-folium component.\n\n    Args:\n        geomap (folium.Map): Geo map.\n        height (optional, int): map height. Defaults to 800.\n    \"\"\"\n    make_map_responsive = \"\"\"\n    &lt;style&gt;\n    [title~=\"st.iframe\"] { width: 100%}\n    &lt;/style&gt;\n    \"\"\"\n    st.markdown(make_map_responsive, unsafe_allow_html=True)\n    folium_static(geomap, height=height)\n</code></pre>"},{"location":"resources/snippets/streamlit/#folium_dual_map","title":"<code>folium_dual_map</code>","text":"<pre><code>from folium import plugins\nimport streamlit as st\nimport streamlit.components.v1 as st_components\n\n\ndef folium_dual_map(dualmap: plugins.DualMap, height: int = 800) -&gt; None:\n    \"\"\"Render a responsive Folium DualMap via streamlit-folium component.\n\n    Args:\n        dualmap (plugins.DualMap): dual geo map.\n        height (optional, int): map height. Defaults to 800.\n    \"\"\"\n    make_map_responsive = \"\"\"\n    &lt;style&gt;\n    [title~=\"st.iframe\"] { width: 100%}\n    &lt;/style&gt;\n    \"\"\"\n    st.markdown(make_map_responsive, unsafe_allow_html=True)\n    st_components.html(\n        dualmap._repr_html_(),\n        height=height\n    )\n</code></pre>"},{"location":"resources/snippets/streamlit/#grid-layout","title":"Grid layout","text":"<pre><code>from typing import Callable, ContextManager\nimport streamlit as st\n\ndef make_grid(n_rows: int, n_cols: int) -&gt; Callable:\n    \"\"\"Build a grid context manager.\n\n    Inspired from https://towardsdatascience.com/how-to-create-a-grid-layout-in-streamlit-7aff16b94508.\n\n    Args:\n        n_rows (int): number of rows.\n        n_cols (int): number of cols.\n\n    Returns:\n        Callable context manager.\n    \"\"\"\n    grid = [st.columns(n_rows) for _ in range(n_cols)]\n    def _grid(i: int, j: int) -&gt; ContextManager:\n        return grid[i][j]\n    return _grid\n\ngrid = make_grid(2, 2)\n\nfor i in range(2):\n    for j in range(2):\n        with grid(i, j):\n            st.markdown(f'# Hello from ({i}, {j})')\n</code></pre>"},{"location":"resources/snippets/streamlit/#injecting-javascript","title":"Injecting <code>javascript</code>","text":"<pre><code>import streamlit.components.v1 as components\n\n# SEE: \n# - https://github.com/streamlit/streamlit/issues/1291#issuecomment-1022408379\n# - https://discuss.streamlit.io/t/injecting-js/22651\n# - https://www.w3schools.com/jsref/event_onclick.asp\ncomponents.html('''\n    &lt;h3 id=\"demo\" onclick=\"myFunction()\"&gt;Click me to change my color.&lt;/h3&gt;\n\n    &lt;script&gt;\n    function myFunction() {\n        let color = document.getElementById(\"demo\").style.color;\n        if (color != \"red\") {\n            document.getElementById(\"demo\").style.color = \"red\";\n            }\n        else {\n            document.getElementById(\"demo\").style.color = \"black\";\n            }\n    }\n    &lt;/script&gt;\n    '''\n) \n</code></pre>"},{"location":"resources/snippets/streamlit/#loguru_to_streamlit","title":"<code>loguru_to_streamlit</code>","text":"<pre><code>import streamlit as st\nfrom loguru import logger\n\n\ndef redirect_loguru_to_streamlit() -&gt; None:\n    \"\"\"Redirect Loguru logs to Streamlit.\"\"\"\n    def _filter_warning(record):\n        return record[\"level\"].no == logger.level(\"WARNING\").no    \n    if 'warning_logger' not in st.session_state:\n        st.session_state['warning_logger'] = logger.add(st.warning, \n                                                        filter=_filter_warning, \n                                                        level='INFO')\n    if 'error_logger' not in st.session_state:\n        st.session_state['error_logger'] = logger.add(st.error, level='ERROR')\n</code></pre>"},{"location":"resources/tools/","title":"Tools","text":""},{"location":"resources/tools/#cmder","title":"cmder","text":"<ul> <li>FAQs</li> <li>cmder wiki</li> </ul>"},{"location":"resources/tools/#cli","title":"CLI","text":"<ul> <li>CLI cheatsheet</li> </ul>"},{"location":"resources/tools/#code-freezing","title":"Code freezing","text":"<ul> <li>Nativefier</li> </ul>"},{"location":"resources/tools/#coding","title":"Coding","text":"<ul> <li>Functional programming in DS projects</li> <li>Carbon for code snapshots</li> </ul>"},{"location":"resources/tools/#cron","title":"Cron","text":"<ul> <li>Crontab Guru</li> <li>Croniter</li> <li>Cronrange</li> </ul>"},{"location":"resources/tools/#docker","title":"Docker","text":"<ul> <li>Git submodules to install custom Python package in Docker image</li> <li>Why use Docker containers for ML development</li> <li>Fast Docker builds with caching</li> <li>Docker best practices for Python developers</li> <li>Multi-stage Docker builds to reduce image size</li> </ul>"},{"location":"resources/tools/#drawio","title":"Draw.io","text":"<ul> <li>Draw.io</li> </ul>"},{"location":"resources/tools/#git-and-versioning","title":"Git and versioning","text":"<ul> <li>A primer on version control</li> <li>Github for DS</li> <li>Pre commit</li> <li>Update data sources in Python</li> <li>Version control with Git</li> <li>Branching and merging</li> <li>Git commands</li> <li>Plugins for DS</li> <li>Github API for Python</li> <li>Branching in Git</li> <li>Github star history</li> <li>Intro to Git for DS</li> <li>Automating workflows with pre-commit hooks</li> <li>Daily git scenarios for DS</li> <li>Git web editor and repo diagram</li> <li>Gource a git history visualizer</li> <li>Branching workflows for Git</li> <li>Pre-commit hook for code formatting</li> <li>Use Git tactically</li> <li>Git cheatsheet by GitHub</li> <li>Gitpod: spin up automated dev environments</li> <li>Git and GitHub illustrations</li> <li> <p>Git scraping: track changes over time by scraping to a Git repository</p> <p>The internet is full of interesting data that changes over time. These changes can sometimes be more interesting than the underlying static data.</p> </li> <li> <p>git-story: tell the story of a Git project by creating video animations</p> </li> <li>git effort: show effort statistics on file</li> </ul>"},{"location":"resources/tools/#github","title":"Github","text":"<ul> <li>20 repositories for developers</li> </ul>"},{"location":"resources/tools/#google","title":"Google","text":"<ul> <li>Advanced Google search</li> </ul>"},{"location":"resources/tools/#graphics","title":"Graphics","text":"<ul> <li>Open source vector graphics editor</li> </ul>"},{"location":"resources/tools/#graphql","title":"GraphQL","text":"<ul> <li>GraphQL</li> </ul>"},{"location":"resources/tools/#html","title":"HTML","text":"<ul> <li>PyScript</li> </ul>"},{"location":"resources/tools/#impressjs","title":"impress.js","text":"<ul> <li>impress.js and Slides, Prezi-inspired</li> </ul>"},{"location":"resources/tools/#json","title":"JSON","text":"<ul> <li>JSON Visio editor</li> </ul>"},{"location":"resources/tools/#markdown","title":"Markdown","text":"<ul> <li>Stackedit</li> <li>Markdown email in PBP</li> <li>Mermaid for markdown diagram</li> <li>Markdown books with mdBook</li> </ul>"},{"location":"resources/tools/#misc","title":"Misc","text":"<ul> <li>Data Science toolset starter kit</li> </ul>"},{"location":"resources/tools/#performance-monitoring","title":"Performance monitoring","text":"<ul> <li>Netdata</li> </ul>"},{"location":"resources/tools/#project-management","title":"Project Management","text":"<ul> <li>Optimize a to-do list with Monte Carlo simulations</li> <li>Estimating tasks with statistics and simulations</li> </ul>"},{"location":"resources/tools/#quarto","title":"Quarto","text":"<ul> <li>Quarto docs</li> </ul>"},{"location":"resources/tools/#revealjs","title":"reveal.js","text":"<ul> <li>reveal.js and Slides</li> </ul>"},{"location":"resources/tools/#slack","title":"Slack","text":"<ul> <li>Python and Slack</li> </ul>"},{"location":"resources/tools/#software-development","title":"Software Development","text":"<ul> <li>SOLID principle</li> <li>Software quality attributes</li> </ul>"},{"location":"resources/tools/#terminal","title":"Terminal","text":"<ul> <li>Upgrade terminal experience</li> <li>Cool terminal customization</li> <li>Rich</li> <li>How to use <code>rich</code> features</li> <li>Quokka.js</li> </ul>"},{"location":"resources/tools/#visual-studio-code","title":"Visual Studio Code","text":"<ul> <li>VSC extensions for DS</li> <li>Sonarlint</li> <li>Kite</li> <li>Code cognitive complexity</li> <li>Python rules for cognitive complexity</li> <li>Intellicode</li> <li>Advanced VSC for Python developers</li> </ul>"},{"location":"resources/tools/#wsl","title":"WSL","text":"<ul> <li>Difference between WSL1 and WSL2</li> <li>WSL on PBP</li> </ul>"},{"location":"resources/tools/#yaml","title":"YAML","text":"<ul> <li>YAML vs JSON</li> <li>YAML vs JSON 2</li> <li>Strict YAML</li> </ul>"},{"location":"resources/tools/cmder/","title":"cmder","text":"<ul> <li>FAQs</li> <li>cmder wiki</li> </ul>"},{"location":"resources/tools/cmder/#cli","title":"CLI","text":"<ul> <li>CLI cheatsheet</li> </ul>"},{"location":"resources/tools/code-freezing/","title":"Code freezing","text":"<ul> <li>Nativefier</li> </ul>"},{"location":"resources/tools/coding/","title":"Coding","text":"<ul> <li>Functional programming in DS projects</li> <li>Carbon for code snapshots</li> </ul>"},{"location":"resources/tools/cron/","title":"Cron","text":"<ul> <li>Crontab Guru</li> <li>Croniter</li> <li>Cronrange</li> </ul>"},{"location":"resources/tools/docker/","title":"Docker","text":"<ul> <li>Git submodules to install custom Python package in Docker image</li> <li>Why use Docker containers for ML development</li> <li>Fast Docker builds with caching</li> <li>Docker best practices for Python developers</li> <li>Multi-stage Docker builds to reduce image size</li> </ul>"},{"location":"resources/tools/drawio/","title":"Draw.io","text":"<ul> <li>Draw.io</li> </ul>"},{"location":"resources/tools/git-versioning/","title":"Git and versioning","text":"<ul> <li>A primer on version control</li> <li>Github for DS</li> <li>Pre commit</li> <li>Update data sources in Python</li> <li>Version control with Git</li> <li>Branching and merging</li> <li>Git commands</li> <li>Plugins for DS</li> <li>Github API for Python</li> <li>Branching in Git</li> <li>Github star history</li> <li>Intro to Git for DS</li> <li>Automating workflows with pre-commit hooks</li> <li>Daily git scenarios for DS</li> <li>Git web editor and repo diagram</li> <li>Gource a git history visualizer</li> <li>Branching workflows for Git</li> <li>Pre-commit hook for code formatting</li> <li>Use Git tactically</li> <li>Git cheatsheet by GitHub</li> <li>Gitpod: spin up automated dev environments</li> <li>Git and GitHub illustrations</li> <li> <p>Git scraping: track changes over time by scraping to a Git repository</p> <p>The internet is full of interesting data that changes over time. These changes can sometimes be more interesting than the underlying static data.</p> </li> <li> <p>git-story: tell the story of a Git project by creating video animations</p> </li> <li>git effort: show effort statistics on file</li> </ul>"},{"location":"resources/tools/github/","title":"Github","text":"<ul> <li>20 repositories for developers</li> </ul>"},{"location":"resources/tools/google/","title":"Google","text":"<ul> <li>Advanced Google search</li> </ul>"},{"location":"resources/tools/graphics/","title":"Graphics","text":"<ul> <li>Open source vector graphics editor</li> </ul>"},{"location":"resources/tools/graphql/","title":"GraphQL","text":"<ul> <li>GraphQL</li> </ul>"},{"location":"resources/tools/html/","title":"HTML","text":"<ul> <li>PyScript</li> </ul>"},{"location":"resources/tools/impress-js/","title":"impress.js","text":"<ul> <li>impress.js and Slides, Prezi-inspired</li> </ul>"},{"location":"resources/tools/json/","title":"JSON","text":"<ul> <li>JSON Visio editor</li> </ul>"},{"location":"resources/tools/markdown/","title":"Markdown","text":"<ul> <li>Stackedit</li> <li>Markdown email in PBP</li> <li>Mermaid for markdown diagram</li> <li>Markdown books with mdBook</li> </ul>"},{"location":"resources/tools/misc/","title":"Misc","text":"<ul> <li>Data Science toolset starter kit</li> </ul>"},{"location":"resources/tools/performance-monitoring/","title":"Performance monitoring","text":"<ul> <li>Netdata</li> </ul>"},{"location":"resources/tools/project-management/","title":"Project Management","text":"<ul> <li>Optimize a to-do list with Monte Carlo simulations</li> <li>Estimating tasks with statistics and simulations</li> </ul>"},{"location":"resources/tools/quarto/","title":"Quarto","text":"<ul> <li>Quarto docs</li> </ul>"},{"location":"resources/tools/reveal-js/","title":"reveal.js","text":"<ul> <li>reveal.js and Slides</li> </ul>"},{"location":"resources/tools/slack/","title":"Slack","text":"<ul> <li>Python and Slack</li> </ul>"},{"location":"resources/tools/software-development/","title":"Software Development","text":"<ul> <li>SOLID principle</li> <li>Software quality attributes</li> </ul>"},{"location":"resources/tools/terminal/","title":"Terminal","text":"<ul> <li>Upgrade terminal experience</li> <li>Cool terminal customization</li> <li>Rich</li> <li>How to use <code>rich</code> features</li> <li>Quokka.js</li> </ul>"},{"location":"resources/tools/visual-studio-code/","title":"Visual Studio Code","text":"<ul> <li>VSC extensions for DS</li> <li>Sonarlint</li> <li>Kite</li> <li>Code cognitive complexity</li> <li>Python rules for cognitive complexity</li> <li>Intellicode</li> <li>Advanced VSC for Python developers</li> </ul>"},{"location":"resources/tools/wsl/","title":"WSL","text":"<ul> <li>Difference between WSL1 and WSL2</li> <li>WSL on PBP</li> </ul>"},{"location":"resources/tools/yaml/","title":"YAML","text":"<ul> <li>YAML vs JSON</li> <li>YAML vs JSON 2</li> <li>Strict YAML</li> </ul>"},{"location":"resources/training/","title":"Training","text":""},{"location":"resources/training/#books","title":"Books","text":"<ul> <li>Free and paid data science books</li> <li>7 free books to read in 2020</li> <li>Forecasting: Principles and Practice</li> <li>Python for Data Analysis, 3E</li> <li>Database Theory</li> <li>Open Electricity Economics</li> <li>The Turing Way</li> <li>The Pragmatic Programmer for Machine Learning</li> <li>An Introduction to Statistical Learning</li> <li>Python4DS</li> <li>The Data Engineering Handbook</li> <li>Stochastic Simulation: from Uniform Random Numbers to Generative Models</li> </ul>"},{"location":"resources/training/#certifications","title":"Certifications","text":"<ul> <li>AWS ML Specialty certification</li> <li>AWS DS training path</li> <li>AWS certified ML</li> <li>Google certificates</li> </ul>"},{"location":"resources/training/#aws-certification-paths","title":"AWS Certification paths","text":"<ul> <li>AWS Certification Paths</li> <li>AWS Training and Certification Guide</li> </ul>"},{"location":"resources/training/#competitions","title":"Competitions","text":"<ul> <li>Data Science and AI competitions for 2021</li> </ul>"},{"location":"resources/training/#courses","title":"Courses","text":"<ul> <li>Making friends with Machine Learning by Cassie Kozyrkov</li> <li>Data Science Tools cheatsheets from MIT 15.003</li> <li>Information Visualization</li> <li>Statistical Rethinking</li> <li>Google ML</li> <li>Applied Machine Learning (Cornell Tech University) and its repo</li> <li>Introduction to data-centric A.I.</li> </ul>"},{"location":"resources/training/#open-source-heroes","title":"Open Source Heroes","text":"<ul> <li>koaning</li> <li>MaartenGr</li> <li>Tutte Institute for Mathematics and Computing</li> </ul>"},{"location":"resources/training/#learning-path","title":"Learning Path","text":"<ul> <li>How to start ML</li> <li>Learning path repositories</li> <li>DevOps roadmap</li> </ul>"},{"location":"resources/training/#master","title":"Master","text":"<ul> <li>BBS Data Science</li> <li>Master Big Data</li> <li>BI Master</li> <li>Bigdata UniRoma</li> <li>DSS UniRoma</li> </ul>"},{"location":"resources/training/#mooc","title":"MOOC","text":"<ul> <li>Udacity</li> <li>edX</li> <li>Udemy</li> <li>AWS @ edX</li> <li>10 things to know about DS</li> <li>ColumbiaX</li> <li>Morphocode</li> <li>Terrelogiche GIS</li> <li>AWS Digital training</li> </ul>"},{"location":"resources/training/#academic-papers","title":"Academic papers","text":"<ul> <li>Papers we love: learning more about academic computer science papers</li> <li>Papers with code</li> </ul>"},{"location":"resources/training/#programming-languages","title":"Programming Languages","text":"<ul> <li>Calmcode</li> <li>shadcn-ui: build your component library</li> </ul>"},{"location":"resources/training/#elm","title":"Elm","text":"<ul> <li>Elm</li> </ul>"},{"location":"resources/training/#go","title":"Go","text":"<ul> <li>Gophernotes</li> <li>Golang features</li> <li>Golang goroutines</li> </ul>"},{"location":"resources/training/#julia","title":"Julia","text":"<ul> <li>Julia by example</li> <li>Learn x in y minutes: Julia</li> <li>Why learn Julia</li> <li>Pluto notebook for Julia</li> <li>From Python to Julia: An Ultimate Guide</li> </ul>"},{"location":"resources/training/#mint","title":"Mint","text":"<ul> <li>Mint language</li> </ul>"},{"location":"resources/training/#rust","title":"Rust","text":"<ul> <li>Rust by example</li> <li>Python to Rust: Breaking Down 3 Big Obstacles</li> </ul>"},{"location":"resources/training/#swift","title":"Swift","text":"<ul> <li>Swift and differentiable programming</li> <li>Swift by example</li> </ul>"},{"location":"resources/training/#schools","title":"Schools","text":"<ul> <li>Barcelona GSE</li> <li>BigDat</li> <li>DS PhD</li> <li>BigDive</li> </ul>"},{"location":"resources/training/books/","title":"Books","text":"<ul> <li>Free and paid data science books</li> <li>7 free books to read in 2020</li> <li>Forecasting: Principles and Practice</li> <li>Python for Data Analysis, 3E</li> <li>Database Theory</li> <li>Open Electricity Economics</li> <li>The Turing Way</li> <li>The Pragmatic Programmer for Machine Learning</li> <li>An Introduction to Statistical Learning</li> <li>Python4DS</li> <li>The Data Engineering Handbook</li> <li>Stochastic Simulation: from Uniform Random Numbers to Generative Models</li> </ul>"},{"location":"resources/training/certifications/","title":"Certifications","text":"<ul> <li>AWS ML Specialty certification</li> <li>AWS DS training path</li> <li>AWS certified ML</li> <li>Google certificates</li> </ul>"},{"location":"resources/training/certifications/#aws-certification-paths","title":"AWS Certification paths","text":"<ul> <li>AWS Certification Paths</li> <li>AWS Training and Certification Guide</li> </ul>"},{"location":"resources/training/competitions/","title":"Competitions","text":"<ul> <li>Data Science and AI competitions for 2021</li> </ul>"},{"location":"resources/training/courses/","title":"Courses","text":"<ul> <li>Making friends with Machine Learning by Cassie Kozyrkov</li> <li>Data Science Tools cheatsheets from MIT 15.003</li> <li>Information Visualization</li> <li>Statistical Rethinking</li> <li>Google ML</li> <li>Applied Machine Learning (Cornell Tech University) and its repo</li> <li>Introduction to data-centric A.I.</li> </ul>"},{"location":"resources/training/heroes/","title":"Open Source Heroes","text":"<ul> <li>koaning</li> <li>MaartenGr</li> <li>Tutte Institute for Mathematics and Computing</li> </ul>"},{"location":"resources/training/learning-path/","title":"Learning Path","text":"<ul> <li>How to start ML</li> <li>Learning path repositories</li> <li>DevOps roadmap</li> </ul>"},{"location":"resources/training/master/","title":"Master","text":"<ul> <li>BBS Data Science</li> <li>Master Big Data</li> <li>BI Master</li> <li>Bigdata UniRoma</li> <li>DSS UniRoma</li> </ul>"},{"location":"resources/training/mooc/","title":"MOOC","text":"<ul> <li>Udacity</li> <li>edX</li> <li>Udemy</li> <li>AWS @ edX</li> <li>10 things to know about DS</li> <li>ColumbiaX</li> <li>Morphocode</li> <li>Terrelogiche GIS</li> <li>AWS Digital training</li> </ul>"},{"location":"resources/training/papers/","title":"Academic papers","text":"<ul> <li>Papers we love: learning more about academic computer science papers</li> <li>Papers with code</li> </ul>"},{"location":"resources/training/programming-languages/","title":"Programming Languages","text":"<ul> <li>Calmcode</li> <li>shadcn-ui: build your component library</li> </ul>"},{"location":"resources/training/programming-languages/#elm","title":"Elm","text":"<ul> <li>Elm</li> </ul>"},{"location":"resources/training/programming-languages/#go","title":"Go","text":"<ul> <li>Gophernotes</li> <li>Golang features</li> <li>Golang goroutines</li> </ul>"},{"location":"resources/training/programming-languages/#julia","title":"Julia","text":"<ul> <li>Julia by example</li> <li>Learn x in y minutes: Julia</li> <li>Why learn Julia</li> <li>Pluto notebook for Julia</li> <li>From Python to Julia: An Ultimate Guide</li> </ul>"},{"location":"resources/training/programming-languages/#mint","title":"Mint","text":"<ul> <li>Mint language</li> </ul>"},{"location":"resources/training/programming-languages/#rust","title":"Rust","text":"<ul> <li>Rust by example</li> <li>Python to Rust: Breaking Down 3 Big Obstacles</li> </ul>"},{"location":"resources/training/programming-languages/#swift","title":"Swift","text":"<ul> <li>Swift and differentiable programming</li> <li>Swift by example</li> </ul>"},{"location":"resources/training/schools/","title":"Schools","text":"<ul> <li>Barcelona GSE</li> <li>BigDat</li> <li>DS PhD</li> <li>BigDive</li> </ul>"},{"location":"archive/2024/","title":"2024","text":""},{"location":"archive/2023/","title":"2023","text":""},{"location":"archive/2022/","title":"2022","text":""},{"location":"archive/2021/","title":"2021","text":""},{"location":"archive/2020/","title":"2020","text":""},{"location":"archive/2019/","title":"2019","text":""},{"location":"category/til/","title":"TIL","text":""},{"location":"category/announcements/","title":"Announcements","text":""},{"location":"category/guides/","title":"Guides","text":""},{"location":"page/2/","title":"A Data Scientist Blog","text":""},{"location":"page/3/","title":"A Data Scientist Blog","text":""},{"location":"tags/","title":"Tags","text":""},{"location":"tags/#aws","title":"AWS","text":"<ul> <li>A comparison between AWS Chalice and AWS SAM</li> <li>AWS CodeBuild local testing</li> <li>A comparison between AWS databases</li> <li>Read DynamoDB table items into a Pandas Dataframe</li> <li>An introduction to Amazon DynamoDB</li> <li>Amazon EC2 instance debug</li> <li>How to display AWS CloudWatch logs in Streamlit</li> <li>AWS S3 presigned URLs</li> <li>Build Lambda layers with AWS SAM</li> <li>Best practices per AWS CDK L3 constructs</li> <li>A visual comparison of AWS Certifications</li> <li>AWS Certification Skill Tree</li> <li>All you need is closure</li> <li>Cross-account full table copy options for Amazon DynamoDB</li> </ul>"},{"location":"tags/#database","title":"Database","text":"<ul> <li>A comparison between AWS databases</li> <li>Read DynamoDB table items into a Pandas Dataframe</li> <li>An introduction to Amazon DynamoDB</li> <li>Cross-account full table copy options for Amazon DynamoDB</li> </ul>"},{"location":"tags/#devops","title":"DevOps","text":"<ul> <li>AWS CodeBuild local testing</li> </ul>"},{"location":"tags/#ita","title":"ITA","text":"<ul> <li>Best practices per AWS CDK L3 constructs</li> <li>Presto/Trino, unix timestamp, window functions e daylight saving time</li> </ul>"},{"location":"tags/#iac","title":"IaC","text":"<ul> <li>Best practices per AWS CDK L3 constructs</li> </ul>"},{"location":"tags/#or","title":"OR","text":"<ul> <li>A brief guide to Python's PuLP</li> <li>A guide to transportation problems</li> </ul>"},{"location":"tags/#open-source","title":"Open Source","text":"<ul> <li>Read DynamoDB table items into a Pandas Dataframe</li> </ul>"},{"location":"tags/#python","title":"Python","text":"<ul> <li>Read DynamoDB table items into a Pandas Dataframe</li> <li>A brief guide to Python's PuLP</li> <li>A visual comparison of AWS Certifications</li> <li>AWS Certification Skill Tree</li> <li>All you need is closure</li> <li>Terminal User Interface</li> </ul>"},{"location":"tags/#sql","title":"SQL","text":"<ul> <li>Presto/Trino, unix timestamp, window functions e daylight saving time</li> </ul>"},{"location":"tags/#streamlit","title":"Streamlit","text":"<ul> <li>How to display AWS CloudWatch logs in Streamlit</li> </ul>"}]}